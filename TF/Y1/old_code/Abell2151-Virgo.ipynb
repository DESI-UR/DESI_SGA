{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd925c8e-e017-40f7-bd18-c75fc388e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "from matplotlib import cm, colors\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "import pandas as pd\n",
    "from astropy.table import Table, unique\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "from astropy import units as u\n",
    "from astropy.table import join\n",
    "from scipy.optimize import minimize, curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3760129-71aa-49cc-9092-0c21c7c07756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table, vstack, hstack, join, unique\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization.wcsaxes import SphericalCircle\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa51e982-2167-4ceb-9723-7b7fe2d5cdfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperfit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhyperfit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinfit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinFit\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperfit'"
     ]
    }
   ],
   "source": [
    "from hyperfit.linfit import LinFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533249c-48da-4daa-a75f-95f2fac3fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1\n",
    "H0 = 100*h\n",
    "\n",
    "c = 3e5\n",
    "\n",
    "q0 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf4d19-4fd5-4182-a3b8-63afed768712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstdigit(n):\n",
    "    \"\"\"Return the first digit of a number.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int, float, or ndarray\n",
    "        Number or list of numbers.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    digit : int\n",
    "        First digit of the number.\n",
    "    \"\"\"\n",
    "    return np.trunc(n * 10**(-np.trunc(np.log10(n)))).astype(int)\n",
    "\n",
    "def plot_radec(ra, dec):\n",
    "    \"\"\"Mollweide projection plot adapted to astro coordinates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ra : pandas.Series or list\n",
    "        List of candidate RA [deg].\n",
    "    dec : pandas.Series or list\n",
    "        List of candidate Dec [deg].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib.Figure\n",
    "        Figure object to let user apply further plot manipulation.\n",
    "    \"\"\"\n",
    "    # Convert RA, Dec to radians.\n",
    "    # Rotate the RA so that the plot goes 360->0 left to right.\n",
    "    _ra = np.radians(120 - ra)\n",
    "    _ra[_ra < -np.pi] += 2*np.pi\n",
    "    _dec = np.radians(dec)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,4), subplot_kw={'projection': 'mollweide'})\n",
    "    ax.scatter(_ra, _dec, alpha=0.5, s=2)\n",
    "    ax.set(xticks=np.radians([-150, -120, -90, -60, -30, 0, 30, 60, 90, 120, 150]),\n",
    "           xticklabels=['270', '240', '210', '180', '150', '120', '90', '60', '30', '0', '330'])\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.grid(ls=':')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig;\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_cutout(targetid, ra, dec, width=300, height=300, verbose=False):\n",
    "    \"\"\"Grab and cache legacy survey cutouts.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    targetid : int\n",
    "        DESI target ID.\n",
    "    ra : float\n",
    "        Right ascension (degrees).\n",
    "    dec : float\n",
    "        Declination (degrees).\n",
    "    verbose : bool\n",
    "        Add some status messages if true.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    img_name : str\n",
    "        Name of JPG cutout file written after query.\n",
    "    w : astropy.wcs.WCS\n",
    "        World coordinate system for the image.\n",
    "    \"\"\"\n",
    "    # Either load an existing image or download a cutout.\n",
    "    os.makedirs('_cache', exist_ok=True)\n",
    "    img_name = f'_cache/cutout_{targetid}_{width}_{height}.jpg'\n",
    "    \n",
    "    if os.path.exists(img_name):\n",
    "        if verbose:\n",
    "            print('{} exists.'.format(img_name))\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('Accessing {}'.format(img_name))\n",
    "        img_url = f'https://www.legacysurvey.org/viewer/cutout.jpg?ra={ra}&dec={dec}&%22/pix=0.25&layer=ls-dr9&width={width}&height={height}&sga'\n",
    "        with open(img_name, 'wb') as handle: \n",
    "            response = requests.get(img_url, stream=True) \n",
    "            if not response.ok: \n",
    "                print(response) \n",
    "            for block in response.iter_content(1024): \n",
    "                if not block: \n",
    "                    break \n",
    "                handle.write(block)\n",
    "                \n",
    "    # Set up the WCS.\n",
    "    wcs_input_dict = {\n",
    "        'CTYPE1': 'RA---TAN',\n",
    "        'CUNIT1': 'deg',\n",
    "        'CDELT1': -0.25/3600,\n",
    "        'CRPIX1': width//2,\n",
    "        'CRVAL1': ra,\n",
    "        'NAXIS1': width,\n",
    "        'CTYPE2': 'DEC--TAN',\n",
    "        'CUNIT2': 'deg',\n",
    "        'CDELT2': 0.25/3600,\n",
    "        'CRPIX2': height//2,\n",
    "        'CRVAL2': dec,\n",
    "        'NAXIS2': height\n",
    "    }\n",
    "    w = WCS(wcs_input_dict)\n",
    "    \n",
    "    return img_name, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b450163-c28a-4928-b212-f72e3948f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_catalog(data):\n",
    "    \"\"\"Take a catalog matched to PV TF targets and apply quality cuts:\n",
    "    * Keep only good redshifts (ZWARN==0, DELTACHI2>=25)\n",
    "    * Ensure 1 main DESI TARGETID per SGA_ID\n",
    "    * Ensure >1 distinct TARGETIDs per SGA_ID\n",
    "    * Ensure targets are not all spatially coincident.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : astropy.Table\n",
    "        Table of TF redshift measurements and matched SGA_IDs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_tf: astropy.Table or None\n",
    "        Data suitable for Tully-Fisher analysis, after basic cuts.\n",
    "    \"\"\"\n",
    "    # All targets\n",
    "    _ids_all, _counts_all = np.unique(tfuji['SGA_ID'], return_counts=True)\n",
    "\n",
    "    # Identify targets with good redshifts.\n",
    "    isgoodz = (data['ZWARN']==0) & (data['DELTACHI2']>=25)\n",
    "    _ids_goodz, _counts_goodz = np.unique(data['SGA_ID'][isgoodz], return_counts=True)\n",
    "\n",
    "    # Select SGA_IDs with at least 2 good associated redshifts.\n",
    "    select = np.in1d(data['SGA_ID'], _ids_goodz[_counts_goodz > 1]) & isgoodz\n",
    "    data = data[select].group_by('SGA_ID')\n",
    "\n",
    "    # Storage for output.\n",
    "    data_tf = None\n",
    "\n",
    "    # Loop through the table and keep only SGA IDs with >= 2 unique TARGETIDs, where one is a MAIN survey target.\n",
    "    sga_ids = np.unique(data['SGA_ID'])\n",
    "    N = len(sga_ids)\n",
    "\n",
    "    with tqdm_notebook(total=N) as progress_bar:\n",
    "        for i, sga_id in enumerate(sga_ids):\n",
    "            progress_bar.update(1)\n",
    "            tab = data[data['SGA_ID']==sga_id]\n",
    "\n",
    "            # MAIN targets have a TARGETID that starts with 3. Ensure one is present.\n",
    "            digits = firstdigit(tab['TARGETID'])\n",
    "            if np.any(digits == 3):\n",
    "                maintargetids = np.unique(tab['TARGETID'][digits==3].value)\n",
    "\n",
    "                # Ensure there are at least two distinct TARGETIDs matched to this SGA_ID.\n",
    "                ntargets = len(np.unique(tab['TARGETID'].value))\n",
    "                if ntargets >= 2:\n",
    "\n",
    "                    # Ensure the TARGETIDs correspond to distinct locations on the sky.\n",
    "                    coords = SkyCoord(tab['TARGET_RA'], tab['TARGET_DEC'], frame='icrs', unit='degree')\n",
    "                    is_distinct = np.any([c1.separation(c2).to_value('arcsec') > 1 for c1 in coords for c2 in coords])\n",
    "                    if not is_distinct:\n",
    "                        continue\n",
    "                # Check that there two or more TARGETIDs.\n",
    "                else:\n",
    "                    continue\n",
    "            # Check that there is a MAIN survey TARGETID associated with this SGA_ID.\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if data_tf is None:\n",
    "                data_tf = tab\n",
    "            else:\n",
    "                data_tf = vstack([data_tf, tab])\n",
    "\n",
    "    return data_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c00a1-f815-4635-9957-b33cfc22185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_catalog_1(data):\n",
    "    \"\"\"Take a catalog matched to PV TF targets and apply quality cuts:\n",
    "    * Keep only good redshifts (ZWARN==0, DELTACHI2>=25)\n",
    "    * Ensure 1 main DESI TARGETID per SGA_ID\n",
    "    * Ensure >1 distinct TARGETIDs per SGA_ID\n",
    "    * Ensure targets are not all spatially coincident.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : astropy.Table\n",
    "        Table of TF redshift measurements and matched SGA_IDs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_tf: astropy.Table or None\n",
    "        Data suitable for Tully-Fisher analysis, after basic cuts.\n",
    "    \"\"\"\n",
    "    # All targets\n",
    "    _ids_all, _counts_all = np.unique(tfuji['SGA_ID'], return_counts=True)\n",
    "\n",
    "    # Identify targets with good redshifts.\n",
    "    isgoodz = (data['ZWARN']==0) & (data['DELTACHI2']>=25)\n",
    "    _ids_goodz, _counts_goodz = np.unique(data['SGA_ID_1'][isgoodz], return_counts=True)\n",
    "\n",
    "    # Select SGA_IDs with at least 2 good associated redshifts.\n",
    "    select = np.in1d(data['SGA_ID_1'], _ids_goodz[_counts_goodz > 1]) & isgoodz\n",
    "    data = data[select].group_by('SGA_ID_1')\n",
    "\n",
    "    # Storage for output.\n",
    "    data_tf = None\n",
    "\n",
    "    # Loop through the table and keep only SGA IDs with >= 2 unique TARGETIDs, where one is a MAIN survey target.\n",
    "    sga_ids = np.unique(data['SGA_ID_1'])\n",
    "    N = len(sga_ids)\n",
    "\n",
    "    with tqdm_notebook(total=N) as progress_bar:\n",
    "        for i, sga_id in enumerate(sga_ids):\n",
    "            progress_bar.update(1)\n",
    "            tab = data[data['SGA_ID_1']==sga_id]\n",
    "\n",
    "            # MAIN targets have a TARGETID that starts with 3. Ensure one is present.\n",
    "            digits = firstdigit(tab['TARGETID'])\n",
    "            if np.any(digits == 3):\n",
    "                maintargetids = np.unique(tab['TARGETID'][digits==3].value)\n",
    "\n",
    "                # Ensure there are at least two distinct TARGETIDs matched to this SGA_ID.\n",
    "                ntargets = len(np.unique(tab['TARGETID'].value))\n",
    "                if ntargets >= 2:\n",
    "\n",
    "                    # Ensure the TARGETIDs correspond to distinct locations on the sky.\n",
    "                    coords = SkyCoord(tab['TARGET_RA'], tab['TARGET_DEC'], frame='icrs', unit='degree')\n",
    "                    is_distinct = np.any([c1.separation(c2).to_value('arcsec') > 1 for c1 in coords for c2 in coords])\n",
    "                    if not is_distinct:\n",
    "                        continue\n",
    "                # Check that there two or more TARGETIDs.\n",
    "                else:\n",
    "                    continue\n",
    "            # Check that there is a MAIN survey TARGETID associated with this SGA_ID.\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if data_tf is None:\n",
    "                data_tf = tab\n",
    "            else:\n",
    "                data_tf = vstack([data_tf, tab])\n",
    "\n",
    "    return data_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569ebb85-8f43-4db3-b3fb-311698ab25b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Fuji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9d130-1c22-4ee8-b585-db35c8d85718",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfuji = Table.read('/global/project/projectdirs/desi/science/td/pv/desi_pv_tf_fuji_healpix.fits')\n",
    "tfuji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22afe677-c73c-4dd9-a248-8f895537327e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Daily Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa52b9-9234-4eab-8a78-4fb99bc3e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdaily = Table.read('/global/project/projectdirs/desi/science/td/pv/desi_pv_tf_daily_tiles.fits')\n",
    "tdaily = unique(tdaily[(tdaily['NIGHT'] > 20210513) & (tdaily['NIGHT'] < 20220514)])\n",
    "tdaily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19849536-dcc4-45ba-9390-3b11291384ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Multiple Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824cfc34-8645-402a-97e8-5f0cf475acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All targets\n",
    "_ids_all, _counts_all = np.unique(tdaily['SGA_ID'], return_counts=True)\n",
    "_ids_all[_counts_all > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895cbfbc-6e0a-4830-b08e-5b029b94b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,5), tight_layout=True)\n",
    "\n",
    "ax.hist(_counts_all[_counts_all > 1], bins = 20)\n",
    "\n",
    "ax.set(xlabel='Observations per SGA_ID in Daily Tiles', \n",
    "       ylabel='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb249b95-3332-4e18-8941-bcf4e56326a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All targets with decent redshifts and observations suitable for the Tully-Fisher analysis\n",
    "tmain_tf = clean_catalog(tdaily)\n",
    "_ids_goodz, _counts_goodz = np.unique(tmain_tf['SGA_ID'], return_counts=True)\n",
    "_ids_goodz[_counts_goodz > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e627c00-9303-4fe2-85dd-66980be68ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmain_goodz = np.in1d(tmain_tf['SGA_ID'], _ids_goodz[_counts_goodz > 1])\n",
    "tmain_g = tmain_tf[tmain_goodz]\n",
    "tmain_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92622c1-6add-49dc-b12f-1246e8f4a398",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inclination Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a164d0c-1634-4161-a738-aae5776d2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGA = Table.read('/global/cfs/cdirs/cosmo/data/sga/2020/SGA-2020.fits', 'ELLIPSE')\n",
    "\n",
    "SGA[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35c94e-5788-4059-acd8-ff02fa4efe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGA_main = join(tmain_g, SGA, keys_left='SGA_ID', keys_right='SGA_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295c4c3-c868-4990-9bf2-2bf6f0ab3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGA_main.group_by('SGA_ID_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11111c5-4ca2-43d5-ab92-9db19fa0ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sga_ids_clean = []\n",
    "\n",
    "rmag_clean = []\n",
    "drmag_clean = []\n",
    "vmax_clean = []\n",
    "dvmax_clean = []\n",
    "z = []\n",
    "\n",
    "q0 = 0.2\n",
    "\n",
    "inc_min = 45*u.degree\n",
    "cosi_max = np.cos(inc_min.to('radian'))\n",
    "\n",
    "SGA_main['cosi'] = np.sqrt((SGA_main['BA']**2 - q0**2)/(1 - q0**2))\n",
    "SGA_main['cosi'][np.isnan(SGA_main['BA'])] = 0 # Objects with b/a < 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e74b1c-a4e3-4f09-bcb1-f5b828c9dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in SGA_main.colnames:\n",
    "    SGA_main = SGA_main[SGA_main['cosi'] < cosi_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee8b6f-94b9-4af5-8a59-d74060b07668",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGA_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13247f94-9775-4e87-9b52-0edd615f2ef7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Morphology Cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf90b1a-24db-4db7-89c5-3a598ba2a68e",
   "metadata": {},
   "source": [
    "for col in SGA_main.colnames:\n",
    "    SGA_main = SGA_main[SGA_main['MORPHTYPE'].startswith('S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf23c8-7f06-4d6c-8f5b-8b24fa84e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,20): \n",
    "    for i in range(0, len(SGA_main)):\n",
    "        morphtype = str(SGA_main['MORPHTYPE'][i])\n",
    "    \n",
    "        # Cut any suspected ellipticals\n",
    "        if morphtype.startswith('S'):\n",
    "            continue\n",
    "        \n",
    "    #print(i, morphtype)\n",
    "    \n",
    "        SGA_main.remove_row(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908af24b-4deb-4aee-bc00-1aa9d9eaaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All targets\n",
    "_ids_all, _counts_all = np.unique(SGA_main['SGA_ID_1'], return_counts=True)\n",
    "_ids_all[_counts_all > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31c814-b222-45f8-ba2d-b2d5f1bdc01a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85e315-980c-40d2-a314-97ced49663f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.open('DESI_SGA/TF/Tully15-Table3.fits')\n",
    "table3 = Table(hdu[1].data)\n",
    "hdu.close()\n",
    "\n",
    "#table3[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4fc2b-6233-4c24-9ba0-2b1aceb29678",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.open('DESI_SGA/TF/Tully13-Table2.fit')\n",
    "table2 = Table(hdu[1].data)\n",
    "hdu.close()\n",
    "\n",
    "#table2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383af748-aac1-4366-8159-16317a85678d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Abell 2151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c6bff-12f9-4885-80d8-5b9e250298eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2151_nest = 100007\n",
    "\n",
    "a2151_row_t3 = table3['Nest'] == a2151_nest\n",
    "\n",
    "R2t_a2151 = table3['R2t'][a2151_row_t3][0]\n",
    "sigma_a2151 = table3['sigP'][a2151_row_t3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fcc733-4f1b-47ce-b12b-07d5868e07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2151_coords = SkyCoord(table3['SGLON'][a2151_row_t3]*u.degree, \n",
    "                       table3['SGLAT'][a2151_row_t3]*u.degree, \n",
    "                       frame='supergalactic')\n",
    "\n",
    "a2151_group_coords = SkyCoord(table2['SGLON']*u.degree, \n",
    "                        table2['SGLAT']*u.degree, \n",
    "                        frame='supergalactic')\n",
    "\n",
    "idx, d2d, d3d = a2151_coords.match_to_catalog_sky(a2151_group_coords)\n",
    "\n",
    "V_a2151 = table2['__HV_'][idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1a402-6d3c-490f-945d-0dc827cea33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to convert R2t from Mpc to an angle, using the group's heliocentric velocity\n",
    "R2t_a2151_angle = (R2t_a2151/(V_a2151/H0))*u.radian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c9644-430a-4fc6-a756-f99d3813fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2151_tf_coords = SkyCoord(SGA_main['TARGET_RA'], SGA_main['TARGET_DEC'], unit='deg')\n",
    "\n",
    "a21sep = a2151_coords.separation(a2151_tf_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d66f4-cdb7-42cc-8aad-0c06c54a035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuji_in_a21511 = (a21sep < 1.5*R2t_a2151_angle) & (SGA_main['Z']*c > V_a2151 - 3*sigma_a2151) & (SGA_main['Z']*c < V_a2151 + 3*sigma_a2151)\n",
    "\n",
    "fuji_in_a21512 = (a21sep >= 1.5*R2t_a2151_angle) & (a21sep < 3*R2t_a2151_angle) & (SGA_main['Z']*c > V_a2151 - 2*sigma_a2151) & (SGA_main['Z']*c < V_a2151 + 2*sigma_a2151)\n",
    "\n",
    "fuji_in_a2151 = fuji_in_a21511 | fuji_in_a21512\n",
    "\n",
    "################################################################################\n",
    "# Keep all instances of each SGA_ID that are within the Coma cluster\n",
    "#-------------------------------------------------------------------------------\n",
    "fuji_ID_in_a2151 = np.unique(SGA_main['SGA_ID_1'][fuji_in_a2151])\n",
    "\n",
    "idx_fuji_in_a2151 = np.in1d(SGA_main['SGA_ID_1'], fuji_ID_in_a2151)\n",
    "\n",
    "inAbell2151_fuji_table = SGA_main[idx_fuji_in_a2151]\n",
    "################################################################################\n",
    "\n",
    "inAbell2151_fuji_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f67d01-a736-4e80-8274-4c54a8d2f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(a21sep[fuji_in_a2151].to_value('degree'))\n",
    "plt.xlabel('MaNGA-Abell 2151 Angular Separation [deg]')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde9d08-e1a5-409e-85f4-0a8e44377445",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,5), tight_layout=True)\n",
    "ax = axes[0]\n",
    "ax.plot(inAbell2151_fuji_table['TARGET_DEC'], inAbell2151_fuji_table['TARGET_RA'], '.')\n",
    "ax = axes[1]\n",
    "ax.hist(inAbell2151_fuji_table['Z']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca05266-3729-49ff-b67d-86065572f329",
   "metadata": {},
   "source": [
    "#### Multiple counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789774b6-9426-4e9b-b93e-bb49520a70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, counts = np.unique(inAbell2151_fuji_table['SGA_ID_1'], return_counts=True)\n",
    "ids[counts > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6157817-73f6-466f-b986-270116004e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,5), tight_layout=True)\n",
    "\n",
    "ax.hist(counts[counts > 1], bins=np.linspace(2,10,20))\n",
    "\n",
    "ax.set(xlabel='Observations per SGA_ID Abell 2151', \n",
    "       ylabel='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee422f2a-c1ad-4317-bd14-3d460a1f5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only those with more than one observation\n",
    "high_count_sga = np.in1d(inAbell2151_fuji_table['SGA_ID_1'], ids[counts > 1])\n",
    "tf_a2151_multiple = inAbell2151_fuji_table[high_count_sga]\n",
    "tf_a2151_multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269ab7d-633e-4716-bae1-a5990636f7b0",
   "metadata": {},
   "source": [
    "#### Calculate Rotational Velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7130b13-97b7-4736-a267-0f7e5ca15baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sga_ids_vel_cuts = []\n",
    "R26 = []\n",
    "rmag = []\n",
    "drmag = []\n",
    "vmax = []\n",
    "dvmax = []\n",
    "\n",
    "for i, sga_id in enumerate(np.unique(inAbell2151_fuji_table['SGA_ID_1'])):\n",
    "    # if sga_id == 474614:\n",
    "    #     print('skipped')\n",
    "    #     continue\n",
    "    galaxy_list = inAbell2151_fuji_table[inAbell2151_fuji_table['SGA_ID_1'] == sga_id]\n",
    "    # print\n",
    "    #print(i+1, sga_id)\n",
    "    \n",
    "    is_sga_galaxy = (galaxy_list['TARGETID'] > 30000000000000000) & (galaxy_list['TARGETID'] < 40000000000000000)\n",
    "    \n",
    "    sga_galaxy = galaxy_list[is_sga_galaxy]\n",
    "    tf_list = galaxy_list[~is_sga_galaxy]\n",
    "    \n",
    "    if np.sum(is_sga_galaxy) > 1:\n",
    "        sga_galaxy = sga_galaxy[0]\n",
    "    \n",
    "    targetid = int(sga_galaxy['TARGETID'])\n",
    "    center = SkyCoord(sga_galaxy['TARGET_RA'], sga_galaxy['TARGET_DEC'], unit='deg')\n",
    "    offcenter = SkyCoord(tf_list['TARGET_RA'], tf_list['TARGET_DEC'], unit='deg')\n",
    "    sep2d = offcenter.separation(center)\n",
    "    r26 = 0.5 * float(sga_galaxy['D26'])*u.arcmin\n",
    "    sep_r26 = sep2d.to('arcmin') / r26\n",
    "    \n",
    "    zc, zc_err = sga_galaxy['Z'], sga_galaxy['ZERR']\n",
    "    zt, zt_err = tf_list['Z'], tf_list['ZERR']\n",
    "    \n",
    "    dz = np.abs(zt - zc)\n",
    "    dz_err = np.sqrt(zc_err**2 + zt_err**2)\n",
    "    \n",
    "    dv = c * dz\n",
    "    dv_err = c * dz_err\n",
    "    \n",
    "    good_vel = dv < 5000\n",
    "    # print(good_vel[0], sga_id)\n",
    "    \n",
    "    if np.sum(good_vel) > 0:\n",
    "        sep_r26 = np.insert(sep_r26[good_vel], 0, 0.)\n",
    "        dv = np.insert(dv[good_vel], 0, 0.)\n",
    "        dv_err = np.insert(dv_err[good_vel], 0, 3e5*zc_err)\n",
    "\n",
    "        # Extract the 0.33xR26 points.\n",
    "        is_033_r26 = (sep_r26 > 0.35) & (sep_r26 < 0.45)\n",
    "        if np.sum(is_033_r26) > 0:\n",
    "            v033 = np.mean(dv[is_033_r26])\n",
    "            dv033 = np.sqrt(np.sum(dv_err[is_033_r26]**2))\n",
    "            \n",
    "            R26.append(0.5 * sga_galaxy['D26']*u.arcmin)\n",
    "            rmag.append(float(sga_galaxy['R_MAG_SB26']))\n",
    "            drmag.append(float(sga_galaxy['R_MAG_SB26_ERR']))\n",
    "            vmax.append(v033)\n",
    "            dvmax.append(dv033)\n",
    "            sga_ids_vel_cuts.append(sga_id)\n",
    "    # break\n",
    "#print('mag:', rmag)\n",
    "#print('vel:', vmax)\n",
    "#print('dv:', dvmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b61de-5088-498a-a58e-726017aa59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmag = np.asarray(rmag)\n",
    "drmag = np.asarray(drmag)\n",
    "vmax = np.asarray(vmax)\n",
    "dvmax = np.asarray(dvmax)\n",
    "R26 = np.asarray(R26)\n",
    "\n",
    "isrmeas = rmag > 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,4), tight_layout=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.errorbar(rmag[isrmeas], vmax[isrmeas], xerr=drmag[isrmeas], yerr=dvmax[isrmeas], fmt='ro')\n",
    "ax.set(xlabel='$m_r$(26)',\n",
    "       xlim=(18.5, 12.5),\n",
    "       ylim=(-50,300),\n",
    "       ylabel='$v_\\mathrm{max}$ [km s$^{-1}$]')\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "log10vmax = np.log10(vmax)\n",
    "dlog10vmax = 0.434 * dvmax / vmax \n",
    "\n",
    "ax.errorbar(rmag[isrmeas], log10vmax[isrmeas], yerr=dlog10vmax[isrmeas], fmt='ro')\n",
    "ax.set(xlabel='$m_r$(26)',\n",
    "       xlim=(18.5, 12.5),\n",
    "       ylabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$',\n",
    "       ylim=(-0.5,3))\n",
    "\n",
    "fig.suptitle(r'Rotational velocity at $0.4R_{26}$ for Abell 2151', y=1.05)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "print(np.sum(isrmeas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73326c0-1e5e-40cd-adf7-3366f458fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sga_ids_clean = []\n",
    "\n",
    "rmag_clean = []\n",
    "drmag_clean = []\n",
    "vmax_clean = []\n",
    "dvmax_clean = []\n",
    "z = []\n",
    "\n",
    "inc_min = 45*u.degree\n",
    "cosi_max = np.cos(inc_min.to('radian'))\n",
    "\n",
    "inAbell2151_fuji_table['cosi'] = np.sqrt((inAbell2151_fuji_table['BA']**2 - q0**2)/(1 - q0**2))\n",
    "inAbell2151_fuji_table['cosi'][np.isnan(inAbell2151_fuji_table['cosi'])] = 0 # Objects with b/a < 0.2\n",
    "\n",
    "#i = 0\n",
    "\n",
    "# for sga_id in np.unique(inComa_sga_table['SGA_ID']):\n",
    "for sga_id in sga_ids_vel_cuts:\n",
    "    galaxy_list = inAbell2151_fuji_table[inAbell2151_fuji_table['SGA_ID_1'] == sga_id]\n",
    "    \n",
    "    is_sga_galaxy = (galaxy_list['TARGETID'] > 30000000000000000) & (galaxy_list['TARGETID'] < 40000000000000000)\n",
    "    sga_galaxy = galaxy_list[is_sga_galaxy]\n",
    "    tf_list = galaxy_list[~is_sga_galaxy]\n",
    "    \n",
    "    if np.sum(is_sga_galaxy) > 1:\n",
    "        sga_galaxy = sga_galaxy[0]\n",
    "    \n",
    "    targetid = int(sga_galaxy['TARGETID'])\n",
    "    \n",
    "    center = SkyCoord(sga_galaxy['TARGET_RA'], sga_galaxy['TARGET_DEC'], unit='deg')\n",
    "    offcenter = SkyCoord(tf_list['TARGET_RA'], tf_list['TARGET_DEC'], unit='deg')\n",
    "    sep2d = offcenter.separation(center)\n",
    "    \n",
    "    morphtype = str(sga_galaxy['MORPHTYPE'])\n",
    "    \n",
    "    cosi = float(sga_galaxy['cosi'])\n",
    "    \n",
    "    r26 = 0.5 * float(sga_galaxy['D26']) * u.arcmin\n",
    "    sep_r26 = sep2d.to('arcmin') / r26\n",
    "\n",
    "    # Cut any suspected ellipticals\n",
    "    if morphtype.startswith('E') or morphtype.startswith('S0') or morphtype.startswith('I'):\n",
    "        continue\n",
    "               \n",
    "    # Inclination cut\n",
    "    if cosi > cosi_max:\n",
    "        continue\n",
    "        \n",
    "    #i += 1\n",
    "    #print(i, sga_id, cosi)\n",
    "    \n",
    "    zc, zc_err = float(sga_galaxy['Z']), float(sga_galaxy['ZERR'])\n",
    "    zt, zt_err = tf_list['Z'], tf_list['ZERR']\n",
    "    \n",
    "    dz = np.abs(zt - zc)\n",
    "    dz_err = np.sqrt(zc_err**2 + zt_err**2)\n",
    "    \n",
    "    dv = 3e5 * dz\n",
    "    dv_err = 3e5 * dz_err\n",
    "    \n",
    "    good_vel = dv < 5000\n",
    "    \n",
    "    if np.sum(good_vel) > 0:\n",
    "    \n",
    "        sep_r26 = np.insert(sep_r26[good_vel], 0, 0.)\n",
    "        dv = np.insert(dv[good_vel], 0, 0.)\n",
    "        dv_err = np.insert(dv_err[good_vel], 0, 3e5*zc_err)\n",
    "\n",
    "        # Extract the 0.33xR26 points.\n",
    "        is_033_r26 = (sep_r26 > 0.35) & (sep_r26 < 0.45)\n",
    "        \n",
    "        if np.sum(is_033_r26) > 0:\n",
    "            v033 = np.mean(dv[is_033_r26]) / np.sqrt(1 - cosi**2)\n",
    "            dv033 = np.sqrt(np.sum(dv_err[is_033_r26]**2)) / np.sqrt(1 - cosi**2)\n",
    "            z.append(zc)\n",
    "            rmag_clean.append(float(sga_galaxy['R_MAG_SB26']))\n",
    "            drmag_clean.append(float(sga_galaxy['R_MAG_SB26_ERR']))\n",
    "            vmax_clean.append(v033)\n",
    "            dvmax_clean.append(dv033)\n",
    "            sga_ids_clean.append(sga_id)\n",
    "    \n",
    "#inComa_sga_table[['SGA_ID', 'BA', 'cosi']].show_in_notebook()\n",
    "print(len(rmag_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9e062-9e94-497a-b61f-39d5a53f107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1norm(pars, x, y, dy):\n",
    "    '''\n",
    "    Linear fit that uses the l1-norm (robust against outliers).\n",
    "    '''\n",
    "    a, b = pars\n",
    "    return np.sum(np.abs((y - a - b*x)/dy))\n",
    "\n",
    "def l1norm_noerror(pars, x, y):\n",
    "    '''\n",
    "    Linear fit that uses the l1-norm without normalizing by measurement uncertainties.\n",
    "    '''\n",
    "    a, b = pars\n",
    "    return np.sum(np.abs(y - a - b*x))\n",
    "\n",
    "def l2norm(pars, x, y, dy):\n",
    "    '''\n",
    "    Linear fit that uses the l2-norm\n",
    "    '''\n",
    "    a, b = pars\n",
    "    return np.sum((y - a - b*x)**2/dy**2)\n",
    "\n",
    "def fit_tfr(r, logv, dlogv):\n",
    "    fmin = 1e99\n",
    "    a, b = 6, -0.25\n",
    "    hess_inv = np.ones((2,2))\n",
    "    \n",
    "    succ_res = None\n",
    "    \n",
    "    # Try a large number of random seeds to ensure a decent fit.\n",
    "    for i in range(1000):\n",
    "        _a, _b = np.random.uniform(0,10), np.random.uniform(-1,0)\n",
    "        \n",
    "        res = minimize(l1norm_noerror, \n",
    "                       [_a, _b], \n",
    "                       args=(r, logv),# dlogv),\n",
    "                       method='L-BFGS-B', \n",
    "                       bounds=[[0,10], [-1,1]])\n",
    "        \n",
    "        if res.fun < fmin and res.success:\n",
    "            print('Successful fit')\n",
    "            succ_res = res.copy()\n",
    "            fmin = res.fun\n",
    "            a, b = res.x\n",
    "            hess_inv = res.hess_inv\n",
    "    \n",
    "    if succ_res is None:\n",
    "        print('No successful fits')\n",
    "    else:\n",
    "        print(succ_res)\n",
    "    \n",
    "    return a, b, hess_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8a9f6-5ed1-4e31-aaaa-f7ff38cbec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,4), tight_layout=True)\n",
    "\n",
    "################################################################################\n",
    "# Original data\n",
    "#-------------------------------------------------------------------------------\n",
    "print('Original')\n",
    "\n",
    "ax.errorbar(rmag[isrmeas], \n",
    "            log10vmax[isrmeas], \n",
    "            yerr=dlog10vmax[isrmeas], \n",
    "            fmt='ko', \n",
    "            alpha=0.7,\n",
    "            label='Abell 2151 data')\n",
    "\n",
    "a, b, _ = fit_tfr(rmag[isrmeas], log10vmax[isrmeas], dlog10vmax[isrmeas])\n",
    "print(a, b)\n",
    "\n",
    "r = np.arange(12.5,18.6,0.1)\n",
    "ax.plot(r, a + b*r, 'r--', alpha=0.7)\n",
    "################################################################################\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Cleaned data\n",
    "#-------------------------------------------------------------------------------\n",
    "'''\n",
    "print('\\nCleaned')\n",
    "\n",
    "rmag_clean = np.asarray(rmag_clean)\n",
    "vmax_clean = np.asarray(vmax_clean)\n",
    "dvmax_clean = np.asarray(dvmax_clean)\n",
    "\n",
    "isrmeas_clean = rmag_clean > 0\n",
    "\n",
    "log10vmax_clean = np.log10(vmax_clean)\n",
    "dlog10vmax_clean = 0.434 * dvmax_clean / vmax_clean \n",
    "\n",
    "ax.errorbar(rmag_clean[isrmeas_clean], \n",
    "            log10vmax_clean[isrmeas_clean], \n",
    "            yerr=dlog10vmax_clean[isrmeas_clean], \n",
    "            fmt='ro', \n",
    "            alpha=0.7,\n",
    "            label='Cleaned data, $\\cos{(i)}$-corrected')\n",
    "\n",
    "a, b, _ = fit_tfr(rmag_clean[isrmeas_clean], \n",
    "                  log10vmax_clean[isrmeas_clean], \n",
    "                  dlog10vmax_clean[isrmeas_clean])\n",
    "print(a, b)\n",
    "r = np.arange(12.5,18.6,0.1)\n",
    "ax.plot(r, a + b*r, 'r--', alpha=0.8)\n",
    "'''\n",
    "################################################################################\n",
    "\n",
    "\n",
    "ax.set(xlabel='$m_r$(26)',\n",
    "       xlim=(18.5, 12.5),\n",
    "       ylabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$',\n",
    "       ylim=(-0.5,3),\n",
    "       title=r'Rotational velocity of Abell 2151 in Daily Tiles')\n",
    "\n",
    "ax.legend(loc='lower right', fontsize=10);\n",
    "\n",
    "# fig.suptitle(r'Max velocity at $0.33\\times R_{26}$', y=1.05)\n",
    "# fig.subplots_adjust(top=0.8)\n",
    "#fig.savefig('tf_coma.png', dpi=120)\n",
    "\n",
    "# print(np.sum(isrmeas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1052563-f8af-4062-9a41-0daaafb901bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,5), tight_layout=True)\n",
    "\n",
    "rmag_clean = np.asarray(rmag_clean)\n",
    "vmax_clean = np.asarray(vmax_clean)\n",
    "dvmax_clean = np.asarray(dvmax_clean)\n",
    "\n",
    "isrmeas_clean = rmag_clean > 0\n",
    "\n",
    "log10vmax_clean = np.log10(vmax_clean)\n",
    "dlog10vmax_clean = 0.434 * dvmax_clean / vmax_clean\n",
    "\n",
    "r = np.arange(12.5,18.6,0.1)\n",
    "v = a + b*r\n",
    "\n",
    "################################################################################\n",
    "# Compute and plot the uncertainty range around the best fit\n",
    "#-------------------------------------------------------------------------------\n",
    "'''\n",
    "hessian = ndt.Hessian(l1norm)\n",
    "hess = hessian((a,b), \n",
    "               rmag_clean[isrmeas_clean], \n",
    "               log10vmax_clean[isrmeas_clean], \n",
    "               dlog10vmax_clean[isrmeas_clean])\n",
    "\n",
    "N_samples = 1000\n",
    "\n",
    "random_samples = np.random.multivariate_normal(mean=(a,b), \n",
    "                                               cov=np.linalg.inv(np.abs(hess)), #hess_inv.matmat(np.eye(2)), \n",
    "                                               size=N_samples)\n",
    "\n",
    "y_samples = np.zeros([1000, len(r)])\n",
    "for i in range(len(r)):\n",
    "    y_samples[:,i] = random_samples[:,0] + random_samples[:,1]*r[i]\n",
    "\n",
    "std_dev = np.std(y_samples, axis=0)\n",
    "\n",
    "ax.fill_betweenx(r, v-std_dev, v+std_dev, facecolor='lightgray')\n",
    "'''\n",
    "################################################################################\n",
    "\n",
    "ax.plot(v, r, 'k--', alpha=0.8)\n",
    "\n",
    "ax.errorbar(log10vmax[isrmeas], \n",
    "            rmag[isrmeas], \n",
    "            xerr=dlog10vmax[isrmeas], \n",
    "            fmt='ro', \n",
    "            alpha=0.7)\n",
    "\n",
    "ax.set(ylabel='$m_r$',\n",
    "       ylim=(18.5, 12.5),\n",
    "       xlabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$',\n",
    "       xlim=(1,3),\n",
    "       title='Rotational velocity for Abell 2151 Cluster');\n",
    "\n",
    "#plt.savefig('../Figures/PV_TFR_Coma_fitWOerrors_09262021.eps', format='eps', dpi=120);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62605e-6440-4aff-9a3a-636f73ca4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(log10vmax[isrmeas])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b94241b-fefc-4cd4-8743-8a0c3935d1de",
   "metadata": {},
   "source": [
    "#### Hyperfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba907cdd-a63e-46bc-81ed-5af014445e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2xN matrix.\n",
    "ndata = len(dlog10vmax[isrmeas])\n",
    "cov = np.empty((2, 2, ndata))\n",
    "\n",
    "# loop over arrays of uncertainties in logv and mag\n",
    "# Assume diagonal covariance for each measurement.\n",
    "for i, (dlogv, dm) in enumerate(zip(dlog10vmax[isrmeas], drmag[isrmeas])):\n",
    "    cov[:,:,i] = np.array([[dlogv**2, 0.], [0., dm**2]])\n",
    "                              \n",
    "# cov[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3bbbc-d17c-454c-8aba-3cb1aea74da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logv = log10vmax[isrmeas]\n",
    "mr = rmag[isrmeas]\n",
    "logv.shape, mr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01fe82e-5f54-4295-8bac-35b7efd3b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [logv, mr]\n",
    "cov1 = cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe5269-d555-4ede-8890-3fab6861f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = LinFit([logv, mr], cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf991a-c48a-42bc-82f6-9cdb651644f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an MCMC\n",
    "bounds = ((-10.0, 10.0), (-1000.0, 1000.0), (1.0e-5, 500.0))\n",
    "mcmc_samples, mcmc_lnlike = hf.emcee(bounds, verbose=True)\n",
    "print(np.mean(mcmc_samples, axis=1), np.std(mcmc_samples, axis=1))\n",
    "\n",
    "# # Make the plot\n",
    "# data.plot(linfit=hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787caea-c01b-4a91-8bb0-ba83c3f6404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, sig    = np.mean(mcmc_samples, axis=1)\n",
    "da, db, dsig = np.std(mcmc_samples, axis=1)\n",
    "\n",
    "for val, err in zip((a, b, sig), (da, db, dsig)):\n",
    "    print('{:6.2f} +/- {:.2f}'.format(val, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039fad31-fb0c-4b52-9b03-b00b48cafd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = hf.get_sigmas()\n",
    "xvals = np.linspace(0., 3., 1000)\n",
    "yvals = hf.coords[0] * xvals + hf.coords[1]\n",
    "\n",
    "# Get the MCMC 1-sigma quantiles to plot with the fit.\n",
    "y_chain = np.outer(xvals, mcmc_samples[0]) + mcmc_samples[1]\n",
    "y_chain_quantiles = np.quantile(y_chain, [0.1587, 0.8414], axis=1)\n",
    "\n",
    "# Pack info into data\n",
    "data = [log10vmax[isrmeas], rmag[isrmeas]]\n",
    "x_err = dlog10vmax[isrmeas]\n",
    "y_err = drmag[isrmeas]\n",
    "corr_xy = np.zeros_like(x_err)\n",
    "\n",
    "# Generate ellipses\n",
    "ells = [\n",
    "    Ellipse(\n",
    "        xy=[data[0][i], data[1][i]],\n",
    "        width=2.0 * y_err[i],\n",
    "        height=2.0 * x_err[i],\n",
    "        angle=np.rad2deg(np.arccos(corr_xy[i])),\n",
    "    )\n",
    "    for i in range(len(data[0]))\n",
    "]\n",
    "\n",
    "# Make the plot\n",
    "fig = plt.figure(figsize=(6,7))\n",
    "ax = fig.add_axes([0.15, 0.15, 1.03, 0.83])\n",
    "for i, e in enumerate(ells):\n",
    "    ax.add_artist(e)\n",
    "    e.set_color(cmo.cm.haline(sigmas[i] / np.amax(sigmas)))\n",
    "    e.set_edgecolor('None')\n",
    "    e.set_alpha(1)\n",
    "ax.fill_between(xvals, y_chain_quantiles[0], y_chain_quantiles[1], color=\"k\", alpha=0.15)\n",
    "ax.plot(xvals, yvals, c=\"k\", marker=\"None\", ls=\"-\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, yvals - hf.vert_scat, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=1)\n",
    "ax.plot(xvals, yvals + hf.vert_scat, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=1)\n",
    "ax.set_xlabel(r\"$\\log_{10}{(v_\\mathrm{0.4R_{26}} / \\mathrm{km~s^{-1}})}$\", fontsize=16)\n",
    "ax.set_ylabel(r\"$m_r$\", fontsize=16)\n",
    "ax.set_title(r\"Abell 2151\", fontsize=16)\n",
    "ax.set_xlim(1.25, 2.75)\n",
    "ax.set_ylim(18, 14.5)\n",
    "\n",
    "# Add the colourbar\n",
    "cb = fig.colorbar(\n",
    "    cm.ScalarMappable(norm=colors.Normalize(vmin=0.0, vmax=np.amax(sigmas)), cmap = cmo.cm.haline),\n",
    "    ax=ax,\n",
    "    shrink=0.5,\n",
    "    aspect=10,\n",
    "    anchor=(-8, 0.95),\n",
    ")\n",
    "cb.set_label(label=r\"$\\sigma$\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29cb0b-ee95-4db5-9a39-8f37b6445607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean as cmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4967a0-a1c0-4fe6-9e83-da0bcf10fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas1 = hf.get_sigmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffaf5b-d4ae-4876-882f-d6958625d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert1 = hf.vert_scat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1f648-60f1-480c-a835-1957932c8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0611c46-46c4-484a-979d-ca5c8afbe12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(mcmc_samples.T, bins=30, smooth=1,\n",
    "             range=[[-4, -12], [22, 40], [0.1, 1.3]],   # Range for a, b, sigma. Adjust as needed.\n",
    "             labels=['$a$', '$b$', r'$\\sigma$'],\n",
    "             levels=(1-np.exp(-0.5), 1-np.exp(-2)),\n",
    "             quantiles=[0.16, 0.5, 0.84],\n",
    "             color='blue',\n",
    "             hist_kwargs={'histtype':'stepfilled', 'alpha':0.3},\n",
    "             plot_datapoints=False,\n",
    "             fill_contours=True,\n",
    "             show_titles=True,\n",
    "             title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55113ffa-f263-4023-be68-e5ae7adebed5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Virgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb28454-e618-495e-ab28-dc42f8f5536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "virgo_nest = 100002\n",
    "\n",
    "virgo_row_t3 = table3['Nest'] == virgo_nest\n",
    "\n",
    "R2t_virgo = table3['R2t'][virgo_row_t3][0]\n",
    "sigma_virgo = table3['sigP'][virgo_row_t3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e4a5a-164f-4a8f-87d5-eed738607fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "virgo_coords = SkyCoord(table3['SGLON'][virgo_row_t3]*u.degree, \n",
    "                       table3['SGLAT'][virgo_row_t3]*u.degree, \n",
    "                       frame='supergalactic')\n",
    "\n",
    "v_group_coords = SkyCoord(table2['SGLON']*u.degree, \n",
    "                        table2['SGLAT']*u.degree, \n",
    "                        frame='supergalactic')\n",
    "\n",
    "idx, d2d, d3d = virgo_coords.match_to_catalog_sky(v_group_coords)\n",
    "\n",
    "V_virgo = table2['__HV_'][idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b538c-91f4-4186-813e-f061f8d89228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to convert R2t from Mpc to an angle, using the group's heliocentric velocity\n",
    "R2t_virgo_angle = (R2t_virgo/(V_virgo/H0))*u.radian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cfe76-846a-4d7e-b625-2e02158e3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tf_coords = SkyCoord(SGA_main['TARGET_RA'], SGA_main['TARGET_DEC'], unit='deg')\n",
    "\n",
    "vsep = virgo_coords.separation(v_tf_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc113fc1-bd4e-4cb0-82d6-0f81f4c0a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuji_in_virgo1 = (vsep < 1.5*R2t_virgo_angle) & (SGA_main['Z']*c > V_virgo - 3*sigma_virgo) & (SGA_main['Z']*c < V_virgo + 3*sigma_virgo)\n",
    "\n",
    "fuji_in_virgo2 = (vsep >= 1.5*R2t_virgo_angle) & (vsep < 3*R2t_virgo_angle) & (SGA_main['Z']*c > V_virgo - 2*sigma_virgo) & (SGA_main['Z']*c < V_virgo + 2*sigma_virgo)\n",
    "\n",
    "fuji_in_virgo = fuji_in_virgo1 | fuji_in_virgo2\n",
    "\n",
    "################################################################################\n",
    "# Keep all instances of each SGA_ID that are within the Coma cluster\n",
    "#-------------------------------------------------------------------------------\n",
    "fuji_ID_in_virgo = np.unique(SGA_main['SGA_ID_1'][fuji_in_virgo])\n",
    "\n",
    "idx_fuji_in_virgo = np.in1d(SGA_main['SGA_ID_1'], fuji_ID_in_virgo)\n",
    "\n",
    "inVirgo_fuji_table = SGA_main[idx_fuji_in_virgo]\n",
    "################################################################################\n",
    "\n",
    "inVirgo_fuji_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61ff13-d156-408b-882c-fc8f4f8c94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(vsep[fuji_in_virgo].to_value('degree'))\n",
    "plt.xlabel('MaNGA-NGC 4065 Angular Separation [deg]')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e82313-6a8f-485d-9da6-ea00538036d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,5), tight_layout=True)\n",
    "ax = axes[0]\n",
    "ax.plot(inVirgo_fuji_table['TARGET_DEC'], inVirgo_fuji_table['TARGET_RA'], '.')\n",
    "ax = axes[1]\n",
    "ax.hist(inVirgo_fuji_table['Z']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1e52b-ca77-411d-8c02-70079281bb66",
   "metadata": {},
   "source": [
    "#### Multiple Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345b1f7-db55-4b47-afcf-0aa1dfbf1ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids, counts = np.unique(inVirgo_fuji_table['SGA_ID_1'], return_counts=True)\n",
    "ids[counts > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4af87-3d3b-4a2b-861a-3d764d51401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,5), tight_layout=True)\n",
    "\n",
    "ax.hist(counts[counts > 1], bins=np.linspace(2,30,34))\n",
    "\n",
    "ax.set(xlabel='Observations per SGA_ID Virgo', \n",
    "       ylabel='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdab955-4a6b-49fb-9913-e33a3186fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only those with more than one observation\n",
    "high_count_sga = np.in1d(inVirgo_fuji_table['SGA_ID_1'], ids[counts > 1])\n",
    "tf_virgo_multiple = inVirgo_fuji_table[high_count_sga]\n",
    "tf_virgo_multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ceb4a3-9171-4214-8d5e-d879851e1349",
   "metadata": {},
   "source": [
    "#### Rotational Velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b9fb6-4a87-4dd7-894c-4f63fb0d6953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sga_ids_vel_cuts = []\n",
    "\n",
    "rmag = []\n",
    "drmag = []\n",
    "vmax = []\n",
    "dvmax = []\n",
    "\n",
    "for i, sga_id in enumerate(np.unique(inVirgo_fuji_table['SGA_ID_1'])):\n",
    "    # if sga_id == 474614:\n",
    "    #     print('skipped')\n",
    "    #     continue\n",
    "    galaxy_list = inVirgo_fuji_table[inVirgo_fuji_table['SGA_ID_1'] == sga_id]\n",
    "    # print\n",
    "    #print(i+1, sga_id)\n",
    "    \n",
    "    is_sga_galaxy = (galaxy_list['TARGETID'] > 30000000000000000) & (galaxy_list['TARGETID'] < 40000000000000000)\n",
    "    \n",
    "    sga_galaxy = galaxy_list[is_sga_galaxy]\n",
    "    tf_list = galaxy_list[~is_sga_galaxy]\n",
    "    \n",
    "    if np.sum(is_sga_galaxy) > 1:\n",
    "        sga_galaxy = sga_galaxy[0]\n",
    "    \n",
    "    targetid = int(sga_galaxy['TARGETID'])\n",
    "    center = SkyCoord(sga_galaxy['TARGET_RA'], sga_galaxy['TARGET_DEC'], unit='deg')\n",
    "    offcenter = SkyCoord(tf_list['TARGET_RA'], tf_list['TARGET_DEC'], unit='deg')\n",
    "    sep2d = offcenter.separation(center)\n",
    "    r26 = 0.5 * float(sga_galaxy['D26'])*u.arcmin\n",
    "    sep_r26 = sep2d.to('arcmin') / r26\n",
    "    \n",
    "    zc, zc_err = sga_galaxy['Z'], sga_galaxy['ZERR']\n",
    "    zt, zt_err = tf_list['Z'], tf_list['ZERR']\n",
    "    \n",
    "    dz = np.abs(zt - zc)\n",
    "    dz_err = np.sqrt(zc_err**2 + zt_err**2)\n",
    "    \n",
    "    dv = c * dz\n",
    "    dv_err = c * dz_err\n",
    "    \n",
    "    good_vel = dv < 5000\n",
    "    # print(good_vel[0], sga_id)\n",
    "    \n",
    "    if np.sum(good_vel) > 0:\n",
    "        sep_r26 = np.insert(sep_r26[good_vel], 0, 0.)\n",
    "        dv = np.insert(dv[good_vel], 0, 0.)\n",
    "        dv_err = np.insert(dv_err[good_vel], 0, 3e5*zc_err)\n",
    "\n",
    "        # Extract the 0.33xR26 points.\n",
    "        is_033_r26 = (sep_r26 > 0.35) & (sep_r26 < 0.45)\n",
    "        if np.sum(is_033_r26) > 0:\n",
    "            v033 = np.mean(dv[is_033_r26])\n",
    "            dv033 = np.sqrt(np.sum(dv_err[is_033_r26]**2))\n",
    "\n",
    "            rmag.append(float(sga_galaxy['R_MAG_SB26']))\n",
    "            drmag.append(float(sga_galaxy['R_MAG_SB26_ERR']))\n",
    "            vmax.append(v033)\n",
    "            dvmax.append(dv033)\n",
    "            sga_ids_vel_cuts.append(sga_id)\n",
    "    # break\n",
    "#print('mag:', rmag)\n",
    "#print('vel:', vmax)\n",
    "#print('dv:', dvmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a0c7c-949b-4173-a395-2e59dc7d0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmag = np.asarray(rmag)\n",
    "drmag = np.asarray(drmag)\n",
    "vmax = np.asarray(vmax)\n",
    "dvmax = np.asarray(dvmax)\n",
    "\n",
    "isrmeas = rmag > 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,4), tight_layout=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.errorbar(rmag[isrmeas], vmax[isrmeas], xerr=drmag[isrmeas], yerr=dvmax[isrmeas], fmt='ro')\n",
    "ax.set(xlabel='$m_r$(26)',\n",
    "       xlim=(18.5, 12.5),\n",
    "       ylim=(-50,300),\n",
    "       ylabel='$v_\\mathrm{max}$ [km s$^{-1}$]')\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "log10vmax = np.log10(vmax)\n",
    "dlog10vmax = 0.434 * dvmax / vmax \n",
    "\n",
    "ax.errorbar(rmag[isrmeas], log10vmax[isrmeas], yerr=dlog10vmax[isrmeas], fmt='ro')\n",
    "ax.set(xlabel='$m_r$(26)',\n",
    "       xlim=(18.5, 12.5),\n",
    "       ylabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$',\n",
    "       ylim=(-0.5,3))\n",
    "\n",
    "fig.suptitle(r'Rotational velocity at $0.4R_{26}$ for Virgo', y=1.05)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "print(np.sum(isrmeas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80a5dd-7673-48cd-9084-bb9cc7ea7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "sga_ids_clean = []\n",
    "\n",
    "rmag_clean = []\n",
    "drmag_clean = []\n",
    "vmax_clean = []\n",
    "dvmax_clean = []\n",
    "z = []\n",
    "\n",
    "inc_min = 45*u.degree\n",
    "cosi_max = np.cos(inc_min.to('radian'))\n",
    "\n",
    "inVirgo_fuji_table['cosi'] = np.sqrt((inVirgo_fuji_table['BA']**2 - q0**2)/(1 - q0**2))\n",
    "inVirgo_fuji_table['cosi'][np.isnan(inVirgo_fuji_table['cosi'])] = 0 # Objects with b/a < 0.2\n",
    "\n",
    "#i = 0\n",
    "\n",
    "# for sga_id in np.unique(inComa_sga_table['SGA_ID']):\n",
    "for sga_id in sga_ids_vel_cuts:\n",
    "    galaxy_list = inVirgo_fuji_table[inVirgo_fuji_table['SGA_ID_1'] == sga_id]\n",
    "    \n",
    "    is_sga_galaxy = (galaxy_list['TARGETID'] > 30000000000000000) & (galaxy_list['TARGETID'] < 40000000000000000)\n",
    "    sga_galaxy = galaxy_list[is_sga_galaxy]\n",
    "    tf_list = galaxy_list[~is_sga_galaxy]\n",
    "    \n",
    "    if np.sum(is_sga_galaxy) > 1:\n",
    "        sga_galaxy = sga_galaxy[0]\n",
    "    \n",
    "    targetid = int(sga_galaxy['TARGETID'])\n",
    "    \n",
    "    center = SkyCoord(sga_galaxy['TARGET_RA'], sga_galaxy['TARGET_DEC'], unit='deg')\n",
    "    offcenter = SkyCoord(tf_list['TARGET_RA'], tf_list['TARGET_DEC'], unit='deg')\n",
    "    sep2d = offcenter.separation(center)\n",
    "    \n",
    "    morphtype = str(sga_galaxy['MORPHTYPE'])\n",
    "    \n",
    "    cosi = float(sga_galaxy['cosi'])\n",
    "    \n",
    "    r26 = 0.5 * float(sga_galaxy['D26']) * u.arcmin\n",
    "    sep_r26 = sep2d.to('arcmin') / r26\n",
    "\n",
    "    # Cut any suspected ellipticals\n",
    "    if morphtype.startswith('E') or morphtype.startswith('S0') or morphtype.startswith('I'):\n",
    "        continue\n",
    "               \n",
    "    # Inclination cut\n",
    "    if cosi > cosi_max:\n",
    "        continue\n",
    "        \n",
    "    #i += 1\n",
    "    #print(i, sga_id, cosi)\n",
    "    \n",
    "    zc, zc_err = float(sga_galaxy['Z']), float(sga_galaxy['ZERR'])\n",
    "    zt, zt_err = tf_list['Z'], tf_list['ZERR']\n",
    "    \n",
    "    dz = np.abs(zt - zc)\n",
    "    dz_err = np.sqrt(zc_err**2 + zt_err**2)\n",
    "    \n",
    "    dv = 3e5 * dz\n",
    "    dv_err = 3e5 * dz_err\n",
    "    \n",
    "    good_vel = dv < 5000\n",
    "    \n",
    "    if np.sum(good_vel) > 0:\n",
    "    \n",
    "        sep_r26 = np.insert(sep_r26[good_vel], 0, 0.)\n",
    "        dv = np.insert(dv[good_vel], 0, 0.)\n",
    "        dv_err = np.insert(dv_err[good_vel], 0, 3e5*zc_err)\n",
    "\n",
    "        # Extract the 0.33xR26 points.\n",
    "        is_033_r26 = (sep_r26 > 0.35) & (sep_r26 < 0.45)\n",
    "        \n",
    "        if np.sum(is_033_r26) > 0:\n",
    "            v033 = np.mean(dv[is_033_r26]) / np.sqrt(1 - cosi**2)\n",
    "            dv033 = np.sqrt(np.sum(dv_err[is_033_r26]**2)) / np.sqrt(1 - cosi**2)\n",
    "            z.append(zc)\n",
    "            rmag_clean.append(float(sga_galaxy['R_MAG_SB26']))\n",
    "            drmag_clean.append(float(sga_galaxy['R_MAG_SB26_ERR']))\n",
    "            vmax_clean.append(v033)\n",
    "            dvmax_clean.append(dv033)\n",
    "            sga_ids_clean.append(sga_id)\n",
    "    \n",
    "#inComa_sga_table[['SGA_ID', 'BA', 'cosi']].show_in_notebook()\n",
    "print(len(rmag_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42bd18-de9e-4b31-98ce-3a247bc069ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,4), tight_layout=True)\n",
    "\n",
    "################################################################################\n",
    "# Original data\n",
    "#-------------------------------------------------------------------------------\n",
    "print('Original')\n",
    "\n",
    "ax.errorbar(rmag[isrmeas], \n",
    "            log10vmax[isrmeas], \n",
    "            yerr=dlog10vmax[isrmeas], \n",
    "            fmt='ko', \n",
    "            alpha=0.7,\n",
    "            label='Abell 2151 data')\n",
    "\n",
    "a, b, _ = fit_tfr(rmag[isrmeas], log10vmax[isrmeas], dlog10vmax[isrmeas])\n",
    "print(a, b)\n",
    "\n",
    "r = np.arange(12.5,18.6,0.1)\n",
    "ax.plot(r, a + b*r, 'r--', alpha=0.7)\n",
    "################################################################################\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Cleaned data\n",
    "#-------------------------------------------------------------------------------\n",
    "'''\n",
    "print('\\nCleaned')\n",
    "\n",
    "rmag_clean = np.asarray(rmag_clean)\n",
    "vmax_clean = np.asarray(vmax_clean)\n",
    "dvmax_clean = np.asarray(dvmax_clean)\n",
    "\n",
    "isrmeas_clean = rmag_clean > 0\n",
    "\n",
    "log10vmax_clean = np.log10(vmax_clean)\n",
    "dlog10vmax_clean = 0.434 * dvmax_clean / vmax_clean \n",
    "\n",
    "ax.errorbar(rmag_clean[isrmeas_clean], \n",
    "            log10vmax_clean[isrmeas_clean], \n",
    "            yerr=dlog10vmax_clean[isrmeas_clean], \n",
    "            fmt='ro', \n",
    "            alpha=0.7,\n",
    "            label='Cleaned data, $\\cos{(i)}$-corrected')\n",
    "\n",
    "a, b, _ = fit_tfr(rmag_clean[isrmeas_clean], \n",
    "                  log10vmax_clean[isrmeas_clean], \n",
    "                  dlog10vmax_clean[isrmeas_clean])\n",
    "print(a, b)\n",
    "r = np.arange(12.5,18.6,0.1)\n",
    "ax.plot(r, a + b*r, 'r--', alpha=0.8)\n",
    "'''\n",
    "################################################################################\n",
    "\n",
    "\n",
    "ax.set(xlabel='$m_r$(26)',\n",
    "       xlim=(18.5, 12.5),\n",
    "       ylabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$',\n",
    "       ylim=(-0.5,3),\n",
    "       title=r'Rotational velocity of Virgo in Daily Tiles')\n",
    "\n",
    "ax.legend(loc='lower right', fontsize=10);\n",
    "\n",
    "# fig.suptitle(r'Max velocity at $0.33\\times R_{26}$', y=1.05)\n",
    "# fig.subplots_adjust(top=0.8)\n",
    "#fig.savefig('tf_coma.png', dpi=120)\n",
    "\n",
    "# print(np.sum(isrmeas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db87f7-e6de-4e76-9487-bd65ca4e4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,5), tight_layout=True)\n",
    "\n",
    "rmag_clean = np.asarray(rmag_clean)\n",
    "vmax_clean = np.asarray(vmax_clean)\n",
    "dvmax_clean = np.asarray(dvmax_clean)\n",
    "\n",
    "isrmeas_clean = rmag_clean > 0\n",
    "\n",
    "log10vmax_clean = np.log10(vmax_clean)\n",
    "dlog10vmax_clean = 0.434 * dvmax_clean / vmax_clean\n",
    "\n",
    "r = np.arange(12.5,18.6,0.1)\n",
    "v = a + b*r\n",
    "\n",
    "################################################################################\n",
    "# Compute and plot the uncertainty range around the best fit\n",
    "#-------------------------------------------------------------------------------\n",
    "'''\n",
    "hessian = ndt.Hessian(l1norm)\n",
    "hess = hessian((a,b), \n",
    "               rmag_clean[isrmeas_clean], \n",
    "               log10vmax_clean[isrmeas_clean], \n",
    "               dlog10vmax_clean[isrmeas_clean])\n",
    "\n",
    "N_samples = 1000\n",
    "\n",
    "random_samples = np.random.multivariate_normal(mean=(a,b), \n",
    "                                               cov=np.linalg.inv(np.abs(hess)), #hess_inv.matmat(np.eye(2)), \n",
    "                                               size=N_samples)\n",
    "\n",
    "y_samples = np.zeros([1000, len(r)])\n",
    "for i in range(len(r)):\n",
    "    y_samples[:,i] = random_samples[:,0] + random_samples[:,1]*r[i]\n",
    "\n",
    "std_dev = np.std(y_samples, axis=0)\n",
    "\n",
    "ax.fill_betweenx(r, v-std_dev, v+std_dev, facecolor='lightgray')\n",
    "'''\n",
    "################################################################################\n",
    "\n",
    "ax.plot(v, r, 'k--', alpha=0.8)\n",
    "\n",
    "ax.errorbar(log10vmax[isrmeas], \n",
    "            rmag[isrmeas], \n",
    "            xerr=dlog10vmax[isrmeas], \n",
    "            fmt='ro', \n",
    "            alpha=0.7)\n",
    "\n",
    "ax.set(ylabel='$m_r$',\n",
    "       ylim=(18.5, 12.5),\n",
    "       xlabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$',\n",
    "       xlim=(1,3),\n",
    "       title='Rotational velocity for Abell 2151 Cluster');\n",
    "\n",
    "#plt.savefig('../Figures/PV_TFR_Coma_fitWOerrors_09262021.eps', format='eps', dpi=120);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199994b-cb7b-4883-a844-4992d63dcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(log10vmax[isrmeas])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37295b9f-54e6-47fd-8562-1ccba045a196",
   "metadata": {},
   "source": [
    "#### Hyperfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4872bb-784d-4753-af51-18f21da451b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2xN matrix.\n",
    "ndata = len(dlog10vmax[isrmeas])\n",
    "cov = np.empty((2, 2, ndata))\n",
    "\n",
    "# loop over arrays of uncertainties in logv and mag\n",
    "# Assume diagonal covariance for each measurement.\n",
    "for i, (dlogv, dm) in enumerate(zip(dlog10vmax[isrmeas], drmag[isrmeas])):\n",
    "    cov[:,:,i] = np.array([[dlogv**2, 0.], [0., dm**2]])\n",
    "                              \n",
    "# cov[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06896a58-ac19-4787-94e8-fba790ded7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logv = log10vmax[isrmeas]\n",
    "mr = rmag[isrmeas]\n",
    "logv.shape, mr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b0bd7-1229-4b7b-b4f3-2be084746599",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [logv, mr]\n",
    "cov2 = cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba6a69-1650-44cb-a6d7-86bd00064147",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = LinFit([logv, mr], cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa34022-9d98-4db4-bfd8-be4c28350e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe822c5-115a-4a40-82a4-154d6532b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an MCMC\n",
    "bounds = ((-6.0, 6.0), (-1000.0, 1000.0), (1.0e-5, 500.0))\n",
    "mcmc_samples, mcmc_lnlike = hf.emcee(bounds, verbose=True)\n",
    "print(np.mean(mcmc_samples, axis=1), np.std(mcmc_samples, axis=1))\n",
    "\n",
    "# # Make the plot\n",
    "# data.plot(linfit=hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68f870-18a5-4903-9389-6c541830b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, sig    = np.mean(mcmc_samples, axis=1)\n",
    "da, db, dsig = np.std(mcmc_samples, axis=1)\n",
    "\n",
    "for val, err in zip((a, b, sig), (da, db, dsig)):\n",
    "    print('{:6.2f} +/- {:.2f}'.format(val, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76073c85-d6e6-48d8-a658-91622c0c85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = hf.get_sigmas()\n",
    "xvals = np.linspace(0., 3., 1000)\n",
    "yvals = hf.coords[0] * xvals + hf.coords[1]\n",
    "\n",
    "# Get the MCMC 1-sigma quantiles to plot with the fit.\n",
    "y_chain = np.outer(xvals, mcmc_samples[0]) + mcmc_samples[1]\n",
    "y_chain_quantiles = np.quantile(y_chain, [0.1587, 0.8414], axis=1)\n",
    "\n",
    "# Pack info into data\n",
    "data = [log10vmax[isrmeas], rmag[isrmeas]]\n",
    "x_err = dlog10vmax[isrmeas]\n",
    "y_err = drmag[isrmeas]\n",
    "corr_xy = np.zeros_like(x_err)\n",
    "\n",
    "# Generate ellipses\n",
    "ells = [\n",
    "    Ellipse(\n",
    "        xy=[data[0][i], data[1][i]],\n",
    "        width=2.0 * y_err[i],\n",
    "        height=2.0 * x_err[i],\n",
    "        angle=np.rad2deg(np.arccos(corr_xy[i])),\n",
    "    )\n",
    "    for i in range(len(data[0]))\n",
    "]\n",
    "\n",
    "# Make the plot\n",
    "fig = plt.figure(figsize=(6,7))\n",
    "ax = fig.add_axes([0.15, 0.15, 1.03, 0.83])\n",
    "for i, e in enumerate(ells):\n",
    "    ax.add_artist(e)\n",
    "    e.set_color(cmo.cm.haline(sigmas[i] / np.amax(sigmas)))\n",
    "    e.set_edgecolor('None')\n",
    "    e.set_alpha(0.9)\n",
    "ax.fill_between(xvals, y_chain_quantiles[0], y_chain_quantiles[1], color=\"k\", alpha=0.2)\n",
    "ax.plot(xvals, yvals, c=\"k\", marker=\"None\", ls=\"-\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, yvals - hf.vert_scat, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, yvals + hf.vert_scat, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.set_xlabel(r\"$\\log_{10}{(v_\\mathrm{0.4R_{26}} / \\mathrm{km~s^{-1}})}$\", fontsize=16)\n",
    "ax.set_ylabel(r\"$m_r$\", fontsize=16)\n",
    "ax.set_title(r\"Virgo\", fontsize=16)\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(18, 12)\n",
    "\n",
    "# Add the colourbar\n",
    "cb = fig.colorbar(\n",
    "    cm.ScalarMappable(norm=colors.Normalize(vmin=0.0, vmax=np.amax(sigmas)), cmap = cmo.cm.haline),\n",
    "    ax=ax,\n",
    "    shrink=0.5,\n",
    "    aspect=10,\n",
    "    anchor=(-8, 0.95),\n",
    ")\n",
    "cb.set_label(label=r\"$\\sigma$\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f98e07a-5e92-4668-9c66-f4607bc7ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2 = hf.get_sigmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661faa3-1fa1-4c70-aee3-3e1e7e654e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert2 = hf.vert_scat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0777cdb-233c-44ee-8793-e4277eb02408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fc092-22f3-45b3-b2a8-677fea10f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(mcmc_samples.T, bins=30, smooth=1,\n",
    "             range=[[-1, -9], [16, 31], [0.2, 2.5]],   # Range for a, b, sigma. Adjust as needed.\n",
    "             labels=['$a$', '$b$', r'$\\sigma$'],\n",
    "             levels=(1-np.exp(-0.5), 1-np.exp(-2)),\n",
    "             quantiles=[0.16, 0.5, 0.84],\n",
    "             color='blue',\n",
    "             hist_kwargs={'histtype':'stepfilled', 'alpha':0.3},\n",
    "             plot_datapoints=False,\n",
    "             fill_contours=True,\n",
    "             show_titles=True,\n",
    "             title = {'Coma'},\n",
    "             title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23e7eb-dca4-4aab-ba45-030349e2d7c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Abell 2151 and Virgo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3d2e3-4eec-4179-8bec-bdd9f865be69",
   "metadata": {},
   "source": [
    "#### Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f2cd0-1ecb-4839-92da-92431d210880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(params, data1, data2, cov1, cov2):\n",
    "    \"\"\"Chi-square function for joint slope fit to two data sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data1 : ndarray\n",
    "        2xN array of [x1, y1] for data set 1.\n",
    "    data2 : ndarray\n",
    "        2xM array of [x2, y2] for data set 2.\n",
    "    cov1 : ndarray\n",
    "        2x2xN covariances for data set 1.\n",
    "    cov2 : ndarray\n",
    "        2x2xM covariances for data set 2.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    chi2 : float\n",
    "        Sum of chi-square fits to data sets 1 and 2.\n",
    "    \"\"\"\n",
    "    a, b1, b2 = params\n",
    "    \n",
    "    x1, y1 = data1[0], data1[1]\n",
    "    varx1, vary1 = cov1[0,0], cov1[1,1]\n",
    "    chi2_1 = np.sum((y1 - a*x1 - b1)**2 / (vary1 + a**2*varx1))\n",
    "    \n",
    "    x2, y2 = data2[0], data2[1]\n",
    "    varx2, vary2 = cov2[0,0], cov2[1,1]\n",
    "    chi2_2 = np.sum((y2 - a*x2 - b2)**2 / (vary2 + a**2*varx2))\n",
    "    \n",
    "    return chi2_1 + chi2_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e3fe6-0822-410f-bf54-b2b16caa816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = [-6, 31, 22]\n",
    "res = minimize(chi2, p0, args=(data1, data2, cov1, cov2), method='BFGS')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809d808-9a8a-4dc4-a74c-6704cb408346",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_, b1_, b2_ = res.x\n",
    "da_, db1_, db2_ = [np.sqrt(res.hess_inv[i,i]) for i in range(3)]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,5))\n",
    "ax.invert_xaxis()\n",
    "eb1 = ax.errorbar(data1[0], data1[1], xerr=np.sqrt(cov1[0,0]), yerr=np.sqrt(cov1[1,1]), fmt='.')\n",
    "ax.plot(data1[0], a_*data1[0] + b1_, color=eb1[0].get_color(),\n",
    "        label=r'$\\hat{{a}}={:.2f}\\pm{:.2f}$, $\\hat{{b}}_1={:.2f}\\pm{:.2f}$'.format(a_, da_, b1_, db1_))\n",
    "\n",
    "eb2 = ax.errorbar(data2[0], data2[1], xerr=np.sqrt(cov2[0,0]), yerr=np.sqrt(cov2[1,1]), fmt='.')\n",
    "ax.plot(data2[0], a_*data2[0] + b2_, color=eb2[0].get_color(),\n",
    "        label=r'$\\hat{{a}}={:.2f}\\pm{:.2f}$, $\\hat{{b}}_1={:.2f}\\pm{:.2f}$'.format(a_, da_, b2_, db2_))\n",
    "\n",
    "ax.set(xlabel='$x$', ylabel='$y$',\n",
    "       title='$a={:g}$, $b_1={:g}$, $b_2={:g}$'.format(a_, b1_, b2_))\n",
    "ax.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5075b70-92c2-42fe-9d4a-dc82ca7344b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### LinFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc3e1d-fab9-431c-8a19-7d08535ebf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, differential_evolution\n",
    "import emcee\n",
    "from hyperfit.linfit import LinFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad2487-c9c0-4680-8b01-4847b12b40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlogl(params, datasets, covs):\n",
    "    \"\"\"Chi-square function for joint slope fit to two or more data sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list or ndarray\n",
    "        m x 2xN array of [x1, y1] for each data set.\n",
    "    cov : ndarray\n",
    "        m x 2x2xN covariances for each data set.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    chi2 : float\n",
    "        Sum of chi-square fits to data sets 1 and 2.\n",
    "    \"\"\"\n",
    "    nsets = len(datasets)\n",
    "    a = params[0]\n",
    "    b = params[1:nsets+1]\n",
    "    sigma = params[nsets+1:]\n",
    "    \n",
    "    nloglike = 0.\n",
    "    for i in range(nsets): \n",
    "        data = datasets[i]\n",
    "        cov = covs[i]\n",
    "        x, dx2 = data[0], cov[0,0]\n",
    "        y, dy2 = data[1], cov[1,1]\n",
    "        dxy = cov[0,1]\n",
    "        sy2 = sigma[i]**2 + a**2*dx2 + dy2 - 2*dxy*a\n",
    "        nloglike += -0.5*np.sum(np.log((a**2 + 1)/sy2) - (a*x - y + b[i])**2/sy2)\n",
    "    \n",
    "    return nloglike\n",
    "\n",
    "# Minimization.\n",
    "print('Differential evolution:')\n",
    "bounds = [[-10., 10.], [-6., 6.], [-5., 5.], [0, 1], [0, 2]]\n",
    "res = differential_evolution(nlogl, bounds, args=([data1, data2], [cov1, cov2]))\n",
    "print(res)\n",
    "\n",
    "# Initial guesses\n",
    "slope = -6\n",
    "intercepts = [31, 22]\n",
    "sigmas = [0.2, 0.3]\n",
    "p0 = [slope] + intercepts + sigmas\n",
    "\n",
    "print('\\n\\nBFGS minimization:')\n",
    "res = minimize(nlogl, p0, args=([data1, data2], [cov1, cov2]), method='BFGS')\n",
    "print(res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a3c56-9a3e-4186-9a0f-b89236d03a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_, b1_, b2_, sig1_, sig2_ = res.x\n",
    "da_, db1_, db2_ = [np.sqrt(res.hess_inv[i,i]) for i in range(3)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,8))\n",
    "ax.invert_xaxis()\n",
    "eb1 = ax.errorbar(data1[0], data1[1], xerr=np.sqrt(cov1[0,0]), yerr=np.sqrt(cov1[1,1]), fmt='.')\n",
    "x_ = np.linspace(np.min(data1[0]), np.max(data1[0]))\n",
    "ax.plot(x_, a_*x_ + b1_, color=eb1[0].get_color(),\n",
    "        label=r'Abell 2151: $\\hat{{a}}={:.2f}\\pm{:.2f}$, $\\hat{{b}}_1={:.2f}\\pm{:.2f}$'.format(a_, da_, b1_, db1_))\n",
    "ax.plot(x_, a_*x_ + b1_ + sig1_, ls=':', color=eb1[0].get_color())\n",
    "ax.plot(x_, a_*x_ + b1_ - sig1_, ls=':', color=eb1[0].get_color())\n",
    "\n",
    "eb2 = ax.errorbar(data2[0], data2[1], xerr=np.sqrt(cov2[0,0]), yerr=np.sqrt(cov2[1,1]), fmt='.')\n",
    "\n",
    "x_ = np.linspace(np.min(data2[0]), np.max(data2[0]))\n",
    "ax.plot(data2[0], a_*data2[0] + b2_, color=eb2[0].get_color(),\n",
    "        label=r'Virgo: $\\hat{{a}}={:.2f}\\pm{:.2f}$, $\\hat{{b}}_1={:.2f}\\pm{:.2f}$'.format(a_, da_, b2_, db2_))\n",
    "ax.plot(x_, a_*x_ + b2_ + sig2_, ls=':', color=eb2[0].get_color())\n",
    "ax.plot(x_, a_*x_ + b2_ - sig2_, ls=':', color=eb2[0].get_color())\n",
    "ax.set_ylabel(r\"$m_r$\", fontsize = 15.0)\n",
    "ax.set_xlabel(r\"$\\log_{10}{(v_\\mathrm{0.4R_{26}} / \\mathrm{km~s^{-1}})}$\", fontsize= 15.0)\n",
    "ax.set_title('Virgo and Abell 2151', fontsize = 15.0)\n",
    "\n",
    "#ax.set(xlabel=r\"$\\log_{10}{(v_\\mathrm{0.4R_{26}} / \\mathrm{km~s^{-1}})}$\", ylabel=r\"$m_r$\",\n",
    "       #title='Virgo and Abell 2151', fontsize = 20.0)\n",
    "ax.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708a208-6181-456b-8cc2-b3798871d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLinFit:\n",
    "    \n",
    "    def __init__(self, datasets, covs, weights=None, vertaxis=-1):\n",
    "        \n",
    "        self.nsets = len(datasets)\n",
    "        self.ndims = np.shape(datasets[0])[0]\n",
    "        self.ndata = [np.shape(data)[1] for data in datasets]\n",
    "        self.datasets = datasets\n",
    "        self.covs = covs\n",
    "        self.data = None\n",
    "        self.cov = None\n",
    "        \n",
    "        self.npars = 1 + self.nsets # slope + intercepts + sigmas\n",
    "        self.params = np.zeros(self.npars)\n",
    "        self.params_scatter = np.zeros(self.nsets)\n",
    "        \n",
    "        self.weights = [np.ones(n) for n in self.ndata] if weights is None else weights\n",
    "        self.vertaxis = vertaxis\n",
    "        \n",
    "        self.param_bounds = None      # parameter fit bounds for all data sets\n",
    "        \n",
    "    def _lnpost(self, params):\n",
    "        lnpost = 0.\n",
    "\n",
    "        for i in range(self.nsets):\n",
    "            # Loop over individual data sets. \n",
    "            self.data = self.datasets[i]\n",
    "            self.cov  = self.covs[i]\n",
    "            \n",
    "            # Set up parameter and bounds arrays for each data set.\n",
    "            pars_i = np.array([params[0]] + [params[1+i]] + [params[self.nsets+1+i]])\n",
    "            bounds_i = [self.param_bounds[0]] + \\\n",
    "                       [self.param_bounds[1+i]] + \\\n",
    "                       [self.param_bounds[self.nsets+1+i]]\n",
    "\n",
    "            # Set up weights for each data set.\n",
    "            weights = self.weights[i]\n",
    "            \n",
    "            # Sum over all data sets.\n",
    "            lnprior = self._lnprior(pars_i, bounds_i)\n",
    "            lnlike = self._lnlike(pars_i)                \n",
    "            lnpost += np.sum(weights * lnlike) + lnprior\n",
    "        \n",
    "        return lnpost\n",
    "                    \n",
    "    def _lnprior(self, params, bounds):\n",
    "        lnprior = 0.\n",
    "        for i, (param, bound) in enumerate(zip(params.T, bounds)):\n",
    "            lnprior += np.where(np.logical_or(param < bound[0], param > bound[1]), -np.inf, 0.0)\n",
    "\n",
    "        return lnprior\n",
    "    \n",
    "    def _lnlike(self, params):\n",
    "        a, b, sigma = params\n",
    "\n",
    "        x, dx2 = self.data[0], self.cov[0,0]\n",
    "        y, dy2 = self.data[1], self.cov[1,1]\n",
    "        dxy = self.cov[0,1]\n",
    "        sy2 = sigma**2 + a**2*dx2 + dy2 - 2*dxy*a\n",
    "        lnlike = 0.5*np.sum(np.log((a**2 + 1)/sy2) - (a*x - y + b)**2/sy2)\n",
    "\n",
    "        return lnlike\n",
    "    \n",
    "    def optimize(self, bounds, tol=1e-6, verbose=False):\n",
    "        self.param_bounds = bounds\n",
    "        res = differential_evolution(lambda *args: -self._lnpost(*args), self.param_bounds, tol=tol)\n",
    "\n",
    "        if verbose:\n",
    "            print(res)\n",
    "            \n",
    "        self.params = res.x[:-self.nsets]\n",
    "        self.params_scatter = np.fabs(res.x[-self.nsets:])\n",
    "        return self.params, self.params_scatter, res.fun\n",
    "    \n",
    "    def emcee(self, bounds, max_iter=100000, batchsize=1000, ntau=50.0, tautol=0.05, verbose=False):\n",
    "\n",
    "        # Set up emcee. Start the walkers in a small 1 percent ball around the best fit.\n",
    "        # The best fit will set self.params and self.params_scatter.\n",
    "        self.optimize(bounds, verbose=verbose)\n",
    "        ndim = len(self.params) + len(self.params_scatter)\n",
    "        nwalker = 4 * ndim\n",
    "        seeds = np.asarray([\n",
    "            [(0.01 * np.random.rand() + 0.995) * j for j in np.concatenate([self.params, self.params_scatter])]\n",
    "            for _ in range(nwalker)\n",
    "        ])\n",
    "\n",
    "        sampler = emcee.EnsembleSampler(nwalker, ndim, self._lnpost)\n",
    "\n",
    "        old_tau = np.inf\n",
    "        niter = 0\n",
    "        converged = 0\n",
    "        while ~converged:\n",
    "            sampler.run_mcmc(seeds, nsteps=batchsize, progress=verbose)\n",
    "            tau = sampler.get_autocorr_time(discard=int(0.5 * niter), tol=0)\n",
    "            converged = np.all(ntau * tau < niter)\n",
    "            converged &= np.all(np.abs(old_tau - tau) / tau < tautol)\n",
    "            old_tau = tau\n",
    "            begin = None\n",
    "            niter += 1000\n",
    "            if verbose:\n",
    "                print(\"Niterations/Max Iterations: \", niter, \"/\", max_iter)\n",
    "                print(\"Integrated ACT/Min Convergence Iterations: \", tau, \"/\", np.amax(ntau * tau))\n",
    "            if niter >= max_iter:\n",
    "                break\n",
    "\n",
    "        # Remove burn-in and and save the samples\n",
    "        tau = sampler.get_autocorr_time(discard=int(0.5 * niter), tol=0)\n",
    "        burnin = int(2 * np.max(tau))\n",
    "        samples = sampler.get_chain(discard=burnin, flat=True).T\n",
    "        mcmc_samples = samples\n",
    "        mcmc_lnlike = sampler.get_log_prob(discard=burnin, flat=True)\n",
    "\n",
    "        return mcmc_samples, mcmc_lnlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18ace7-aa9c-4ec2-9a25-74d25340e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MultiLinFit([data1, data2], [cov1, cov2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb0c9c-18e6-4093-86ed-1982df101016",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [[-10., 10.], [-10., 10.], [-10., 10.], [0., 2.], [0., 2.]]\n",
    "mlf.optimize(bounds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc5a02-8f88-4c7c-8be8-b55fa0e8d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an MCMC\n",
    "bounds = [[-10., 10.], [-10., 40.], [-10., 30.], [0., 2.], [0., 2.]]\n",
    "mcmc_samples, mcmc_lnlike = mlf.emcee(bounds, max_iter=10000, verbose=True)\n",
    "print(np.mean(mcmc_samples, axis=1), np.std(mcmc_samples, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee9bb1-637e-4f36-84ab-7d3b455e45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b1, b2, sig1, sig2    = np.mean(mcmc_samples, axis=1)\n",
    "da, db1, db2, dsig1, dsig2 = np.std(mcmc_samples, axis=1)\n",
    "\n",
    "for val, err in zip((a, b1, b2, sig1, sig2), (da, db1, db2, dsig1, dsig2)):\n",
    "    print('{:6.2f} +/- {:.2f}'.format(val, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7127fcf-faa3-42cb-867b-8969dd4b2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.linspace(0., 3., 1000)\n",
    "yvals1 = a * xvals + b1\n",
    "yvals2 = a * xvals + b2\n",
    "\n",
    "# Get the MCMC 1-sigma quantiles to plot with the fit.\n",
    "y_chain1 = np.outer(xvals, mcmc_samples[0]) + mcmc_samples[1]\n",
    "y_chain_quantiles1 = np.quantile(y_chain1, [0.1587, 0.8414], axis=1)\n",
    "\n",
    "y_chain2 = np.outer(xvals, mcmc_samples[0]) + mcmc_samples[2]\n",
    "y_chain_quantiles2 = np.quantile(y_chain2, [0.1587, 0.8414], axis=1)\n",
    "\n",
    "# Pack info into data\n",
    "x_err1 = np.sqrt(cov1[0][0])\n",
    "y_err1 = np.sqrt(cov2[1][1])\n",
    "corr_xy1 = np.zeros_like(x_err1)\n",
    "\n",
    "x_err2 = np.sqrt(cov2[0][0])\n",
    "y_err2 = np.sqrt(cov2[1][1])\n",
    "corr_xy2 = np.zeros_like(x_err2)\n",
    "\n",
    "\n",
    "# Generate ellipses\n",
    "ells1 = [\n",
    "    Ellipse(\n",
    "        xy=[data1[0][i], data1[1][i]],\n",
    "        width=2.0 * y_err1[i],\n",
    "        height=2.0 * x_err1[i],\n",
    "        angle=np.rad2deg(np.arccos(corr_xy1[i])),\n",
    "    )\n",
    "    for i in range(len(data1[0]))\n",
    "]\n",
    "\n",
    "ells2 = [\n",
    "    Ellipse(\n",
    "        xy=[data2[0][i], data2[1][i]],\n",
    "        width=2.0 * y_err2[i],\n",
    "        height=2.0 * x_err2[i],\n",
    "        angle=np.rad2deg(np.arccos(corr_xy2[i])),\n",
    "    )\n",
    "    for i in range(len(data2[0]))\n",
    "]\n",
    "\n",
    "\n",
    "print(len(ells1))\n",
    "print(len(ells2))\n",
    "\n",
    "\n",
    "# Make the plot\n",
    "fig = plt.figure(figsize=(12,15))\n",
    "ax = fig.add_axes([0.15, 0.15, 1.03, 0.83])\n",
    "for i, e in enumerate(ells1):\n",
    "    ax.add_artist(e)\n",
    "    e.set_color('blue')\n",
    "    e.set_edgecolor('blue')\n",
    "    e.set_alpha(0.9)\n",
    "\n",
    "e.set_label('Abell 2151')\n",
    "for i, e in enumerate(ells2):\n",
    "    ax.add_artist(e)\n",
    "    e.set_color('red')\n",
    "    e.set_edgecolor('red')\n",
    "    e.set_alpha(0.9)\n",
    "\n",
    "e.set_label('Virgo')\n",
    "ax.fill_between(xvals, y_chain_quantiles1[0], y_chain_quantiles1[1], color=\"k\", alpha=0.2)\n",
    "ax.fill_between(xvals, y_chain_quantiles2[0], y_chain_quantiles2[1], color=\"k\", alpha=0.2)\n",
    "ax.plot(xvals, -6.95*xvals + b1, c=\"k\", marker=\"None\", ls=\"-\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, -6.95*xvals + b1 - vert1, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, -6.95*xvals + b1 + vert1, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, -6.95*xvals + b2, c=\"k\", marker=\"None\", ls=\"-\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, -6.95*xvals + b2 - vert2, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, -6.95*xvals + b2 + vert2, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.set_xlabel(r\"$\\log_{10}{(v_\\mathrm{0.4R_{26}} / \\mathrm{km~s^{-1}})}$\", fontsize=32)\n",
    "ax.set_ylabel(r\"$m_r$\", fontsize=32)\n",
    "ax.set_title(r\"Virgo and Abell 2151\", fontsize=32)\n",
    "ax.set_xlim(0.5, 2.75)\n",
    "ax.set_ylim(18, 12.5)\n",
    "\n",
    "ax.legend(fontsize=26)\n",
    "\n",
    "# Add the colourbar\n",
    "#cb = fig.colorbar(\n",
    " #   cm.ScalarMappable(norm=colors.Normalize(vmin=0.0, vmax=np.amax(sigmas)), cmap = cmo.cm.matter),\n",
    "  #  ax=ax,\n",
    "   # shrink=0.4,\n",
    "    #aspect=10,\n",
    "    #anchor=(-7.2, 0.95),\n",
    "#)\n",
    "#cb.set_label(label=r\"$\\sigma$\", fontsize=14)\n",
    "\n",
    "plt.savefig('virgo&a2151.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad015dc5-72ca-444c-b41e-5bd289c5a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066888d-b1f0-4d68-8a4c-87d71af92ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "linregress(xvals, -6.95*xvals + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1b738-4c03-4874-aec2-a612c8ff1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = hf.get_sigmas()\n",
    "xvals = np.linspace(0., 3., 1000)\n",
    "yvals = hf.coords[0] * xvals + hf.coords[1]\n",
    "\n",
    "# Get the MCMC 1-sigma quantiles to plot with the fit.\n",
    "y_chain = np.outer(xvals, mcmc_samples[0]) + mcmc_samples[1]\n",
    "y_chain_quantiles = np.quantile(y_chain, [0.1587, 0.8414], axis=1)\n",
    "\n",
    "# Pack info into data\n",
    "data = [log10vmax[isrmeas], rmag[isrmeas]]\n",
    "x_err = dlog10vmax[isrmeas]\n",
    "y_err = drmag[isrmeas]\n",
    "corr_xy = np.zeros_like(x_err)\n",
    "\n",
    "# Generate ellipses\n",
    "ells = [\n",
    "    Ellipse(\n",
    "        xy=[data[0][i], data[1][i]],\n",
    "        width=2.0 * y_err[i],\n",
    "        height=2.0 * x_err[i],\n",
    "        angle=np.rad2deg(np.arccos(corr_xy[i])),\n",
    "    )\n",
    "    for i in range(len(data[0]))\n",
    "]\n",
    "\n",
    "# Make the plot\n",
    "fig = plt.figure(figsize=(6,7))\n",
    "ax = fig.add_axes([0.15, 0.15, 1.03, 0.83])\n",
    "for i, e in enumerate(ells):\n",
    "    ax.add_artist(e)\n",
    "    e.set_color(cmo.cm.haline(sigmas[i] / np.amax(sigmas)))\n",
    "    e.set_edgecolor('None')\n",
    "    e.set_alpha(0.9)\n",
    "ax.fill_between(xvals, y_chain_quantiles[0], y_chain_quantiles[1], color=\"k\", alpha=0.2)\n",
    "ax.plot(xvals, yvals, c=\"k\", marker=\"None\", ls=\"-\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, yvals - hf.vert_scat, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, yvals + hf.vert_scat, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.set_xlabel(r\"$\\log_{10}{(v_\\mathrm{0.4R_{26}} / \\mathrm{km~s^{-1}})}$\", fontsize=16)\n",
    "ax.set_ylabel(r\"$m_r$\", fontsize=16)\n",
    "ax.set_title(r\"Virgo\", fontsize=16)\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(18, 12)\n",
    "\n",
    "# Add the colourbar\n",
    "cb = fig.colorbar(\n",
    "    cm.ScalarMappable(norm=colors.Normalize(vmin=0.0, vmax=np.amax(sigmas)), cmap = cmo.cm.haline),\n",
    "    ax=ax,\n",
    "    shrink=0.5,\n",
    "    aspect=10,\n",
    "    anchor=(-8, 0.95),\n",
    ")\n",
    "cb.set_label(label=r\"$\\sigma$\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571cfc91-d974-4e3c-9276-4241422aee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(mcmc_samples.T, bins=25, smooth=1,\n",
    "#              range=[[1.9, 2.4], [0.75, 1.1], [0.1, 0.3]],   # Range for a, b, sigma. Adjust as needed.\n",
    "             labels=['$a$', '$b_1$', '$b_2$', r'$\\sigma_1$', r'$\\sigma_2$'],\n",
    "             levels=(1-np.exp(-0.5), 1-np.exp(-2)),\n",
    "             quantiles=[0.16, 0.5, 0.84],\n",
    "             color='blue',\n",
    "             hist_kwargs={'histtype':'stepfilled', 'alpha':0.3},\n",
    "             plot_datapoints=False,\n",
    "             fill_contours=True,\n",
    "             show_titles=True,\n",
    "             title_kwargs={\"fontsize\": 12})\n",
    "plt.savefig('cornerplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472cffb-c25c-4f2d-a337-891fabc5acc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calibration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511be033-bca1-4260-a145-31b488f8bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGA_IDs = tdaily['SGA_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479d262-7c5b-4064-a9fc-1ce75f29ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGA = Table.read('/global/homes/h/hnofi/DESI_SGA/TF/SGA_distances.fits', format = 'fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840816a-3e6f-47bf-9c24-da93b5751378",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = join(SGA_main, SGA, keys_left='SGA_ID_1', keys_right='SGA_ID')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c3ae50-0c3b-4616-aac4-4a281243227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(t)):\n",
    "    if (t['SN_Catalog'][i] == '-1') & (t['Stellar_Catalog'][i] == '-1'):\n",
    "        t.remove_row(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e10922-79fe-4329-ac4b-17ce3db68b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All targets\n",
    "_ids_all, _counts_all = np.unique(t['SGA_ID'], return_counts=True)\n",
    "_ids_all[_counts_all > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d661a042-472f-4153-b947-96712a75a1a9",
   "metadata": {},
   "source": [
    "#### Remove Galaxy: 501697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1bb6cc-94c1-4361-9c88-5cf0cd905477",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(t)):\n",
    "    if (t['SGA_ID_1'][i] == 501697):\n",
    "        t.remove_row(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548526d2-e6b8-459b-97b0-ba2b9594278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sga_ids_vel_cuts = []\n",
    "rmag = []\n",
    "rmag_err = []\n",
    "abs_mag = []\n",
    "abs_mag_err = []\n",
    "vmax = []\n",
    "dvmax = []\n",
    "\n",
    "for i, sga_id in enumerate(t['SGA_ID_1']):\n",
    "    # if sga_id == 474614:\n",
    "    #     print('skipped')\n",
    "    #     continue\n",
    "    galaxy_list = t[t['SGA_ID_1'] == sga_id]\n",
    "    print\n",
    "    #print(i+1, sga_id)\n",
    "    \n",
    "    is_sga_galaxy = (galaxy_list['TARGETID'] > 30000000000000000) & (galaxy_list['TARGETID'] < 40000000000000000)\n",
    "    \n",
    "    sga_galaxy = galaxy_list[is_sga_galaxy]\n",
    "    tf_list = galaxy_list[~is_sga_galaxy]\n",
    "    \n",
    "    if np.sum(is_sga_galaxy) > 1:\n",
    "        sga_galaxy = sga_galaxy[0]\n",
    "    \n",
    "    targetid = int(sga_galaxy['TARGETID'])\n",
    "    center = SkyCoord(sga_galaxy['TARGET_RA'], sga_galaxy['TARGET_DEC'], unit='deg')\n",
    "    offcenter = SkyCoord(tf_list['TARGET_RA'], tf_list['TARGET_DEC'], unit='deg')\n",
    "    sep2d = offcenter.separation(center)\n",
    "    r26 = 0.5 * float(sga_galaxy['D26_1'])*u.arcmin\n",
    "    sep_r26 = sep2d.to('arcmin') / r26\n",
    "    \n",
    "    zc, zc_err = sga_galaxy['Z'], sga_galaxy['ZERR']\n",
    "    zt, zt_err = tf_list['Z'], tf_list['ZERR']\n",
    "    \n",
    "    dz = np.abs(zt - zc)\n",
    "    dz_err = np.sqrt(zc_err**2 + zt_err**2)\n",
    "    \n",
    "    dv = c * dz\n",
    "    dv_err = c * dz_err\n",
    "    \n",
    "    good_vel = dv < 5000\n",
    "    \n",
    "    if np.sum(good_vel) > 0:\n",
    "        sep_r26 = np.insert(sep_r26[good_vel], 0, 0.)\n",
    "        dv = np.insert(dv[good_vel], 0, 0.)\n",
    "        dv_err = np.insert(dv_err[good_vel], 0, 3e5*zc_err)\n",
    "\n",
    "        # Extract the 0.33xR26 points.\n",
    "        is_033_r26 = (sep_r26 > 0.35) & (sep_r26 < 0.45)\n",
    "        if np.sum(is_033_r26) > 0:\n",
    "            v033 = np.mean(dv[is_033_r26])\n",
    "            dv033 = np.sqrt(np.sum(dv_err[is_033_r26]**2))\n",
    "\n",
    "            rmag.append(float(sga_galaxy['R_MAG_SB26_1']))\n",
    "            rmag_err.append(float(sga_galaxy['R_MAG_SB26_ERR_1']))\n",
    "            vmax.append(v033)\n",
    "            dvmax.append(dv033)\n",
    "            # Find absolute magnitude - 5log(h), using h=0.742 (Union2 (2010))\n",
    "            abs_mag.append(float(sga_galaxy['R_MAG_SB26_1'] - sga_galaxy['DM1_SN']) - 5*np.log10(0.742))\n",
    "            abs_mag_err.append(np.sqrt((float(sga_galaxy['R_MAG_SB26_ERR_1']))**2 + (float(sga_galaxy['e_DM1_SN']))**2))\n",
    "            sga_ids_vel_cuts.append(sga_id)\n",
    "            \n",
    "#print(sga_ids_vel_cuts)\n",
    "#print('mag:', rmag)\n",
    "#print('vel:', vmax)\n",
    "#print('dv:', dvmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22e715-95ca-4374-86cd-7ba3b1a228e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmag = np.asarray(rmag)\n",
    "rmag_err = np.asarray(rmag_err)\n",
    "vmax = np.asarray(vmax)\n",
    "dvmax = np.asarray(dvmax)\n",
    "abs_mag = np.asarray(abs_mag)\n",
    "abs_mag_err = np.asarray(abs_mag_err)\n",
    "\n",
    "isrmeas = rmag > 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,4), tight_layout=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.errorbar(rmag[isrmeas], vmax[isrmeas], xerr = rmag_err[isrmeas], yerr=dvmax[isrmeas], fmt='ro')\n",
    "ax.set(xlabel='$M_r$(26) - 5log$_{10}$(h)',\n",
    "       #xlim=(18.5, 12.5),\n",
    "       #ylim=(-50,300),\n",
    "       ylabel='$v_\\mathrm{max}$ [km s$^{-1}$]')\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "log10vmax = np.log10(vmax)\n",
    "dlog10vmax = 0.434 * dvmax / vmax \n",
    "\n",
    "ax.errorbar(rmag[isrmeas], log10vmax[isrmeas], xerr = rmag_err[isrmeas], yerr=dlog10vmax[isrmeas], fmt='ro')\n",
    "ax.set(xlabel='$M_r$(26) - 5log$_{10}$(h)',\n",
    "       #xlim=(18.5, 12.5),\n",
    "       ylabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$')\n",
    "       #ylim=(-0.5,3))\n",
    "\n",
    "fig.suptitle(r'Rotational velocity at $0.4R_{26}$', y=1.05)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "print(np.sum(isrmeas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c3159-9bfc-4fac-8f0d-6c369e4eea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmag = np.asarray(rmag)\n",
    "vmax = np.asarray(vmax)\n",
    "dvmax = np.asarray(dvmax)\n",
    "abs_mag = np.asarray(abs_mag)\n",
    "abs_mag_err = np.asarray(abs_mag_err)\n",
    "# abs_mag_err = np.sqrt()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,4), tight_layout=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.errorbar(abs_mag, vmax, xerr = abs_mag_err,yerr=dvmax, fmt='ro')\n",
    "ax.set(xlabel='$M_r$(26)',\n",
    "       # xlim=(18.5, 12.5),\n",
    "       ylim=(-50,300),\n",
    "       ylabel='$v_\\mathrm{max}$ [km s$^{-1}$]')\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "log10vmax = np.log10(vmax)\n",
    "dlog10vmax = 0.434 * dvmax / vmax \n",
    "\n",
    "ax.errorbar(abs_mag[isrmeas], log10vmax[isrmeas], xerr = abs_mag_err[isrmeas],yerr=dlog10vmax[isrmeas], fmt='ro')\n",
    "ax.set(xlabel='$M_r$(26)',\n",
    "       # xlim=(18.5, 12.5),\n",
    "       ylabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$',\n",
    "       ylim=(-0.5,3))\n",
    "\n",
    "fig.suptitle(r'Rotational velocity at $0.4R_{26}$', y=1.05)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "print(np.sum(isrmeas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768c1ee-e4a4-413b-9629-3771b6b43fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sga_table = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac89d3-79fb-43f6-9d7f-10813a10f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmag_clean = []\n",
    "rmag_err_clean = []\n",
    "vmax_clean = []\n",
    "dvmax_clean = []\n",
    "abs_mag_clean = []\n",
    "abs_mag_err_clean = []\n",
    "z= []\n",
    "\n",
    "inc_min = 45*u.degree\n",
    "cosi_max = np.cos(inc_min.to('radian'))\n",
    "\n",
    "sga_table['cosi'] = np.sqrt((sga_table['BA_1']**2 - q0**2)/(1 - q0**2))\n",
    "sga_table['cosi'][np.isnan(sga_table['cosi'])] = 0 # Objects with b/a < 0.2\n",
    "\n",
    "#i = 0\n",
    "\n",
    "for sga_id in np.unique(sga_table['SGA_ID_1']):\n",
    "    galaxy_list = sga_table[sga_table['SGA_ID_1'] == sga_id]\n",
    "    \n",
    "    is_sga_galaxy = (galaxy_list['TARGETID'] > 30000000000000000) & (galaxy_list['TARGETID'] < 40000000000000000)\n",
    "    sga_galaxy = galaxy_list[is_sga_galaxy]\n",
    "    tf_list = galaxy_list[~is_sga_galaxy]\n",
    "    \n",
    "    if np.sum(is_sga_galaxy) > 1:\n",
    "        sga_galaxy = sga_galaxy[0]\n",
    "    \n",
    "    targetid = int(sga_galaxy['TARGETID'])\n",
    "    \n",
    "    center = SkyCoord(sga_galaxy['TARGET_RA'], sga_galaxy['TARGET_DEC'], unit='deg')\n",
    "    offcenter = SkyCoord(tf_list['TARGET_RA'], tf_list['TARGET_DEC'], unit='deg')\n",
    "    sep2d = offcenter.separation(center)\n",
    "    \n",
    "    morphtype = str(sga_galaxy['MORPHTYPE_1'])\n",
    "    \n",
    "    cosi = float(sga_galaxy['cosi'])\n",
    "    \n",
    "    r26 = 0.5 * float(sga_galaxy['D26_1']) * u.arcmin\n",
    "    sep_r26 = sep2d.to('arcmin') / r26\n",
    "\n",
    "    # Cut any suspected ellipticals\n",
    "    if morphtype.startswith('E') or morphtype.startswith('S0') or morphtype.startswith('I'):\n",
    "        print('{} cut (morphology)'.format(sga_id))\n",
    "        continue\n",
    "               \n",
    "    # Inclination cut\n",
    "    if cosi > cosi_max:\n",
    "        print('{} cut (inclination)'.format(sga_id))\n",
    "        continue\n",
    "        \n",
    "    #i += 1\n",
    "    #print(i, sga_id, cosi)\n",
    "    \n",
    "    zc, zc_err = float(sga_galaxy['Z']), float(sga_galaxy['ZERR'])\n",
    "    zt, zt_err = tf_list['Z'], tf_list['ZERR']\n",
    "    \n",
    "    dz = np.abs(zt - zc)\n",
    "    dz_err = np.sqrt(zc_err**2 + zt_err**2)\n",
    "    \n",
    "    dv = 3e5 * dz\n",
    "    dv_err = 3e5 * dz_err\n",
    "    \n",
    "    good_vel = dv < 5000\n",
    "    \n",
    "    if np.sum(good_vel) > 0:\n",
    "    \n",
    "        sep_r26 = np.insert(sep_r26[good_vel], 0, 0.)\n",
    "        dv = np.insert(dv[good_vel], 0, 0.)\n",
    "        dv_err = np.insert(dv_err[good_vel], 0, 3e5*zc_err)\n",
    "\n",
    "        # Extract the 0.33xR26 points.\n",
    "        is_033_r26 = (sep_r26 > 0.35) & (sep_r26 < 0.45)\n",
    "        \n",
    "        if np.sum(is_033_r26) > 0:\n",
    "            v033 = np.mean(dv[is_033_r26]) / np.sqrt(1 - cosi**2)\n",
    "            dv033 = np.sqrt(np.sum(dv_err[is_033_r26]**2)) / np.sqrt(1 - cosi**2)\n",
    "            z.append(zc)\n",
    "            rmag_clean.append(float(sga_galaxy['R_MAG_SB26_1']))\n",
    "            rmag_err_clean.append(float(sga_galaxy['R_MAG_SB26_ERR_1']))\n",
    "            vmax_clean.append(v033)\n",
    "            dvmax_clean.append(dv033)\n",
    "            abs_mag_clean.append(float(sga_galaxy['R_MAG_SB26_1'] - sga_galaxy['DM1_SN'] - 5*np.log10(0.742)))\n",
    "            abs_mag_err_clean.append(np.sqrt((float(sga_galaxy['R_MAG_SB26_ERR_1']))**2 + (float(sga_galaxy['e_DM1_SN']))**2))\n",
    "    \n",
    "#inComa_sga_table[['SGA_ID', 'BA', 'cosi']].show_in_notebook()\n",
    "print(len(rmag_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d10aa-b4b4-4e70-b785-3d3ff22e03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1norm(pars, x, y, dy):\n",
    "    '''\n",
    "    Linear fit that uses the l1-norm (robust against outliers).\n",
    "    '''\n",
    "    a, b = pars\n",
    "    return np.sum(np.abs((y - a - b*x)/dy))\n",
    "\n",
    "def l1norm_noerror(pars, x, y):\n",
    "    '''\n",
    "    Linear fit that uses the l1-norm without normalizing by measurement uncertainties.\n",
    "    '''\n",
    "    a, b = pars\n",
    "    return np.sum(np.abs(y - a - b*x))\n",
    "\n",
    "def l2norm(pars, x, y, dy):\n",
    "    '''\n",
    "    Linear fit that uses the l2-norm\n",
    "    '''\n",
    "    a, b = pars\n",
    "    return np.sum((y - a - b*x)**2/dy**2)\n",
    "\n",
    "def fit_tfr(r, logv, dlogv):\n",
    "    fmin = 1e99\n",
    "    a, b = -0.5, -0.15\n",
    "    hess_inv = np.ones((2,2))\n",
    "    \n",
    "    succ_res = None\n",
    "    \n",
    "    # Try a large number of random seeds to ensure a decent fit.\n",
    "    for i in range(1000):\n",
    "        _a, _b = np.random.uniform(-1,1), np.random.uniform(-0.14306432,-0.14306432)\n",
    "        \n",
    "        res = minimize(l1norm_noerror, \n",
    "                       [_a, _b], \n",
    "                       args=(r,logv),# dlogv),\n",
    "                       method='L-BFGS-B', \n",
    "                       bounds=[[-1,1], [-0.14306432,-0.14306432]])\n",
    "        \n",
    "        if res.fun < fmin and res.success:\n",
    "            # print('Successful fit')\n",
    "            succ_res = res.copy()\n",
    "            fmin = res.fun\n",
    "            a, b = res.x\n",
    "            hess_inv = res.hess_inv\n",
    "    \n",
    "    if succ_res is None:\n",
    "        print('No successful fits')\n",
    "    # else:\n",
    "    #     print(succ_res)\n",
    "    \n",
    "    return a, b, hess_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e166bc-276d-4183-9ebb-7412172dba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_mag_clean = np.asarray(abs_mag_clean)\n",
    "abs_mag_err_clean = np.asarray(abs_mag_err_clean)\n",
    "vmax_clean = np.asarray(vmax_clean)\n",
    "dvmax_clean = np.asarray(dvmax_clean)\n",
    "\n",
    "log10vmax_clean = np.log10(vmax_clean)\n",
    "dlog10vmax_clean = 0.434 * dvmax_clean / vmax_clean \n",
    "\n",
    "a, b, hess_inv = fit_tfr(abs_mag_clean, \n",
    "                  log10vmax_clean, \n",
    "                  dlog10vmax_clean)\n",
    "\n",
    "print('Fitted params: a={0}, b={1}'.format(a, b))\n",
    "print('Slope={0}, y-int={1}'.format(1/b, -a/b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1e9cb-7ff3-4422-ac2b-18a0531d4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6), tight_layout=True)\n",
    "\n",
    "ax.errorbar(log10vmax_clean, \n",
    "            abs_mag_clean,\n",
    "            yerr = abs_mag_err_clean,\n",
    "            xerr=dlog10vmax_clean, \n",
    "            fmt='ro', \n",
    "            alpha=0.7,\n",
    "            label='Cleaned data, $\\cos{(i)}$-corrected')\n",
    "\n",
    "# a = -0.75655391\n",
    "# b = -0.14665\n",
    "\n",
    "logv = np.arange(2, 2.5, 0.03)\n",
    "ax.plot(logv, 1/b * (logv - a), 'r--', alpha=0.8)\n",
    "# ################################################################################\n",
    "\n",
    "\n",
    "ax.set(ylabel='$M_r$(26)-5log$_{10}$(h)',\n",
    "       #ylim=(-18, -38),\n",
    "       xlabel=r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$',\n",
    "        ylim=(-18, -22),\n",
    "       title=r'Rotational velocity at $0.4R_{26}$')\n",
    "ax.grid(ls=':')\n",
    "# ax.legend(loc='upper left', fontsize=10);\n",
    "\n",
    "# fig.suptitle(r'Max velocity at $0.33\\times R_{26}$', y=1.05)\n",
    "# fig.subplots_adjust(top=0.8)\n",
    "#fig.savefig('tf_dist_04_06_2022.png', dpi=120, transparent=True)\n",
    "\n",
    "# print(np.sum(isrmeas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9168f2-dba5-4c66-9dc3-17e7c6542f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bd6f7-9889-4d18-b991-4b7ede57bc97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71c2a7-faa1-47d6-a1a4-4773b788ddf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0bba2-9b71-4262-90fa-35ddd7703b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2xN matrix.\n",
    "ndata = len(dlog10vmax_clean)\n",
    "cov3 = np.empty((2, 2, ndata))\n",
    "\n",
    "# loop over arrays of uncertainties in logv and mag\n",
    "# Assume diagonal covariance for each measurement.\n",
    "for i, (dlogv, dm) in enumerate(zip(dlog10vmax_clean, abs_mag_err_clean)):\n",
    "    cov3[:,:,i] = np.array([[dlogv**2, 0.], [0., dm**2]])\n",
    "                              \n",
    "# cov[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4d50e-cf6c-4886-81d6-cdaee15f8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "logv = log10vmax_clean\n",
    "mr = abs_mag_clean\n",
    "logv.shape, mr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68974490-f66e-4051-b57f-06f20df4eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = [logv, mr]\n",
    "cov3 = cov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ef8cc-942f-4a86-9e18-fe5e6f98ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = LinFit([logv, mr], cov3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9d604-1b70-4fe0-a6f1-498553e7d274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bounds = ((-6.99, -6.98), (-10.0, 10.0), (1.0e-5, 500.0))\n",
    "mcmc_samples, mcmc_lnlike = hf.emcee(bounds)\n",
    "print(np.mean(mcmc_samples, axis=1), np.std(mcmc_samples, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f560a-d6dc-4094-9c23-d42be2c6da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, sig    = np.mean(mcmc_samples, axis=1)\n",
    "da, db, dsig = np.std(mcmc_samples, axis=1)\n",
    "\n",
    "for val, err in zip((a, b, sig), (da, db, dsig)):\n",
    "    print('{:6.2f} +/- {:.2f}'.format(val, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd576775-036d-407f-ad38-9930ee6bb86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = hf.get_sigmas()\n",
    "xvals = np.linspace(0., 3., 1000)\n",
    "yvals = hf.coords[0] * xvals + hf.coords[1]\n",
    "\n",
    "# Get the MCMC 1-sigma quantiles to plot with the fit.\n",
    "y_chain = np.outer(xvals, mcmc_samples[0]) + mcmc_samples[1]\n",
    "y_chain_quantiles = np.quantile(y_chain, [0.1587, 0.8414], axis=1)\n",
    "\n",
    "# Pack info into data\n",
    "data = [log10vmax_clean, abs_mag_clean, ]\n",
    "x_err = dlog10vmax_clean\n",
    "y_err = abs_mag_err_clean \n",
    "corr_xy = np.zeros_like(x_err)\n",
    "\n",
    "# Generate ellipses\n",
    "ells = [\n",
    "    Ellipse(\n",
    "        xy=[data[0][i], data[1][i]],\n",
    "        width=2.0 * y_err[i],\n",
    "        height=2.0 * x_err[i],\n",
    "        angle=np.rad2deg(np.arccos(corr_xy[i])),\n",
    "    )\n",
    "    for i in range(len(data[0]))\n",
    "]\n",
    "\n",
    "# Make the plot\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "ax = fig.add_axes([0.15, 0.15, 1.03, 0.83])\n",
    "for i, e in enumerate(ells):\n",
    "    ax.add_artist(e)\n",
    "    e.set_color(cmo.cm.matter(sigmas[i] / np.amax(sigmas)))\n",
    "    e.set_edgecolor('None')\n",
    "    e.set_alpha(0.9)\n",
    "ax.fill_between(xvals, y_chain_quantiles[0], y_chain_quantiles[1], color=\"k\", alpha=0.2)\n",
    "ax.plot(xvals, yvals, c=\"k\", marker=\"None\", ls=\"-\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, yvals - hf.vert_scat, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.plot(xvals, yvals + hf.vert_scat, c=\"k\", marker=\"None\", ls=\"--\", lw=1.3, alpha=0.9)\n",
    "ax.set_xlabel(r'$\\log{(v_\\mathrm{max} / \\mathrm{km~s}^{-1})}$', fontsize=24)\n",
    "ax.set_ylabel('$M_r$(26)-5log$_{10}$(h)', fontsize=24)\n",
    "ax.set_title(r\"Independent Distance Measurements\", fontsize=24)\n",
    "ax.set_xlim(1.9, 2.5)\n",
    "ax.set_ylim(-18, -22)\n",
    "\n",
    "# Add the colourbar\n",
    "cb = fig.colorbar(\n",
    "    cm.ScalarMappable(norm=colors.Normalize(vmin=0.0, vmax=np.amax(sigmas)), cmap = cmo.cm.matter),\n",
    "    ax=ax,\n",
    "    shrink=0.5,\n",
    "    aspect=10,\n",
    "    anchor=(-6.6, 0.95),\n",
    ")\n",
    "cb.set_label(label=r\"$\\sigma$\", fontsize=16)\n",
    "plt.savefig('inddist.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3d167-5e99-4189-be98-74bf0b864a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yrand, bins = 30)\n",
    "#plt.xlim(-3,-6)\n",
    "plt.axvline(yrand.mean(), ymin=-1, ymax=15, color='red', label='mean')\n",
    "plt.axvline(x=yrand.mean() - sty * 1.96, ymin=-1, ymax=15, color='green', label='95% CI')\n",
    "plt.axvline(x=yrand.mean() + sty * 1.96, ymin=-1, ymax=15, color='green')\n",
    "plt.title('Hyperfit MCMC Y-Intercept Values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESI main",
   "language": "python",
   "name": "desi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
