{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1bf435-46fb-4ece-aae1-101cc1c7e0c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Joint TFR Fitting with Galaxies in Clusters Found Suitable\n",
    "\n",
    "Using the clusters and the galaxies included within those clusters, we fit the Tully-Fisher relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65e7a76-009e-45d3-a030-13ad4724dd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Module imports and constant definitions \n",
    "from astropy.table import unique, Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits, ascii \n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization.wcsaxes import SphericalCircle\n",
    "from corner import corner\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.special import loggamma\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from hyperfit.linfit import LinFit\n",
    "\n",
    "import emcee\n",
    "import os\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ff09f6-0bb1-4921-9c9b-a5def2ab820c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = 1\n",
    "H0 = 100*h\n",
    "c = 3e5\n",
    "q0 = 0.2\n",
    "V0 = 2.5 # 0-point of TFR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c9614-7f63-4e45-b735-8c1b3b888c47",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DESI Iron & SGA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc3d297-c99d-431a-9a53-10e56cd5f8e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Iron Data\n",
    "We read in the Iron data to use throughout the notebook. Commented out below is the Fuji data, to use to check against when necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa84685f-3a0f-4f0c-a42f-2ff03812704c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=5</i>\n",
       "<table id=\"table140642297328160\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>TARGETID</th><th>TARGET_RA</th><th>TARGET_DEC</th><th>HEALPIX</th><th>SURVEY</th><th>Z</th><th>ZERR</th><th>ZWARN</th><th>DELTACHI2</th><th>FILENAME</th><th>PVTYPE</th><th>SGA_ID</th><th>RA</th><th>DEC</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>float64</th><th>float64</th><th>int64</th><th>bytes4</th><th>float64</th><th>float64</th><th>int64</th><th>float64</th><th>bytes65</th><th>bytes3</th><th>int64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>2852147603439621</td><td>198.369130660983</td><td>36.5372037049171</td><td>10475</td><td>main</td><td>0.815976335547845</td><td>7.38513168100107e-05</td><td>4</td><td>0.128754377365112</td><td>iron/healpix/main/dark/104/10475/redrock-main-dark-10475.fits</td><td>EXT</td><td>649377</td><td>198.36913066098333</td><td>36.537203704917076</td></tr>\n",
       "<tr><td>2399148812795907</td><td>198.371733180003</td><td>36.4994335406917</td><td>10475</td><td>main</td><td>1.11088784970434</td><td>7.48767797671894e-05</td><td>4</td><td>7.9473560154438</td><td>iron/healpix/main/bright/104/10475/redrock-main-bright-10475.fits</td><td>EXT</td><td>649377</td><td>198.37173318000336</td><td>36.499433540691676</td></tr>\n",
       "<tr><td>2399382443917318</td><td>184.845242475328</td><td>49.8157304793777</td><td>10995</td><td>main</td><td>1.14739342108157</td><td>0.000146302276719084</td><td>4</td><td>2.56771463155746</td><td>iron/healpix/main/bright/109/10995/redrock-main-bright-10995.fits</td><td>EXT</td><td>1008911</td><td>184.84524247532795</td><td>49.81573047937771</td></tr>\n",
       "<tr><td>2399634072797192</td><td>184.341289722203</td><td>70.8283725474297</td><td>11965</td><td>main</td><td>1.51703376230705</td><td>6.28979649962091e-05</td><td>4</td><td>4.76254060305655</td><td>iron/healpix/main/bright/119/11965/redrock-main-bright-11965.fits</td><td>EXT</td><td>241234</td><td>184.34128972220284</td><td>70.82837254742968</td></tr>\n",
       "<tr><td>2852141710442505</td><td>123.256011148025</td><td>36.2652948002806</td><td>6448</td><td>main</td><td>0.00787379494184006</td><td>3.4714052819995e-05</td><td>0</td><td>22.1719104201402</td><td>iron/healpix/main/dark/64/6448/redrock-main-dark-6448.fits</td><td>EXT</td><td>31591</td><td>123.25601114802525</td><td>36.26529480028061</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "    TARGETID        TARGET_RA     ...         RA                DEC        \n",
       "     int64           float64      ...      float64            float64      \n",
       "---------------- ---------------- ... ------------------ ------------------\n",
       "2852147603439621 198.369130660983 ... 198.36913066098333 36.537203704917076\n",
       "2399148812795907 198.371733180003 ... 198.37173318000336 36.499433540691676\n",
       "2399382443917318 184.845242475328 ... 184.84524247532795  49.81573047937771\n",
       "2399634072797192 184.341289722203 ... 184.34128972220284  70.82837254742968\n",
       "2852141710442505 123.256011148025 ... 123.25601114802525  36.26529480028061"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiron = Table.read('/global/cfs/projectdirs/desi/science/td/pv/desi_pv_tf_iron_healpix.fits')\n",
    "#tiron = Table.read('/global/cfs/projectdirs/desi/science/td/pv/desi_pv_tf_fuji_healpix.fits')\n",
    "\n",
    "tiron[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31806e8d-bcce-4584-9944-7e3620f1a5ee",
   "metadata": {},
   "source": [
    "### SGA\n",
    "We read in the SGA to use throughout the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad24a524-771b-42d2-a434-5e7168a65d56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=5</i>\n",
       "<table id=\"table140641378785824\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>SGA_ID</th><th>SGA_GALAXY</th><th>GALAXY</th><th>PGC</th><th>RA_LEDA</th><th>DEC_LEDA</th><th>MORPHTYPE</th><th>PA_LEDA</th><th>D25_LEDA</th><th>BA_LEDA</th><th>Z_LEDA</th><th>SB_D25_LEDA</th><th>MAG_LEDA</th><th>BYHAND</th><th>REF</th><th>GROUP_ID</th><th>GROUP_NAME</th><th>GROUP_MULT</th><th>GROUP_PRIMARY</th><th>GROUP_RA</th><th>GROUP_DEC</th><th>GROUP_DIAMETER</th><th>BRICKNAME</th><th>RA</th><th>DEC</th><th>D26</th><th>D26_REF</th><th>PA</th><th>BA</th><th>RA_MOMENT</th><th>DEC_MOMENT</th><th>SMA_MOMENT</th><th>G_SMA50</th><th>R_SMA50</th><th>Z_SMA50</th><th>SMA_SB22</th><th>SMA_SB22.5</th><th>SMA_SB23</th><th>SMA_SB23.5</th><th>SMA_SB24</th><th>SMA_SB24.5</th><th>SMA_SB25</th><th>SMA_SB25.5</th><th>SMA_SB26</th><th>G_MAG_SB22</th><th>R_MAG_SB22</th><th>Z_MAG_SB22</th><th>G_MAG_SB22.5</th><th>R_MAG_SB22.5</th><th>Z_MAG_SB22.5</th><th>G_MAG_SB23</th><th>R_MAG_SB23</th><th>Z_MAG_SB23</th><th>G_MAG_SB23.5</th><th>R_MAG_SB23.5</th><th>Z_MAG_SB23.5</th><th>G_MAG_SB24</th><th>R_MAG_SB24</th><th>Z_MAG_SB24</th><th>G_MAG_SB24.5</th><th>R_MAG_SB24.5</th><th>Z_MAG_SB24.5</th><th>G_MAG_SB25</th><th>R_MAG_SB25</th><th>Z_MAG_SB25</th><th>G_MAG_SB25.5</th><th>R_MAG_SB25.5</th><th>Z_MAG_SB25.5</th><th>G_MAG_SB26</th><th>R_MAG_SB26</th><th>Z_MAG_SB26</th><th>SMA_SB22_ERR</th><th>SMA_SB22.5_ERR</th><th>SMA_SB23_ERR</th><th>SMA_SB23.5_ERR</th><th>SMA_SB24_ERR</th><th>SMA_SB24.5_ERR</th><th>SMA_SB25_ERR</th><th>SMA_SB25.5_ERR</th><th>SMA_SB26_ERR</th><th>G_MAG_SB22_ERR</th><th>R_MAG_SB22_ERR</th><th>Z_MAG_SB22_ERR</th><th>G_MAG_SB22.5_ERR</th><th>R_MAG_SB22.5_ERR</th><th>Z_MAG_SB22.5_ERR</th><th>G_MAG_SB23_ERR</th><th>R_MAG_SB23_ERR</th><th>Z_MAG_SB23_ERR</th><th>G_MAG_SB23.5_ERR</th><th>R_MAG_SB23.5_ERR</th><th>Z_MAG_SB23.5_ERR</th><th>G_MAG_SB24_ERR</th><th>R_MAG_SB24_ERR</th><th>Z_MAG_SB24_ERR</th><th>G_MAG_SB24.5_ERR</th><th>R_MAG_SB24.5_ERR</th><th>Z_MAG_SB24.5_ERR</th><th>G_MAG_SB25_ERR</th><th>R_MAG_SB25_ERR</th><th>Z_MAG_SB25_ERR</th><th>G_MAG_SB25.5_ERR</th><th>R_MAG_SB25.5_ERR</th><th>Z_MAG_SB25.5_ERR</th><th>G_MAG_SB26_ERR</th><th>R_MAG_SB26_ERR</th><th>Z_MAG_SB26_ERR</th><th>G_COG_PARAMS_MTOT</th><th>G_COG_PARAMS_M0</th><th>G_COG_PARAMS_ALPHA1</th><th>G_COG_PARAMS_ALPHA2</th><th>G_COG_PARAMS_CHI2</th><th>R_COG_PARAMS_MTOT</th><th>R_COG_PARAMS_M0</th><th>R_COG_PARAMS_ALPHA1</th><th>R_COG_PARAMS_ALPHA2</th><th>R_COG_PARAMS_CHI2</th><th>Z_COG_PARAMS_MTOT</th><th>Z_COG_PARAMS_M0</th><th>Z_COG_PARAMS_ALPHA1</th><th>Z_COG_PARAMS_ALPHA2</th><th>Z_COG_PARAMS_CHI2</th><th>ELLIPSEBIT</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>bytes16</th><th>bytes29</th><th>int64</th><th>float64</th><th>float64</th><th>bytes21</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>bool</th><th>bytes13</th><th>int64</th><th>bytes35</th><th>int16</th><th>bool</th><th>float64</th><th>float64</th><th>float32</th><th>bytes8</th><th>float64</th><th>float64</th><th>float32</th><th>bytes4</th><th>float32</th><th>float32</th><th>float64</th><th>float64</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>int32</th></tr></thead>\n",
       "<tr><td>2</td><td>SGA-2020 2</td><td>PGC1283207</td><td>1283207</td><td>228.3770865</td><td>5.4232017</td><td>S?</td><td>152.2</td><td>0.36307806</td><td>0.724436</td><td>0.03463229</td><td>23.40448</td><td>16.976</td><td>False</td><td>LEDA-20181114</td><td>0</td><td>PGC1283207</td><td>1</td><td>True</td><td>228.3770865</td><td>5.4232017</td><td>0.36307806</td><td>2283p055</td><td>228.3770803831908</td><td>5.423191398593787</td><td>0.49470574</td><td>SB26</td><td>158.20142</td><td>0.545691</td><td>228.37700918822188</td><td>5.4232652570544015</td><td>10.897086</td><td>3.3509698</td><td>3.1147978</td><td>3.240862</td><td>5.902337</td><td>6.9126143</td><td>7.941369</td><td>8.997992</td><td>10.073601</td><td>11.199986</td><td>12.391357</td><td>13.561038</td><td>14.841172</td><td>16.966799</td><td>16.108246</td><td>15.486356</td><td>16.879545</td><td>16.024958</td><td>15.400715</td><td>16.818878</td><td>15.967034</td><td>15.341793</td><td>16.776297</td><td>15.925804</td><td>15.300776</td><td>16.746685</td><td>15.897334</td><td>15.272053</td><td>16.725166</td><td>15.876816</td><td>15.2521105</td><td>16.708357</td><td>15.862035</td><td>15.237181</td><td>16.696539</td><td>15.851936</td><td>15.226998</td><td>16.689613</td><td>15.844313</td><td>15.21976</td><td>0.013392451</td><td>0.02354</td><td>0.021872982</td><td>0.01736985</td><td>0.024445537</td><td>0.039866067</td><td>0.05026544</td><td>0.08455789</td><td>0.122911856</td><td>0.005682776</td><td>0.0054258136</td><td>0.0049038026</td><td>0.005588406</td><td>0.005323561</td><td>0.0047632363</td><td>0.00543534</td><td>0.005177031</td><td>0.0046343105</td><td>0.0053025587</td><td>0.005040888</td><td>0.0045181247</td><td>0.005206092</td><td>0.0049438984</td><td>0.0044374703</td><td>0.0051483097</td><td>0.0048758644</td><td>0.0043834248</td><td>0.0051032505</td><td>0.0048264163</td><td>0.004344248</td><td>0.0050705094</td><td>0.004792021</td><td>0.004319857</td><td>0.005054293</td><td>0.004765629</td><td>0.0043044444</td><td>16.65942</td><td>0.34037337</td><td>0.2978292</td><td>3.0239506</td><td>0.07928849</td><td>15.820566</td><td>0.2640441</td><td>0.34559453</td><td>3.3033552</td><td>0.003811298</td><td>15.195567</td><td>0.29826432</td><td>0.3001073</td><td>3.2333765</td><td>0.011723555</td><td>0</td></tr>\n",
       "<tr><td>3</td><td>SGA-2020 3</td><td>PGC1310416</td><td>1310416</td><td>202.54443750000002</td><td>6.9345944</td><td>Sc</td><td>159.26</td><td>0.4017908</td><td>0.7816278</td><td>0.073888786</td><td>23.498482</td><td>16.85</td><td>False</td><td>LEDA-20181114</td><td>1</td><td>PGC1310416</td><td>1</td><td>True</td><td>202.54443750000002</td><td>6.9345944</td><td>0.4017908</td><td>2025p070</td><td>202.5444619671207</td><td>6.9346244322326624</td><td>0.55350494</td><td>SB26</td><td>161.5937</td><td>0.7291764</td><td>202.54432739596137</td><td>6.934806737209989</td><td>15.746941</td><td>5.6416235</td><td>5.2647552</td><td>5.0895185</td><td>5.9838247</td><td>7.4356494</td><td>8.728868</td><td>10.087478</td><td>11.529764</td><td>12.818195</td><td>14.115497</td><td>15.319822</td><td>16.605148</td><td>16.963299</td><td>16.307854</td><td>15.806882</td><td>16.729511</td><td>16.097378</td><td>15.615527</td><td>16.606344</td><td>15.990707</td><td>15.518403</td><td>16.525967</td><td>15.917321</td><td>15.450624</td><td>16.462585</td><td>15.859485</td><td>15.397182</td><td>16.419558</td><td>15.820947</td><td>15.36243</td><td>16.390558</td><td>15.796369</td><td>15.338905</td><td>16.376112</td><td>15.782492</td><td>15.323709</td><td>16.364115</td><td>15.773462</td><td>15.313725</td><td>0.036992554</td><td>0.034982767</td><td>0.037769336</td><td>0.049429573</td><td>0.052699674</td><td>0.074114166</td><td>0.07914538</td><td>0.09781406</td><td>0.15534972</td><td>0.016095797</td><td>0.019181909</td><td>0.021539452</td><td>0.013955905</td><td>0.016594552</td><td>0.018640138</td><td>0.012786752</td><td>0.015244632</td><td>0.01715491</td><td>0.011973826</td><td>0.014366956</td><td>0.016208366</td><td>0.011358372</td><td>0.013676575</td><td>0.015474222</td><td>0.010944939</td><td>0.013225297</td><td>0.015011175</td><td>0.010691595</td><td>0.012931233</td><td>0.014687982</td><td>0.010546411</td><td>0.012796015</td><td>0.014518412</td><td>0.010457551</td><td>0.012685407</td><td>0.014379212</td><td>16.284733</td><td>1.0914493</td><td>0.24674739</td><td>2.4320207</td><td>0.68685365</td><td>15.704403</td><td>0.8764323</td><td>0.27360612</td><td>2.4995425</td><td>0.49343896</td><td>15.235263</td><td>1.3098688</td><td>0.17866786</td><td>2.1750498</td><td>0.20391206</td><td>0</td></tr>\n",
       "<tr><td>4</td><td>SGA-2020 4</td><td>SDSSJ145059.93+135143.0</td><td>4435547</td><td>222.749787</td><td>13.8619111</td><td>S?</td><td>44.57</td><td>0.33342642</td><td>0.6637431</td><td>0.07567602</td><td>24.457481</td><td>18.214</td><td>False</td><td>LEDA-20181114</td><td>2</td><td>SDSSJ145059.93+135143.0</td><td>1</td><td>True</td><td>222.749787</td><td>13.8619111</td><td>0.33342642</td><td>2228p137</td><td>222.7497050504303</td><td>13.861929561160224</td><td>0.37067476</td><td>SB26</td><td>45.28537</td><td>0.70922077</td><td>222.749650475464</td><td>13.862052070022896</td><td>8.877115</td><td>4.652771</td><td>4.4837785</td><td>4.4959745</td><td>2.01033</td><td>3.3967943</td><td>4.76257</td><td>6.043787</td><td>7.242806</td><td>8.250407</td><td>9.158723</td><td>10.083457</td><td>11.120243</td><td>19.97595</td><td>19.190666</td><td>18.649523</td><td>19.098536</td><td>18.397219</td><td>17.899643</td><td>18.624952</td><td>17.967802</td><td>17.50231</td><td>18.35278</td><td>17.718002</td><td>17.265854</td><td>18.192762</td><td>17.5654</td><td>17.115404</td><td>18.10496</td><td>17.480022</td><td>17.033989</td><td>18.053415</td><td>17.430794</td><td>16.982971</td><td>18.020155</td><td>17.399996</td><td>16.948252</td><td>17.994783</td><td>17.377092</td><td>16.924469</td><td>0.02113719</td><td>0.03639431</td><td>0.051901262</td><td>0.06539029</td><td>0.08552586</td><td>0.07008602</td><td>0.070394725</td><td>0.08394975</td><td>0.113649584</td><td>0.013428732</td><td>0.017600043</td><td>0.016373685</td><td>0.012251812</td><td>0.014566466</td><td>0.013732588</td><td>0.012644532</td><td>0.014030071</td><td>0.013153961</td><td>0.012747069</td><td>0.013512552</td><td>0.012818239</td><td>0.012865601</td><td>0.01324455</td><td>0.012532208</td><td>0.012762528</td><td>0.013058522</td><td>0.012420634</td><td>0.01252645</td><td>0.012827468</td><td>0.012283978</td><td>0.012320441</td><td>0.012607317</td><td>0.012104107</td><td>0.0121167945</td><td>0.01244376</td><td>0.011985352</td><td>17.896797</td><td>0.5557265</td><td>0.25455818</td><td>3.167909</td><td>1.0522435</td><td>17.28287</td><td>0.4885815</td><td>0.2782499</td><td>3.2144456</td><td>1.3733263</td><td>16.807674</td><td>0.5177045</td><td>0.32264626</td><td>2.900518</td><td>1.8054093</td><td>0</td></tr>\n",
       "<tr><td>7</td><td>SGA-2020 7</td><td>PGC1742504</td><td>1742504</td><td>182.0888085</td><td>25.6022764</td><td>Sbc</td><td>84.97</td><td>0.548277</td><td>0.25118864</td><td>0.10090814</td><td>24.91348</td><td>17.59</td><td>False</td><td>LEDA-20181114</td><td>3</td><td>PGC1742504</td><td>1</td><td>True</td><td>182.0888085</td><td>25.6022764</td><td>0.548277</td><td>1820p255</td><td>182.08882232629614</td><td>25.60226821438983</td><td>0.8883204</td><td>SB26</td><td>84.857475</td><td>0.19753796</td><td>182.08873760544392</td><td>25.602311195157757</td><td>19.779116</td><td>6.5958204</td><td>6.0386286</td><td>5.8089786</td><td>9.279068</td><td>10.949478</td><td>12.652142</td><td>14.446171</td><td>16.323679</td><td>18.392954</td><td>20.915508</td><td>23.566542</td><td>26.649612</td><td>17.390274</td><td>16.360935</td><td>15.531964</td><td>17.285898</td><td>16.262264</td><td>15.440768</td><td>17.2167</td><td>16.195492</td><td>15.380734</td><td>17.16217</td><td>16.144245</td><td>15.334935</td><td>17.130178</td><td>16.110302</td><td>15.304758</td><td>17.104496</td><td>16.084463</td><td>15.280803</td><td>17.081282</td><td>16.061373</td><td>15.2589855</td><td>17.063671</td><td>16.045204</td><td>15.243196</td><td>17.046705</td><td>16.031244</td><td>15.23268</td><td>0.04351465</td><td>0.055440858</td><td>0.052207235</td><td>0.07507412</td><td>0.0793679</td><td>0.10347854</td><td>0.13569456</td><td>0.13104819</td><td>0.17234002</td><td>0.03885276</td><td>0.03744209</td><td>0.03786608</td><td>0.035534665</td><td>0.03441038</td><td>0.03503794</td><td>0.033557214</td><td>0.032548346</td><td>0.033348277</td><td>0.031964395</td><td>0.03106612</td><td>0.031957533</td><td>0.031133845</td><td>0.030202182</td><td>0.031190341</td><td>0.030430589</td><td>0.029511228</td><td>0.030530946</td><td>0.02975241</td><td>0.028853998</td><td>0.029866546</td><td>0.02928568</td><td>0.0284345</td><td>0.029445464</td><td>0.028843498</td><td>0.028076617</td><td>0.029169334</td><td>16.995174</td><td>21.083004</td><td>0.0164273</td><td>1.9079465</td><td>0.029703742</td><td>15.991165</td><td>0.7657307</td><td>0.52285546</td><td>2.3045986</td><td>0.006013103</td><td>15.191324</td><td>1.0408205</td><td>0.32956335</td><td>2.1520333</td><td>0.004725194</td><td>0</td></tr>\n",
       "<tr><td>18</td><td>SGA-2020 18</td><td>2MASXJ12340801+4535444</td><td>3550748</td><td>188.5335525</td><td>45.5956434</td><td>E</td><td>168.65</td><td>0.53088444</td><td>0.6950243</td><td>0.07609531</td><td>23.97948</td><td>16.726</td><td>False</td><td>LEDA-20181114</td><td>4</td><td>2MASXJ12340801+4535444</td><td>1</td><td>True</td><td>188.5335525</td><td>45.5956434</td><td>0.53088444</td><td>1883p455</td><td>188.53364923054596</td><td>45.595620212931856</td><td>0.73435897</td><td>SB26</td><td>166.25127</td><td>0.70995796</td><td>188.53349052789085</td><td>45.59567446403057</td><td>15.694805</td><td>5.091253</td><td>4.670616</td><td>2.9429996</td><td>5.219665</td><td>6.6119533</td><td>8.228266</td><td>10.109745</td><td>12.170589</td><td>14.364073</td><td>16.722517</td><td>19.18709</td><td>22.03077</td><td>17.208511</td><td>16.224203</td><td>15.566424</td><td>17.050343</td><td>16.080097</td><td>15.443468</td><td>16.921791</td><td>15.962402</td><td>15.347263</td><td>16.814959</td><td>15.864242</td><td>15.27134</td><td>16.729906</td><td>15.787886</td><td>15.218466</td><td>16.664564</td><td>15.730083</td><td>15.182751</td><td>16.61991</td><td>15.686324</td><td>15.1601305</td><td>16.585676</td><td>15.654064</td><td>15.148039</td><td>16.558054</td><td>15.629669</td><td>15.141826</td><td>0.032001704</td><td>0.043849397</td><td>0.045203492</td><td>0.072918765</td><td>0.06263939</td><td>0.07675708</td><td>0.10399303</td><td>0.07780949</td><td>0.14017467</td><td>0.016467415</td><td>0.021250801</td><td>0.032092847</td><td>0.0149329165</td><td>0.019061867</td><td>0.028947951</td><td>0.01369758</td><td>0.01736746</td><td>0.026648495</td><td>0.012623343</td><td>0.015980754</td><td>0.024998168</td><td>0.011793644</td><td>0.014977396</td><td>0.023862366</td><td>0.011184664</td><td>0.014255281</td><td>0.023120966</td><td>0.010785815</td><td>0.013740733</td><td>0.022603082</td><td>0.010472503</td><td>0.013351409</td><td>0.022360764</td><td>0.010212836</td><td>0.013043255</td><td>0.022296576</td><td>16.471447</td><td>0.3236818</td><td>1.9206839</td><td>2.3249283</td><td>0.0973919</td><td>15.540598</td><td>0.3247282</td><td>1.7439244</td><td>2.1774826</td><td>0.023485765</td><td>15.124181</td><td>0.16547345</td><td>1.4694684</td><td>3.3948786</td><td>0.028653827</td><td>0</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "SGA_ID  SGA_GALAXY          GALAXY         ... Z_COG_PARAMS_CHI2 ELLIPSEBIT\n",
       "int64    bytes16           bytes29         ...      float32        int32   \n",
       "------ ----------- ----------------------- ... ----------------- ----------\n",
       "     2  SGA-2020 2              PGC1283207 ...       0.011723555          0\n",
       "     3  SGA-2020 3              PGC1310416 ...        0.20391206          0\n",
       "     4  SGA-2020 4 SDSSJ145059.93+135143.0 ...         1.8054093          0\n",
       "     7  SGA-2020 7              PGC1742504 ...       0.004725194          0\n",
       "    18 SGA-2020 18  2MASXJ12340801+4535444 ...       0.028653827          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGA = Table.read('/global/cfs/cdirs/cosmo/data/sga/2020/SGA-2020.fits', 'ELLIPSE')\n",
    "\n",
    "## Create a dictionary of SGA IDs to find row indices \n",
    "SGA_dict = {}\n",
    "for i in range(len(SGA)):\n",
    "    SGA_dict[SGA['SGA_ID'][i]] = i\n",
    "\n",
    "SGA[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f70ba30-c59c-4e6f-8f78-bbafbb7db5cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Separation between Galaxies and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3d184-a377-4b3f-94fd-a3a0680cc046",
   "metadata": {},
   "source": [
    "Find all targets on each galaxy, and then calculate distance between SGA center coordinates and observation coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de47cfb-0760-41a8-a46e-3d09a7995bff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a525ebbb9148fe9a50cb15b9428724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tiron['SKY_FIBER_DIST'] = 0.\n",
    "tiron['SKY_FIBER_DIST_R26'] = 0.\n",
    "\n",
    "## For each SGA galaxy that has 1+ observations, calculate distance for all of its targets\n",
    "for sga_id in tqdm(np.unique(tiron['SGA_ID'])):\n",
    "    \n",
    "    ## Identify all galaxy targets on this galaxy\n",
    "    obs_idx = tiron['SGA_ID'] == sga_id\n",
    "    \n",
    "    ## Find galaxy index in SGA catalog\n",
    "    sga_idx = SGA_dict[sga_id]\n",
    "    \n",
    "    ## Calculate distance between each observation and the center of the galaxy\n",
    "    SGA_coords = SkyCoord(ra=SGA['RA'][sga_idx], \n",
    "                          dec=SGA['DEC'][sga_idx], \n",
    "                          unit=u.degree)\n",
    "    target_coords = SkyCoord(ra=tiron['RA'][obs_idx], \n",
    "                             dec=tiron['DEC'][obs_idx], \n",
    "                             unit=u.degree)\n",
    "    sep2d = target_coords.separation(SGA_coords)\n",
    "    \n",
    "    ## Add the distance to the tiron table\n",
    "    tiron['SKY_FIBER_DIST'][obs_idx] = sep2d\n",
    "    ## Add the distance in R26 to the tiron table \n",
    "    tiron['SKY_FIBER_DIST_R26'][obs_idx] = 2*sep2d.to('arcmin')/(SGA['D26'][sga_idx]*u.arcmin)\n",
    "\n",
    "## Isolate the centers to be those measurements where the distance is <.1*R26\n",
    "centers_boolean = tiron['SKY_FIBER_DIST_R26'] < 0.1\n",
    "\n",
    "## Sort observations into center and axis observations \n",
    "iron_centers = tiron[centers_boolean]\n",
    "iron_axis = tiron[~centers_boolean]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f7f3d-d393-41c0-ab49-99bd83ee6fd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleaning Iron Center Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8cf267-1d8e-4d6b-b138-22e2d4dd04ad",
   "metadata": {},
   "source": [
    "Only keep those observations with\n",
    " * `DELTACHI2` > 25\n",
    " * `ZWARN` == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b8c19d5-7747-4d99-9829-83e888e66891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_centers = iron_centers[(iron_centers['DELTACHI2'] > 25) & (iron_centers['ZWARN'] == 0)]\n",
    "\n",
    "## Check for multiple good center observations \n",
    "unique_ids, counts = np.unique(good_centers['SGA_ID'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de30ed-2506-4927-81d9-36f12c3f2501",
   "metadata": {},
   "source": [
    "If there's at least one good center observation, set the galaxy's redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d101817-1731-4890-8d65-1635cbcc29ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SGA['Z_DESI'] = np.nan\n",
    "SGA['ZERR_DESI'] = np.nan\n",
    "\n",
    "weights = 1./(good_centers['ZERR']**2)\n",
    "\n",
    "for sga_id in np.unique(good_centers['SGA_ID']):\n",
    "    \n",
    "    ## Find all the center observations of this galaxy\n",
    "    obs_idx = good_centers['SGA_ID'] == sga_id\n",
    "    \n",
    "    ## Find the row in SGA for this galaxy\n",
    "    SGA_idx = SGA_dict[sga_id]\n",
    "    \n",
    "    # Set the redshift of this galaxy to be weighted average of all good center observation redshifts\n",
    "    SGA['Z_DESI'][SGA_idx] = np.average(good_centers['Z'][obs_idx], \n",
    "                                        weights=weights[obs_idx])\n",
    "    SGA['ZERR_DESI'][SGA_idx] = np.sqrt(1./np.sum(weights[obs_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c25a0-7443-41a8-8b22-c63c569359f1",
   "metadata": {},
   "source": [
    "Determine how many observations at $.4R$ we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e88bba0-2f44-4d3c-87ed-498790d840a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11819  unique galaxies with center and .4R observations\n",
      "15.726793698105174 % of all Iron galaxies\n"
     ]
    }
   ],
   "source": [
    "## Include all observations where .38R < distance < .42R in our .4R values\n",
    "r0p4 = iron_axis[(iron_axis['SKY_FIBER_DIST_R26'] > 0.38) & (iron_axis['SKY_FIBER_DIST_R26'] < 0.42)]\n",
    "\n",
    "## Count how many of these are unique values\n",
    "unique_centers = np.unique(good_centers['SGA_ID'])\n",
    "unique_r0p4 = np.unique(r0p4['SGA_ID'])\n",
    "\n",
    "centers_and_p4s = []\n",
    "for i in unique_r0p4: \n",
    "    if i in unique_centers: \n",
    "        centers_and_p4s.append(i)\n",
    "\n",
    "## Output the number of observations that are generally good for TF fitting\n",
    "print(len(centers_and_p4s),\" unique galaxies with center and .4R observations\")\n",
    "\n",
    "## Find the percentage of all Iron galaxies that are generally good for TF fitting\n",
    "num_iron = len(np.unique(tiron['SGA_ID']))\n",
    "percentage_TF = 100*((len(centers_and_p4s))/num_iron)\n",
    "print(percentage_TF,\"% of all Iron galaxies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e416821-3b21-4d57-9fdb-08fa1bbb359a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster Membership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e3ab0-8305-44d0-87f2-9c9894976da8",
   "metadata": {},
   "source": [
    "Following Cosmicflows4 (Kourkchi et al. 2020), cluster membership is defined as\n",
    "- $R_p < 1.5R_{2t}$ and $v < V_c \\pm 3\\sigma_p$\n",
    "- $1.5R_{2t} \\leq R_p < 3R_{2t}$ and $v < V_c \\pm 2\\sigma_p$\n",
    "\n",
    "where $R_p$ is the projected distance from the cluster center, $R_{2t}$ is the cluster projected second turnaround radius, $\\sigma_p$ is the projected velocity dispersion of the cluster, and $V_c$ is the average heliocentric radial velocity of the cluster.\n",
    "\n",
    "Note: this has been done in `Iron_Cluster_Membership_SunnyW.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "597d5bca-81d1-4a1b-9e24-688bfce8296e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## read in data from files formed in `Iron_Cluster_Membership_SunnyW.ipynb`\n",
    "\n",
    "suited_clusters = [100007, 100042, 100067, 100073, 100077, 100081, 100168, 100282, 101823, 103175, 103182, 160002, 200011]\n",
    "SGA_IDs_in_clusters = []\n",
    "\n",
    "for i in range(len(suited_clusters)):\n",
    "    file = ascii.read('output_' + str(suited_clusters[i]) + '.txt', format = 'commented_header')\n",
    "    SGA_IDs_in_clusters.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc52565-f933-4b30-b212-273e247b517f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Abell-2151 Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a4150-d4d7-416f-a601-9e515d0b40cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_4r_in_Abell, SGA_in_Abell, SGA_ID_in_Abell, centers_in_Abell, axis_in_Abell, Abell_coords, v_Abell, sep_Abell = cluster_membership(100007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8046bbc-4274-45e1-b870-eaedd8eb486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set active row for Abell-2151 nest and base values \n",
    "active_row_Abell = table3_dict[100007]\n",
    "R2t_Abell = table3[\"R2t\"][active_row_Abell]\n",
    "sigma_Abell = table3[\"sigP\"][active_row_Abell]\n",
    "\n",
    "## Find the coordinates for each cluster\n",
    "Abell_coords = SkyCoord(table3[\"SGLON\"][active_row_Abell]*u.degree, \n",
    "                   table3[\"SGLAT\"][active_row_Abell]*u.degree, \n",
    "                   frame='supergalactic')\n",
    "\n",
    "group_coords = SkyCoord(table2['SGLON']*u.degree, \n",
    "                    table2['SGLAT']*u.degree, \n",
    "                    frame='supergalactic')\n",
    "\n",
    "## Match cluster to group coordinates \n",
    "idx_Abell, d2d_Abell, d3d_Abell = Abell_coords.match_to_catalog_sky(group_coords)\n",
    "v_Abell = table2[\"__HV_\"][idx_Abell]\n",
    "\n",
    "## Match SGA coordinates from unique galaxies to nearest cluster\n",
    "SGA_coords_Abell = SkyCoord(TF_SGA_cp4['RA'], TF_SGA_cp4['DEC'], unit='deg')\n",
    "sep_Abell = Abell_coords.separation(SGA_coords_Abell)\n",
    "\n",
    "## Convert R2t to an angle \n",
    "R2t_Abell_angle = (R2t_Abell/(v_Abell/H0))*u.radian\n",
    "\n",
    "SGA_in_cluster1_Abell = (sep_Abell < 1.5*R2t_Abell_angle) & (TF_SGA_cp4[\"Z_DESI\"]*c > v_Abell - 3*sigma_Abell) & (TF_SGA_cp4[\"Z_DESI\"]*c < v_Abell + 3*sigma_Abell)\n",
    "SGA_in_cluster2_Abell = (sep_Abell >= 1.5*R2t_Abell_angle) & (sep_Abell < 3*R2t_Abell_angle) & (TF_SGA_cp4[\"Z_DESI\"]*c > v_Abell - 2*sigma_Abell) & (TF_SGA_cp4[\"Z_DESI\"]*c < v_Abell + 2*sigma_Abell)\n",
    "\n",
    "SGA_in_Abell = SGA_in_cluster1_Abell | SGA_in_cluster2_Abell\n",
    "\n",
    "## Keep observations that are within Abell-2151\n",
    "SGA_ID_in_Abell = TF_SGA_cp4[\"SGA_ID\"][SGA_in_Abell]\n",
    "\n",
    "## Gather centers and axes in the cluster\n",
    "centers_in_Abell = good_centers[np.in1d(good_centers['SGA_ID'], SGA_ID_in_Abell)]\n",
    "axis_in_Abell = iron_axis[np.in1d(iron_axis['SGA_ID'], SGA_ID_in_Abell)]\n",
    "\n",
    "c_4r_in_Abell.append(SGA_ID_in_Abell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efb4c4-c827-4c41-99f9-69c4a3fa5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a bar graph of the angular separation \n",
    "plt.hist(sep_Abell[SGA_in_Abell].to_value('degree'), bins=np.arange(0,5, 0.5))\n",
    "plt.xlabel('SGA-Abell-2151 Angular Separation [deg]')\n",
    "plt.ylabel('number of galaxies');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd98a21-1afa-4790-ae0e-dcdb382244b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the physical locations and the redshifts of the cluster\n",
    "\n",
    "plt.figure(figsize=(15,5), tight_layout=True)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(centers_in_Abell['TARGET_RA'], centers_in_Abell['TARGET_DEC'], '.')\n",
    "plt.plot(Abell_coords.transform_to('icrs').ra.deg, Abell_coords.transform_to('icrs').dec.deg, 'kx', ms=10, mew=5)\n",
    "plt.xlabel(r'$\\alpha$ [deg]')\n",
    "plt.ylabel(r'$\\delta$ [deg]')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(centers_in_Abell['Z'], centers_in_Abell['TARGET_DEC'], '.')\n",
    "plt.plot(v_Abell/c, Abell_coords.transform_to('icrs').dec.deg, 'kx', ms=10, mew=5)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel(r'$\\delta$ [deg]')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.hist(centers_in_Abell['Z'], bins=np.arange(0.02, .06, 0.01))\n",
    "plt.vlines(v_Abell/c, 0, 100, colors='k', linestyles='dotted')\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('number of galaxies')\n",
    "plt.ylim(ymax=95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292ea32-8849-4415-9940-6a1d73961203",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_SGAids_Abell, axis_counts_Abell = np.unique(axis_in_Abell['SGA_ID'], return_counts=True)\n",
    "center_SGAids_Abell, center_counts_Abell = np.unique(centers_in_Abell['SGA_ID'], return_counts=True)\n",
    "\n",
    "counts_Abell = []\n",
    "\n",
    "for sga_id in SGA_ID_in_Abell:\n",
    "    \n",
    "    center_count_Abell = 0\n",
    "    axis_count_Abell = 0\n",
    "    \n",
    "    if sga_id in center_SGAids_Abell:\n",
    "        \n",
    "        center_count_Abell = center_counts_Abell[center_SGAids_Abell == sga_id]\n",
    "        \n",
    "    if sga_id in axis_SGAids_Abell:\n",
    "        \n",
    "        axis_count_Abell = axis_counts_Abell[axis_SGAids_Abell == sga_id]\n",
    "        \n",
    "    count = center_count_Abell + axis_count_Abell\n",
    "    \n",
    "    if count > 1:\n",
    "        \n",
    "        counts_Abell.append(count)\n",
    "        \n",
    "\n",
    "plt.figure(tight_layout=True)\n",
    "\n",
    "plt.hist(np.array(counts), bins=np.arange(2,15))\n",
    "\n",
    "plt.xlabel('Observations per SGA_ID in Abell-2151')\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e667c-56d6-441d-a11b-5aee242bf66b",
   "metadata": {},
   "source": [
    "### Calculate the rotational velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac813d-efe5-49eb-b613-d7f3d60f4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_in_Abell['SKY_FIBER_DIST'] = 0.\n",
    "axis_in_Abell['SKY_FIBER_DIST_R26'] = 0.\n",
    "axis_in_Abell['V_ROT'] = np.nan\n",
    "axis_in_Abell['V_ROT_ERR'] = np.nan\n",
    "\n",
    "\n",
    "# For each SGA galaxy that has at least one center observation, calculate the \n",
    "# distance for all of that galaxy's targets\n",
    "for sga_gal in np.unique(centers_in_Abell['SGA_ID']):\n",
    "    \n",
    "    # Identify all galaxy targets on this galaxy\n",
    "    obs_idx = axis_in_Abell['SGA_ID'] == sga_gal\n",
    "    \n",
    "    # Find galaxy index in SGA catalog\n",
    "    sga_idx = SGA_dict[sga_gal]\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Calculate distance between each observation and the center\n",
    "    #---------------------------------------------------------------------------\n",
    "    center_coords_Abell = SkyCoord(ra=SGA['RA'][sga_idx], \n",
    "                             dec=SGA['DEC'][sga_idx], \n",
    "                             unit=u.degree)\n",
    "    target_coords_Abell = SkyCoord(ra=axis_in_Abell['RA'][obs_idx], \n",
    "                             dec=axis_in_Abell['DEC'][obs_idx], \n",
    "                             unit=u.degree)\n",
    "    \n",
    "    sep2d_Abell = target_coords_Abell.separation(center_coords_Abell)\n",
    "    \n",
    "    axis_in_Abell['SKY_FIBER_DIST'][obs_idx] = sep2d_Abell\n",
    "    axis_in_Abell['SKY_FIBER_DIST_R26'][obs_idx] = 2*sep2d_Abell.to('arcmin')/(SGA['D26'][sga_idx]*u.arcmin)\n",
    "    #---------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Calculate rotational velocity\n",
    "    #---------------------------------------------------------------------------\n",
    "    # Use the average redshift of all center observations for the systemic velocity\n",
    "    z_center_Abell = np.mean(SGA['Z_DESI'][sga_idx])\n",
    "    z_err_center2_Abell = SGA['ZERR_DESI'][sga_idx]**2\n",
    "\n",
    "    # Calculate rotational velocity for all observations of the galaxy\n",
    "    axis_in_Abell['V_ROT'][obs_idx] = c*(axis_in_Abell['Z'][obs_idx] - z_center_Abell)\n",
    "    axis_in_Abell['V_ROT_ERR'][obs_idx] = c*np.sqrt(axis_in_Abell['ZERR'][obs_idx]**2 + z_err_center2_Abell)\n",
    "    #---------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Correct rotational velocities for inclination angle\n",
    "    #---------------------------------------------------------------------------\n",
    "    cosi2 = (SGA['BA'][sga_idx]**2 - q0**2)/(1 - q0**2)\n",
    "    \n",
    "    # Galaxies with b/a < q0\n",
    "    if cosi2 < 0:\n",
    "        cosi2 = 0\n",
    "    \n",
    "    axis_in_Abell['V_ROT'][obs_idx] /= np.sin(np.arccos(np.sqrt(cosi2)))\n",
    "    #---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878de15d-113b-49e1-b74e-fa756fe31d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(tight_layout=True)\n",
    "\n",
    "plt.hist(np.abs(axis_in_Abell['V_ROT']), bins=np.linspace(0, 1000, 100))\n",
    "\n",
    "plt.xlabel('$V_{rot}$ [km/s]')\n",
    "plt.ylabel('number of observations');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d02a1-80d8-4f73-b708-ce8ee940ec23",
   "metadata": {},
   "source": [
    "### Cut for Abell-2151 galaxies suitable for calibrating the TFR\n",
    "\n",
    "Requirements:\n",
    " * $10 < V_{rot} < 1000$ km/s at $0.33R_{26}$\n",
    " * $\\Delta V / V_{min} \\leq 5$\n",
    " * $i > 45^\\circ$\n",
    " * Spiral-type morphology\n",
    " * Passes visual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feab612-8de2-4b82-b417-03740dd106c4",
   "metadata": {},
   "source": [
    "#### Velocity Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fed72f-569f-4d9d-b5c8-7fe77ac931b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0p4_Abell = (axis_in_Abell['SKY_FIBER_DIST_R26'] > 0.38) & (axis_in_Abell['SKY_FIBER_DIST_R26'] < 0.42)\n",
    "\n",
    "Vgood_Abell = (np.abs(axis_in_Abell['V_ROT']) < 1000) & (np.abs(axis_in_Abell['V_ROT']) > 10)\n",
    "\n",
    "good_axis_in_Abell = axis_in_Abell[r0p4_Abell & Vgood_Abell]\n",
    "\n",
    "print(len(good_axis_in_Abell), len(np.unique(good_axis_in_Abell['SGA_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b321a99-efc7-44b7-99ef-175e23fa4b9e",
   "metadata": {},
   "source": [
    "#### Relative Velocity Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e65d86d-5662-41f8-9885-f72934951657",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_deltaV_Abell = np.ones(len(good_axis_in_Abell), dtype=bool)\n",
    "\n",
    "for sga_id in np.unique(good_axis_in_Abell['SGA_ID']):\n",
    "    \n",
    "    # Identify all galaxy targets on this galaxy\n",
    "    obs_idx = good_axis_in_Abell['SGA_ID'] == sga_id\n",
    "    \n",
    "    n_obs = np.sum(obs_idx)\n",
    "    \n",
    "    if n_obs > 1:\n",
    "        \n",
    "        Vmin_Abell = np.min(np.abs(good_axis_in_Abell['V_ROT'][obs_idx]))\n",
    "        Vmax_Abell = np.max(np.abs(good_axis_in_Abell['V_ROT'][obs_idx]))\n",
    "        \n",
    "        v_norm_min_Abell = np.abs(good_axis_in_Abell['V_ROT'][obs_idx])/Vmin_Abell\n",
    "        v_norm_max_Abell = np.abs(good_axis_in_Abell['V_ROT'][obs_idx])/Vmax_Abell\n",
    "        \n",
    "        diff_matrix = np.abs(good_axis_in_Abell['V_ROT'][obs_idx]).reshape(n_obs, 1) - np.abs(good_axis_in_Abell['V_ROT'][obs_idx]).reshape(1, n_obs)\n",
    "        \n",
    "        diff_matrix_norm = diff_matrix/Vmin_Abell\n",
    "        \n",
    "        if np.any(np.abs(diff_matrix_norm) > 5.):\n",
    "            \n",
    "            '''\n",
    "            print(sga_id)\n",
    "            print(diff_matrix_norm)\n",
    "            print(1/v_norm_min.data)\n",
    "            print(v_norm_max.data)\n",
    "            print(good_axis_inComa[['TARGETID', 'V_ROT', 'PVTYPE', 'FILENAME', 'DELTACHI2', 'ZWARN']][obs_idx].pprint(max_width=-1))\n",
    "            ''';\n",
    "            \n",
    "            # Remove all observations with DELTACHI2 < 25\n",
    "            # Note: This also typically removes observations with ZWARN != 0\n",
    "            deltachi2_idx = good_axis_in_Abell['DELTACHI2'] >= 25\n",
    "            \n",
    "            good_deltaV_Abell[obs_idx & ~deltachi2_idx] = False\n",
    "            \n",
    "            good_obs_idx = obs_idx & deltachi2_idx\n",
    "            \n",
    "            n_obs_good = np.sum(good_obs_idx)\n",
    "            \n",
    "            # Check to make sure that, if there are still multiple observations, they all satisfy our relative velocity criteria\n",
    "            if n_obs_good > 1:\n",
    "                \n",
    "                Vmin_Abell = np.min(np.abs(good_axis_in_Abell['V_ROT'][good_obs_idx]))\n",
    "                \n",
    "                diff_matrix = np.abs(good_axis_in_Abell['V_ROT'][good_obs_idx]).reshape(n_obs_good, 1) - np.abs(good_axis_in_Abell['V_ROT'][good_obs_idx]).reshape(1, n_obs_good)\n",
    "                \n",
    "                diff_matrix_norm = diff_matrix/Vmin_Abell\n",
    "                \n",
    "                if np.any(np.abs(diff_matrix_norm) > 5.):\n",
    "                    '''\n",
    "                    print(sga_id)\n",
    "                    print(diff_matrix_norm)\n",
    "                    print(good_axis_inComa[['TARGETID', 'V_ROT', 'PVTYPE', 'FILENAME', 'DELTACHI2', 'ZWARN']][obs_idx].pprint(max_width=-1))\n",
    "                    ''';\n",
    "                    # Set all of these so that we don't look at this galaxy\n",
    "                    good_deltaV_Abell[good_obs_idx] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff63610-7f48-45b3-af58-4f3586fcb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_deltaV_axis_in_Abell = good_axis_in_Abell[good_deltaV_Abell]\n",
    "\n",
    "print(len(good_deltaV_axis_in_Abell), len(np.unique(good_deltaV_axis_in_Abell['SGA_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cace82-8f8b-48ae-a189-1fd38b51973d",
   "metadata": {},
   "source": [
    "#### Inclination Angle Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192dce1-2ee4-4c0d-8776-c2aa06881fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGA['cosi2'] = (SGA['BA']**2 - q0**2)/(1 - q0**2)\n",
    "SGA['cosi2'][SGA['cosi2'] < 0] = 0\n",
    "\n",
    "good_deltaV_axis_in_Abell['iSGA'] = -1\n",
    "\n",
    "for i in range(len(good_deltaV_axis_in_Abell)):\n",
    "    \n",
    "    # Find galaxy in SGA\n",
    "    sga_idx = SGA_dict[good_deltaV_axis_in_Abell['SGA_ID'][i]]\n",
    "    \n",
    "    good_deltaV_axis_in_Abell['iSGA'][i] = sga_idx\n",
    "    \n",
    "good_deltaV_axis_in_Abell['cosi2'] = SGA['cosi2'][good_deltaV_axis_in_Abell['iSGA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49974a-69a9-4630-8517-471bcfcaf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_min = 45. # degrees\n",
    "\n",
    "cosi2_max = np.cos(i_min*np.pi/180.)**2\n",
    "\n",
    "edge = good_deltaV_axis_in_Abell['cosi2'] <= cosi2_max\n",
    "\n",
    "good_edge_axis_in_Abell = good_deltaV_axis_in_Abell[edge]\n",
    "\n",
    "print(len(good_edge_axis_in_Abell), len(np.unique(good_edge_axis_in_Abell['SGA_ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947753e8-810d-42db-bc3e-2b3aec024bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(tight_layout=True)\n",
    "\n",
    "plt.hist(np.arccos(np.sqrt(good_edge_axis_in_Abell['cosi2']))*180/np.pi, bins=np.linspace(0, 90, 10))\n",
    "\n",
    "plt.xlabel('inclination angle [deg]')\n",
    "plt.ylabel('number of observations');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8239d-c716-43cf-af31-9fed88476698",
   "metadata": {},
   "source": [
    "#### Morphology Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f159f-111e-47be-917c-ba62520deda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_edge_axis_in_Abell['MORPHTYPE'] = SGA['MORPHTYPE'][good_edge_axis_in_Abell['iSGA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94c0d7-2964-4763-bf03-047d9ab6034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spirals_Abell = np.zeros(len(good_edge_axis_in_Abell), dtype=bool)\n",
    "\n",
    "for i in range(len(good_edge_axis_in_Abell)):\n",
    "    \n",
    "    try:    \n",
    "        if (good_edge_axis_in_Abell['MORPHTYPE'][i][0] == 'S') and (good_edge_axis_in_Abell['MORPHTYPE'][i][:2] != 'S0'):\n",
    "            spirals_Abell[i] = True\n",
    "    except IndexError:\n",
    "        print(good_edge_axis_in_Abell['MORPHTYPE'][i])\n",
    "\n",
    "good_edge_spirals_axis_in_Abell = good_edge_axis_in_Abell[spirals_Abell]\n",
    "\n",
    "print(len(good_edge_spirals_axis_in_Abell), len(np.unique(good_edge_spirals_axis_in_Abell['SGA_ID'])))\n",
    "\n",
    "VI_good_edge_spirals_axis_in_Abell = good_edge_spirals_axis_in_Abell ## delete this line when VI completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c705f-7bba-45bf-a2a2-3c762a3337b1",
   "metadata": {},
   "source": [
    "Stopped at visual inspection cut because the number of galaxies dropped below 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df16264-e46a-4849-8e1a-a079363354d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visual Inspection Cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2fb5d-a8f9-4021-9510-88a3873ecbc2",
   "metadata": {},
   "source": [
    "The visual inspection cut still needs to be done, and there is still a problem with the data above, but we're adding the fitting of the TFR code below so that it should work when the data <i>is</i> correct. At present, the variable `VI_good_edge_spirals_axis_in_Abell = good_edge_spirals_axis_in_Abell`, because the VI hasn't been done yet. Use `VI_good_edge_spirals_axis_in_Abell` to store the results of the visual inspection so the code further down works, and delete the line indicated in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b5e92a-83af-4831-ad43-218f71089259",
   "metadata": {
    "tags": []
   },
   "source": [
    "Compute the weighted average velocity for those galaxies with more than one observation at $0.33R_{26}$:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\overline{v} = \\frac{\\sum_i w_i v_i}{\\sum_i w_i}\n",
    "\\end{equation}\n",
    "where $w_i = 1/\\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13846534-7edb-4ad7-bbb2-6cbaba9c1022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SGA['V_0p33R26'] = np.nan\n",
    "SGA['V_0p33R26_err'] = np.nan\n",
    "\n",
    "weights_Abell = 1./(VI_good_edge_spirals_axis_in_Abell['V_ROT_ERR']**2)\n",
    "\n",
    "for sga_id in np.unique(VI_good_edge_spirals_axis_in_Abell['SGA_ID']):\n",
    "    \n",
    "    # Identify all galaxy targets on this galaxy\n",
    "    obs_idx = VI_good_edge_spirals_axis_in_Abell['SGA_ID'] == sga_id\n",
    "    \n",
    "    SGA['V_0p33R26'][SGA_dict[sga_id]] = np.average(np.abs(VI_good_edge_spirals_axis_in_Abell['V_ROT'][obs_idx])) ## fiddled with this slightly, check jointlinefit.ipynb for original\n",
    "\n",
    "    SGA['V_0p33R26_err'][SGA_dict[sga_id]] = np.sqrt(1./np.sum(weights_Abell[obs_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dda37-1a62-4d72-9c40-2e6c0a36a404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a catalog of just those galaxies with velocities\n",
    "SGA_TF_Abell = SGA[np.isfinite(SGA['V_0p33R26']) & (SGA['R_MAG_SB26'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686df1e-2b08-4014-876d-f6b61b813f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,5), tight_layout=True)\n",
    "\n",
    "x_Abell = np.log10(SGA_TF_Abell['V_0p33R26'])\n",
    "y_Abell = SGA_TF_Abell['R_MAG_SB26']\n",
    "\n",
    "xerr_Abell = SGA_TF_Abell['V_0p33R26_err']/SGA_TF_Abell['V_0p33R26']\n",
    "yerr_Abell = SGA_TF_Abell['R_MAG_SB26_ERR']\n",
    "\n",
    "plt.errorbar(x_Abell, y_Abell, \n",
    "             yerr_Abell, xerr_Abell, \n",
    "             fmt='.')\n",
    "\n",
    "plt.xlim([1.5, 2.5])\n",
    "plt.ylim([18, 14])\n",
    "\n",
    "plt.xlabel('log($V_{rot}$ [km/s])')\n",
    "plt.ylabel('$m_r (26)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8922b3-180d-4457-b8a4-314f1aece915",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Virgo Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2388f2d-3906-4f0f-89ed-4c067e7cc237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(c_4r_in_Virgo, SGA_in_Virgo, SGA_ID_in_Virgo, centers_in_Virgo, axis_in_Virgo, Virgo_coords, v_Virgo, sep_Virgo) = cluster_membership(100002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf0172-0c4b-492e-bfa6-28d191a75060",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set active row for Virgo nest and base values \n",
    "active_row_Virgo = table3_dict[100002]\n",
    "R2t_Virgo = table3[\"R2t\"][active_row_Virgo]\n",
    "sigma_Virgo = table3[\"sigP\"][active_row_Virgo]\n",
    "\n",
    "## Find the coordinates for each cluster\n",
    "Virgo_coords = SkyCoord(table3[\"SGLON\"][active_row_Virgo]*u.degree, \n",
    "                   table3[\"SGLAT\"][active_row_Virgo]*u.degree, \n",
    "                   frame='supergalactic')\n",
    "\n",
    "group_coords = SkyCoord(table2['SGLON']*u.degree, \n",
    "                    table2['SGLAT']*u.degree, \n",
    "                    frame='supergalactic')\n",
    "\n",
    "## Match cluster to group coordinates \n",
    "idx_Virgo, d2d_Virgo, d3d_Virgo = Virgo_coords.match_to_catalog_sky(group_coords)\n",
    "v_Virgo = table2[\"__HV_\"][idx_Virgo]\n",
    "\n",
    "## Match SGA coordinates from unique galaxies to nearest cluster\n",
    "SGA_coords_Virgo = SkyCoord(TF_SGA_cp4['RA'], TF_SGA_cp4['DEC'], unit='deg')\n",
    "sep_Virgo = Virgo_coords.separation(SGA_coords_Virgo)\n",
    "\n",
    "## Convert R2t to an angle \n",
    "R2t_Virgo_angle = (R2t_Virgo/(v_Virgo/H0))*u.radian\n",
    "\n",
    "SGA_in_cluster1_Virgo = (sep_Virgo < 1.5*R2t_Virgo_angle) & (TF_SGA_cp4[\"Z_DESI\"]*c > v_Virgo - 3*sigma_Virgo) & (TF_SGA_cp4[\"Z_DESI\"]*c < v_Virgo + 3*sigma_Virgo)\n",
    "SGA_in_cluster2_Virgo = (sep_Virgo >= 1.5*R2t_Virgo_angle) & (sep_Virgo < 3*R2t_Virgo_angle) & (TF_SGA_cp4[\"Z_DESI\"]*c > v_Virgo - 2*sigma_Virgo) & (TF_SGA_cp4[\"Z_DESI\"]*c < v_Virgo + 2*sigma_Virgo)\n",
    "\n",
    "SGA_in_Virgo = SGA_in_cluster1_Virgo | SGA_in_cluster2_Virgo\n",
    "\n",
    "## Keep observations that are within Virgo-2151\n",
    "SGA_ID_in_Virgo = TF_SGA_cp4[\"SGA_ID\"][SGA_in_Virgo]\n",
    "\n",
    "## Gather centers and axes in the cluster\n",
    "centers_in_Virgo = good_centers[np.in1d(good_centers['SGA_ID'], SGA_ID_in_Virgo)]\n",
    "axis_in_Virgo = iron_axis[np.in1d(iron_axis['SGA_ID'], SGA_ID_in_Virgo)]\n",
    "\n",
    "c_4r_in_Virgo.append(SGA_ID_in_Virgo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848db4a-8e98-4c12-85da-f900f7f7a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a bar graph of the angular separation \n",
    "plt.hist(sep_Virgo[SGA_in_Virgo].to_value('degree'), bins=np.arange(0,25, 1))\n",
    "plt.xlabel('SGA-Virgo Angular Separation [deg]')\n",
    "plt.ylabel('number of galaxies');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db652c5-cc3b-456f-8634-5c0f98c37ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the physical locations and the redshifts of the cluster\n",
    "\n",
    "plt.figure(figsize=(15,5), tight_layout=True)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(centers_in_Virgo['TARGET_RA'], centers_in_Virgo['TARGET_DEC'], '.')\n",
    "plt.plot(Virgo_coords.transform_to('icrs').ra.deg, Virgo_coords.transform_to('icrs').dec.deg, 'kx', ms=10, mew=5)\n",
    "plt.xlabel(r'$\\alpha$ [deg]')\n",
    "plt.ylabel(r'$\\delta$ [deg]')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(centers_in_Virgo['Z'], centers_in_Virgo['TARGET_DEC'], '.')\n",
    "plt.plot(v_Virgo/c, Virgo_coords.transform_to('icrs').dec.deg, 'kx', ms=10, mew=5)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel(r'$\\delta$ [deg]')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.hist(centers_in_Virgo['Z'], bins=np.arange(0, .01, 0.001))\n",
    "plt.vlines(v_Virgo/c, 0, 100, colors='k', linestyles='dotted')\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('number of galaxies')\n",
    "plt.ylim(ymax=95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295a477-b0f5-47cc-9c68-e0f588d08b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_SGAids_Virgo, axis_counts_Virgo = np.unique(axis_in_Virgo['SGA_ID'], return_counts=True)\n",
    "center_SGAids_Virgo, center_counts_Virgo = np.unique(centers_in_Virgo['SGA_ID'], return_counts=True)\n",
    "\n",
    "counts_Virgo = []\n",
    "\n",
    "for sga_id in SGA_ID_in_Virgo:\n",
    "    \n",
    "    center_count_Virgo = 0\n",
    "    axis_count_Virgo = 0\n",
    "    \n",
    "    if sga_id in center_SGAids_Virgo:\n",
    "        \n",
    "        center_count_Virgo = center_counts_Virgo[center_SGAids_Virgo == sga_id]\n",
    "        \n",
    "    if sga_id in axis_SGAids_Virgo:\n",
    "        \n",
    "        axis_count_Virgo = axis_counts_Virgo[axis_SGAids_Virgo == sga_id]\n",
    "        \n",
    "    count = center_count_Virgo + axis_count_Virgo\n",
    "    \n",
    "    if count > 1:\n",
    "        \n",
    "        counts_Virgo.append(count)\n",
    "        \n",
    "\n",
    "plt.figure(tight_layout=True)\n",
    "\n",
    "plt.hist(np.array(counts), bins=np.arange(2,15))\n",
    "\n",
    "plt.xlabel('Observations per SGA_ID in Virgo-2151')\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce425a-8757-472a-8e89-43e091faa5ca",
   "metadata": {},
   "source": [
    "### Calculate the rotational velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2edfe1d-bc38-44c9-9e89-6d783b9c9c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_in_Virgo['SKY_FIBER_DIST'] = 0.\n",
    "axis_in_Virgo['SKY_FIBER_DIST_R26'] = 0.\n",
    "axis_in_Virgo['V_ROT'] = np.nan\n",
    "axis_in_Virgo['V_ROT_ERR'] = np.nan\n",
    "\n",
    "\n",
    "# For each SGA galaxy that has at least one center observation, calculate the \n",
    "# distance for all of that galaxy's targets\n",
    "for sga_gal in np.unique(centers_in_Virgo['SGA_ID']):\n",
    "    \n",
    "    # Identify all galaxy targets on this galaxy\n",
    "    obs_idx = axis_in_Virgo['SGA_ID'] == sga_gal\n",
    "    \n",
    "    # Find galaxy index in SGA catalog\n",
    "    sga_idx = SGA_dict[sga_gal]\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Calculate distance between each observation and the center\n",
    "    #---------------------------------------------------------------------------\n",
    "    center_coords_Virgo = SkyCoord(ra=SGA['RA'][sga_idx], \n",
    "                             dec=SGA['DEC'][sga_idx], \n",
    "                             unit=u.degree)\n",
    "    target_coords_Virgo = SkyCoord(ra=axis_in_Virgo['RA'][obs_idx], \n",
    "                             dec=axis_in_Virgo['DEC'][obs_idx], \n",
    "                             unit=u.degree)\n",
    "    \n",
    "    sep2d_Virgo = target_coords_Virgo.separation(center_coords_Virgo)\n",
    "    \n",
    "    axis_in_Virgo['SKY_FIBER_DIST'][obs_idx] = sep2d_Virgo\n",
    "    axis_in_Virgo['SKY_FIBER_DIST_R26'][obs_idx] = 2*sep2d_Virgo.to('arcmin')/(SGA['D26'][sga_idx]*u.arcmin)\n",
    "    #---------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Calculate rotational velocity\n",
    "    #---------------------------------------------------------------------------\n",
    "    # Use the average redshift of all center observations for the systemic velocity\n",
    "    z_center_Virgo = np.mean(SGA['Z_DESI'][sga_idx])\n",
    "    z_err_center2_Virgo = SGA['ZERR_DESI'][sga_idx]**2\n",
    "\n",
    "    # Calculate rotational velocity for all observations of the galaxy\n",
    "    axis_in_Virgo['V_ROT'][obs_idx] = c*(axis_in_Virgo['Z'][obs_idx] - z_center_Virgo)\n",
    "    axis_in_Virgo['V_ROT_ERR'][obs_idx] = c*np.sqrt(axis_in_Virgo['ZERR'][obs_idx]**2 + z_err_center2_Virgo)\n",
    "    #---------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Correct rotational velocities for inclination angle\n",
    "    #---------------------------------------------------------------------------\n",
    "    cosi2 = (SGA['BA'][sga_idx]**2 - q0**2)/(1 - q0**2)\n",
    "    \n",
    "    # Galaxies with b/a < q0\n",
    "    if cosi2 < 0:\n",
    "        cosi2 = 0\n",
    "    \n",
    "    axis_in_Virgo['V_ROT'][obs_idx] /= np.sin(np.arccos(np.sqrt(cosi2)))\n",
    "    #---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2670d-29ea-4805-8781-7406f8500de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(tight_layout=True)\n",
    "\n",
    "plt.hist(np.abs(axis_in_Virgo['V_ROT']), bins=np.linspace(0, 1000, 100))\n",
    "\n",
    "plt.xlabel('$V_{rot}$ [km/s]')\n",
    "plt.ylabel('number of observations');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e2d34-cabf-4c24-b176-6ab3f13cb976",
   "metadata": {},
   "source": [
    "### Cut for Virgo galaxies suitable for calibrating the TFR\n",
    "\n",
    "Requirements:\n",
    " * $10 < V_{rot} < 1000$ km/s at $0.33R_{26}$\n",
    " * $\\Delta V / V_{min} \\leq 5$\n",
    " * $i > 45^\\circ$\n",
    " * Spiral-type morphology\n",
    " * Passes visual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f64cd-5ea9-40f4-8cd3-27a72c11cd8c",
   "metadata": {},
   "source": [
    "#### Velocity Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f0862-1b34-4e35-9b69-08bf47ac3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0p4_Virgo = (axis_in_Virgo['SKY_FIBER_DIST_R26'] > 0.38) & (axis_in_Virgo['SKY_FIBER_DIST_R26'] < 0.42)\n",
    "\n",
    "Vgood_Virgo = (np.abs(axis_in_Virgo['V_ROT']) < 1000) & (np.abs(axis_in_Virgo['V_ROT']) > 10)\n",
    "\n",
    "good_axis_in_Virgo = axis_in_Virgo[r0p4_Virgo & Vgood_Virgo]\n",
    "\n",
    "print(len(good_axis_in_Virgo), len(np.unique(good_axis_in_Virgo['SGA_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ede13-233f-4e85-8154-faecf6f77fe3",
   "metadata": {},
   "source": [
    "#### Relative Velocity Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7745739-868c-4370-9700-f38e6a8838c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_deltaV_Virgo = np.ones(len(good_axis_in_Virgo), dtype=bool)\n",
    "\n",
    "for sga_id in np.unique(good_axis_in_Virgo['SGA_ID']):\n",
    "    \n",
    "    # Identify all galaxy targets on this galaxy\n",
    "    obs_idx = good_axis_in_Virgo['SGA_ID'] == sga_id\n",
    "    \n",
    "    n_obs = np.sum(obs_idx)\n",
    "    \n",
    "    if n_obs > 1:\n",
    "        \n",
    "        Vmin_Virgo = np.min(np.abs(good_axis_in_Virgo['V_ROT'][obs_idx]))\n",
    "        Vmax_Virgo = np.max(np.abs(good_axis_in_Virgo['V_ROT'][obs_idx]))\n",
    "        \n",
    "        v_norm_min_Virgo = np.abs(good_axis_in_Virgo['V_ROT'][obs_idx])/Vmin_Virgo\n",
    "        v_norm_max_Virgo = np.abs(good_axis_in_Virgo['V_ROT'][obs_idx])/Vmax_Virgo\n",
    "        \n",
    "        diff_matrix = np.abs(good_axis_in_Virgo['V_ROT'][obs_idx]).reshape(n_obs, 1) - np.abs(good_axis_in_Virgo['V_ROT'][obs_idx]).reshape(1, n_obs)\n",
    "        \n",
    "        diff_matrix_norm = diff_matrix/Vmin_Virgo\n",
    "        \n",
    "        if np.any(np.abs(diff_matrix_norm) > 5.):\n",
    "            \n",
    "            '''\n",
    "            print(sga_id)\n",
    "            print(diff_matrix_norm)\n",
    "            print(1/v_norm_min.data)\n",
    "            print(v_norm_max.data)\n",
    "            print(good_axis_inComa[['TARGETID', 'V_ROT', 'PVTYPE', 'FILENAME', 'DELTACHI2', 'ZWARN']][obs_idx].pprint(max_width=-1))\n",
    "            ''';\n",
    "            \n",
    "            # Remove all observations with DELTACHI2 < 25\n",
    "            # Note: This also typically removes observations with ZWARN != 0\n",
    "            deltachi2_idx = good_axis_in_Virgo['DELTACHI2'] >= 25\n",
    "            \n",
    "            good_deltaV_Virgo[obs_idx & ~deltachi2_idx] = False\n",
    "            \n",
    "            good_obs_idx = obs_idx & deltachi2_idx\n",
    "            \n",
    "            n_obs_good = np.sum(good_obs_idx)\n",
    "            \n",
    "            # Check to make sure that, if there are still multiple observations, they all satisfy our relative velocity criteria\n",
    "            if n_obs_good > 1:\n",
    "                \n",
    "                Vmin_Virgo = np.min(np.abs(good_axis_in_Virgo['V_ROT'][good_obs_idx]))\n",
    "                \n",
    "                diff_matrix = np.abs(good_axis_in_Virgo['V_ROT'][good_obs_idx]).reshape(n_obs_good, 1) - np.abs(good_axis_in_Virgo['V_ROT'][good_obs_idx]).reshape(1, n_obs_good)\n",
    "                \n",
    "                diff_matrix_norm = diff_matrix/Vmin_Virgo\n",
    "                \n",
    "                if np.any(np.abs(diff_matrix_norm) > 5.):\n",
    "                    '''\n",
    "                    print(sga_id)\n",
    "                    print(diff_matrix_norm)\n",
    "                    print(good_axis_inComa[['TARGETID', 'V_ROT', 'PVTYPE', 'FILENAME', 'DELTACHI2', 'ZWARN']][obs_idx].pprint(max_width=-1))\n",
    "                    ''';\n",
    "                    # Set all of these so that we don't look at this galaxy\n",
    "                    good_deltaV_Virgo[good_obs_idx] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531ceb5-3bdf-455e-968e-dfbbfa353e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_deltaV_axis_in_Virgo = good_axis_in_Virgo[good_deltaV_Virgo]\n",
    "\n",
    "print(len(good_deltaV_axis_in_Virgo), len(np.unique(good_deltaV_axis_in_Virgo['SGA_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081db19-f918-4d3a-bc7c-81857b37d789",
   "metadata": {},
   "source": [
    "#### Inclination Angle Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274d2bb-05a2-4464-b468-2c8cceb48d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGA['cosi2'] = (SGA['BA']**2 - q0**2)/(1 - q0**2)\n",
    "SGA['cosi2'][SGA['cosi2'] < 0] = 0\n",
    "\n",
    "good_deltaV_axis_in_Virgo['iSGA'] = -1\n",
    "\n",
    "for i in range(len(good_deltaV_axis_in_Virgo)):\n",
    "    \n",
    "    # Find galaxy in SGA\n",
    "    sga_idx = SGA_dict[good_deltaV_axis_in_Virgo['SGA_ID'][i]]\n",
    "    \n",
    "    good_deltaV_axis_in_Virgo['iSGA'][i] = sga_idx\n",
    "    \n",
    "good_deltaV_axis_in_Virgo['cosi2'] = SGA['cosi2'][good_deltaV_axis_in_Virgo['iSGA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81050ee4-42cb-4e2f-9380-547be8e0cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_min = 45. # degrees\n",
    "\n",
    "cosi2_max = np.cos(i_min*np.pi/180.)**2\n",
    "\n",
    "edge = good_deltaV_axis_in_Virgo['cosi2'] <= cosi2_max\n",
    "\n",
    "good_edge_axis_in_Virgo = good_deltaV_axis_in_Virgo[edge]\n",
    "\n",
    "print(len(good_edge_axis_in_Virgo), len(np.unique(good_edge_axis_in_Virgo['SGA_ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806897ec-edc9-4a3e-84ad-5f9ce568ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(tight_layout=True)\n",
    "\n",
    "plt.hist(np.arccos(np.sqrt(good_edge_axis_in_Virgo['cosi2']))*180/np.pi, bins=np.linspace(0, 90, 10))\n",
    "\n",
    "plt.xlabel('inclination angle [deg]')\n",
    "plt.ylabel('number of observations');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87588f-714d-4d1b-9e00-d67d250f5aa1",
   "metadata": {},
   "source": [
    "#### Morphology Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e94c7b-be26-42f3-95bd-b38f3c9df47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_edge_axis_in_Virgo['MORPHTYPE'] = SGA['MORPHTYPE'][good_edge_axis_in_Virgo['iSGA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09040f89-8c75-493f-80f6-35547fcaaaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spirals_Virgo = np.zeros(len(good_edge_axis_in_Virgo), dtype=bool)\n",
    "\n",
    "for i in range(len(good_edge_axis_in_Virgo)):\n",
    "    \n",
    "    try:    \n",
    "        if (good_edge_axis_in_Virgo['MORPHTYPE'][i][0] == 'S') and (good_edge_axis_in_Virgo['MORPHTYPE'][i][:2] != 'S0'):\n",
    "            spirals_Virgo[i] = True\n",
    "    except IndexError:\n",
    "        print(good_edge_axis_in_Virgo['MORPHTYPE'][i])\n",
    "\n",
    "good_edge_spirals_axis_in_Virgo = good_edge_axis_in_Virgo[spirals_Virgo]\n",
    "\n",
    "print(len(good_edge_spirals_axis_in_Virgo), len(np.unique(good_edge_spirals_axis_in_Virgo['SGA_ID'])))\n",
    "\n",
    "VI_good_edge_spirals_axis_in_Virgo = good_edge_spirals_axis_in_Virgo ## delete this line when VI is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76bed49-b72e-4369-9f0c-f16cf8bb1982",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visual Inspection Cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0872ba2-2471-4f5a-8e63-2d7b25940360",
   "metadata": {},
   "source": [
    "The visual inspection cut still needs to be done, and there is still a problem with the data above, but we're adding the fitting of the TFR code below so that it should work when the data <i>is</i> correct. At present, the variable `VI_good_edge_spirals_axis_in_Virgo = good_edge_spirals_axis_in_Virgo`, because the VI hasn't been done yet. Use `VI_good_edge_spirals_axis_in_Virgo` to store the results of the visual inspection so the code further down works, and delete the line indicated in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2adab-d340-4058-8694-858aa18678e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cutout(targetid, ra, dec, size, verbose=False):\n",
    "    \"\"\"Grab and cache legacy survey cutouts.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    targetid : int\n",
    "        DESI target ID.\n",
    "    ra : float\n",
    "        Right ascension (degrees).\n",
    "    dec : float\n",
    "        Declination (degrees).\n",
    "    verbose : bool\n",
    "        Add some status messages if true.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    img_name : str\n",
    "        Name of JPG cutout file written after query.\n",
    "    w : astropy.wcs.WCS\n",
    "        World coordinate system for the image.\n",
    "    \"\"\"\n",
    "    # Either load an existing image or download a cutout.\n",
    "    img_name = 'cache/iron_{}.jpg'.format(targetid)\n",
    "    \n",
    "    if os.path.exists(img_name):\n",
    "        if verbose:\n",
    "            print('{} exists.'.format(img_name))\n",
    "    else:\n",
    "        img_url = 'https://www.legacysurvey.org/viewer/cutout.jpg?ra={}&dec={}&zoom=14&layer=ls-dr9&size={}&sga'.format(ra, dec, size)\n",
    "        if verbose:\n",
    "            print('Get {}'.format(img_url))\n",
    "            \n",
    "        with open(img_name, 'wb') as handle: \n",
    "            response = requests.get(img_url, stream=True) \n",
    "            if not response.ok: \n",
    "                print(response) \n",
    "            for block in response.iter_content(1024): \n",
    "                if not block: \n",
    "                    break \n",
    "                handle.write(block)\n",
    "                \n",
    "    # Set up the WCS.\n",
    "    wcs_input_dict = {\n",
    "        'CTYPE1': 'RA---TAN',\n",
    "        'CUNIT1': 'deg',\n",
    "        'CDELT1': -0.262/3600,\n",
    "        'CRPIX1': size/2 + 0.5,\n",
    "        'CRVAL1': ra,\n",
    "        'NAXIS1': size,\n",
    "        'CTYPE2': 'DEC--TAN',\n",
    "        'CUNIT2': 'deg',\n",
    "        'CDELT2': 0.262/3600,\n",
    "        'CRPIX2': size/2 + 0.5,\n",
    "        'CRVAL2': dec,\n",
    "        'NAXIS2': size\n",
    "    }\n",
    "    w = WCS(wcs_input_dict)\n",
    "    \n",
    "    return img_name, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560edb39-7b45-4504-b24e-4677205045f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Compute the weighted average velocity for those galaxies with more than one observation at $0.33R_{26}$:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\overline{v} = \\frac{\\sum_i w_i v_i}{\\sum_i w_i}\n",
    "\\end{equation}\n",
    "where $w_i = 1/\\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bfb64-417b-4996-83f7-69b2eaa83fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SGA['V_0p33R26'] = np.nan\n",
    "SGA['V_0p33R26_err'] = np.nan\n",
    "\n",
    "weights_Virgo = 1./(VI_good_edge_spirals_axis_in_Virgo['V_ROT_ERR']**2)\n",
    "\n",
    "for sga_id in np.unique(VI_good_edge_spirals_axis_in_Virgo['SGA_ID']):\n",
    "    \n",
    "    # Identify all galaxy targets on this galaxy\n",
    "    obs_idx = VI_good_edge_spirals_axis_in_Virgo['SGA_ID'] == sga_id\n",
    "    \n",
    "    SGA['V_0p33R26'][SGA_dict[sga_id]] = np.average(np.abs(VI_good_edge_spirals_axis_in_Virgo['V_ROT'][obs_idx])) ## fiddled with this slightly, check jointlinefit.ipynb for original\n",
    "\n",
    "    SGA['V_0p33R26_err'][SGA_dict[sga_id]] = np.sqrt(1./np.sum(weights_Virgo[obs_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a98617-a5ad-487c-9b61-973858b80140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a catalog of just those galaxies with velocities\n",
    "SGA_TF_Virgo = SGA[np.isfinite(SGA['V_0p33R26']) & (SGA['R_MAG_SB26'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e95aac-b756-4583-ac26-e9a6fe504b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,5), tight_layout=True)\n",
    "\n",
    "x_Virgo = np.log10(SGA_TF_Virgo['V_0p33R26'])\n",
    "y_Virgo = SGA_TF_Virgo['R_MAG_SB26']\n",
    "xerr_Virgo = SGA_TF_Virgo['V_0p33R26_err']/SGA_TF_Virgo['V_0p33R26'],\n",
    "yerr_Virgo = SGA_TF_Virgo['R_MAG_SB26_ERR']\n",
    "\n",
    "plt.errorbar(x_Virgo, y_Virgo,\n",
    "             yerr_Virgo, xerr_Virgo,\n",
    "             fmt='.')\n",
    "\n",
    "plt.xlim([0.5, 3])\n",
    "plt.ylim([17, 8])\n",
    "\n",
    "plt.xlabel('log($V_{rot}$ [km/s])')\n",
    "plt.ylabel('$m_r (26)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676176fc-44ec-45c3-836b-bb97c88d6eed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fitting the TFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe456f7-2e0b-4790-956a-97b443dd5238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the first data set from Abell-2151 filtering, and pack the results into the arrays data1 and cov1.\n",
    "data_Abell = [] \n",
    "data_Abell.append(x_Abell)\n",
    "data_Abell.append(y_Abell)\n",
    "dx_Abell, dy_Abell = xerr_Abell, yerr_Abell\n",
    "\n",
    "data1 = data_Abell\n",
    "\n",
    "cov1 = np.empty((2, 2, len(x_Abell)))\n",
    "for i, (dx, dy) in enumerate(zip(dx_Abell, dy_Abell)):\n",
    "    cov1[:, :, i] = np.array([[dx**2, dx*dy], [dx*dy, dy**2]])\n",
    "\n",
    "# Generate the second data set from Virgo filtering, and pack the results into the arrays data2 and cov2.\n",
    "\n",
    "data_Virgo = [] \n",
    "data_Virgo.append(x_Virgo)\n",
    "data_Virgo.append(y_Virgo)\n",
    "dx_Virgo, dy_Virgo = xerr_Virgo, yerr_Virgo\n",
    "\n",
    "data2 = data_Virgo\n",
    "\n",
    "cov2 = np.empty((2, 2, len(x_Virgo)))\n",
    "for i, (dx, dy) in enumerate(zip(dx_Virgo, dy_Virgo)):\n",
    "    cov2[:, :, i] = np.array([[dx[1]**2, dx[1]*dy], [dx[1]*dy, dy**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de6fa9-827d-4368-8245-c07ea9cd55b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot of the correct data, but not using covariance calculations above (this cell should be deleted eventually) \n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,8))\n",
    "eb1 = ax.errorbar(x_Abell, y_Abell, yerr_Abell, xerr_Abell, fmt='.')\n",
    "eb2 = ax.errorbar(x_Virgo, y_Virgo, yerr_Virgo, xerr_Virgo, fmt='.')\n",
    "ax.set(xlabel='log($V_{rot}$ [km/s])', ylabel='$m_r (26)$');\n",
    "ax.set_ylim(18,8)\n",
    "ax.set_title('Abell-2151 and Virgo Data (Real Data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f2855-16c5-4971-9173-d2558b9a6af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Eventually correct plotting, but it's doing the weird covariance from two cells up so this is WRONG (this cell is what should be used once cov2 is handled)\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,8))\n",
    "eb1 = ax.errorbar(data1[0], data1[1], xerr=np.sqrt(cov1[0,0]), yerr=np.sqrt(cov1[1,1]), fmt='.')\n",
    "eb2 = ax.errorbar(data2[0], data2[1], xerr=np.sqrt(cov2[0,0]), yerr=np.sqrt(cov2[1,1]), fmt='.')\n",
    "\n",
    "ax.set(xlabel='log($V_{rot}$ [km/s])', ylabel='$m_r (26)$');\n",
    "ax.set_xlim(0.5,2.5)\n",
    "ax.set_ylim(18,8)\n",
    "ax.set_title('Abell-2151 and Virgo Data (Incorrect cov2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa24315-2b6d-4f32-ab16-9b580dcc382b",
   "metadata": {},
   "source": [
    "### Standard Fit\n",
    "\n",
    "Attempt a standard $\\chi^2$ fit to the data. Use both the uncertainties in $x$ and $y$, but ignore the covariances. Here we use the form of the $\\chi^2$ defined in **Numerical Recipes in C++**, eq. 15.3.2:\n",
    "\n",
    "$$\n",
    "\\chi^2(a,b) = \\sum_{i}\\frac{(y_i-ax_i-b)^2}{\\sigma_{y_i}^2 + a^2\\sigma_{x_i}^2}\n",
    "$$\n",
    "\n",
    "In this case, we divide the data in two and specify the parameters as the array `[a, b1, b2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf54a22-d0cb-4d51-939e-8a31853f0289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chi2(params, data1, data2, cov1, cov2):    \n",
    "    \"\"\"Chi-square function for joint slope fit to two data sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data1 : ndarray\n",
    "        2xN array of [x1, y1] for data set 1.\n",
    "    data2 : ndarray\n",
    "        2xM array of [x2, y2] for data set 2.\n",
    "    cov1 : ndarray\n",
    "        2x2xN covariances for data set 1.\n",
    "    cov2 : ndarray\n",
    "        2x2xM covariances for data set 2.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    chi2 : float\n",
    "        Sum of chi-square fits to data sets 1 and 2.\n",
    "    \"\"\"\n",
    "    a, b1, b2 = params\n",
    "    \n",
    "    x1, y1 = data1[0], data1[1]\n",
    "    varx1, vary1 = cov1[0,0], cov1[1,1]\n",
    "    chi2_1 = np.sum((y1 - a*x1 - b1)**2 / (vary1 + a**2*varx1))\n",
    "    \n",
    "    x2, y2 = data2[0], data2[1]\n",
    "    ##varx2, vary2 = cov2[0,0], cov2[1,1]\n",
    "    varx2, vary2 = (xerr_Virgo[0])**2, (yerr_Virgo[0])**2 ## makeshift cov2 \n",
    "    chi2_2 = np.sum((y2 - a*x2 - b2)**2 / (vary2 + a**2*varx2))\n",
    "    \n",
    "    return chi2_1 + chi2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c76b9d7-22c2-451a-82c2-a95de2244cb9",
   "metadata": {},
   "source": [
    "### Peform the Fit and Plot Results\n",
    "\n",
    "Use the `BFGS` minimizer to find the best fit parameters.\n",
    "\n",
    "Note that the result may depend sensitively on the initial seed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba4353-0a0d-4098-bba5-842800205b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## due to the non-functional cov2 above, this cell currently fails \n",
    "\n",
    "p0 = [1.5, 0.7, 1.2]\n",
    "res = minimize(chi2, p0, args=(data1, data2, cov1, cov2), method='BFGS')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba5af3-e8fb-4272-84ee-2c058f71be02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## res.x does not return the necessary 5 values, just the first 3 (no sig values) so this cell does not plot correctly. \n",
    "\n",
    "a_, b1_, b2_, sig1_, sig2_ = res.x\n",
    "da_, db1_, db2_ = [np.sqrt(res.hess_inv[i,i]) for i in range(3)]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,8))\n",
    "eb1 = ax.errorbar(data1[0], data1[1], xerr=np.sqrt(cov1[0,0]), yerr=np.sqrt(cov1[1,1]), fmt='.')\n",
    "x_ = np.linspace(np.min(data1[0]), np.max(data1[0]))\n",
    "ax.plot(x_, a_*x_ + b1_, color=eb1[0].get_color(),\n",
    "        label=r'Abell-2151: $\\hat{{a}}={:.2f}\\pm{:.2f}$, $\\hat{{b}}_1={:.2f}\\pm{:.2f}$'.format(a_, da_, b1_, db1_))\n",
    "ax.plot(x_, a_*x_ + b1_ + sig1_, ls=':', color=eb1[0].get_color())\n",
    "ax.plot(x_, a_*x_ + b1_ - sig1_, ls=':', color=eb1[0].get_color())\n",
    "\n",
    "##eb2 = ax.errorbar(data2[0], data2[1], xerr=np.sqrt(cov2[0,0]), yerr=np.sqrt(cov2[1,1]), fmt='.')\n",
    "eb2 = ax.errorbar(data2[0], data2[1], yerr_Virgo, xerr_Virgo, fmt='.')\n",
    "\n",
    "x_ = np.linspace(np.min(data2[0]), np.max(data2[0]))\n",
    "ax.plot(data2[0], a_*data2[0] + b2_, color=eb2[0].get_color(),\n",
    "        label=r'Virgo: $\\hat{{a}}={:.2f}\\pm{:.2f}$, $\\hat{{b}}_1={:.2f}\\pm{:.2f}$'.format(a_, da_, b2_, db2_))\n",
    "ax.plot(x_, a_*x_ + b2_ + sig2_, ls=':', color=eb2[0].get_color())\n",
    "ax.plot(x_, a_*x_ + b2_ - sig2_, ls=':', color=eb2[0].get_color())\n",
    "\n",
    "ax.set(xlabel='log($V_{rot}$ [km/s])', ylabel='$m_r (26)$')\n",
    "ax.legend()\n",
    "ax.set_title('Abell-2151 and Virgo Data Joint-Line TFR (Real Data)')\n",
    "ax.set_ylim(18,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72496643-e79f-49a7-9b13-fe4d6a82d202",
   "metadata": {},
   "source": [
    "### Enable a Joint Fit in `hyperfit`\n",
    "\n",
    "Here we set up a new class that can handle multiple data sets at once. The main condition is that the linear fits to the data always have a common slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ce70e-baee-4b41-97c1-1902d0d70cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nlogl(params, datasets, covs):\n",
    "    \"\"\"Chi-square function for joint slope fit to two or more data sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list or ndarray\n",
    "        m x 2xN array of [x1, y1] for each data set.\n",
    "    cov : ndarray\n",
    "        m x 2x2xN covariances for each data set.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    chi2 : float\n",
    "        Sum of chi-square fits to data sets 1 and 2.\n",
    "    \"\"\"\n",
    "    nsets = len(datasets)\n",
    "    a = params[0]\n",
    "    b = params[1:nsets+1]\n",
    "    sigma = params[nsets+1:]\n",
    "    \n",
    "    nloglike = 0.\n",
    "    for i in range(nsets): \n",
    "        data = datasets[i]\n",
    "        cov = covs[i]\n",
    "        x, dx2 = data[0], cov[0,0]\n",
    "        y, dy2 = data[1], cov[1,1]\n",
    "        dxy = cov[0,1]\n",
    "        sy2 = sigma[i]**2 + a**2*dx2 + dy2 - 2*dxy*a\n",
    "        nloglike += -0.5*np.sum(np.log((a**2 + 1)/sy2) - (a*x - y + b[i])**2/sy2)\n",
    "    \n",
    "    return nloglike\n",
    "\n",
    "# Minimization.\n",
    "print('Differential evolution:')\n",
    "bounds = [[-10., 10.], [-6., 6.], [-5., 5.], [0, 1], [0, 2]]\n",
    "res = differential_evolution(nlogl, bounds, args=([data1, data2], [cov1, cov2]))\n",
    "print(res)\n",
    "\n",
    "# Initial guesses\n",
    "slope = 1.5\n",
    "intercepts = [0.7, 1.3]\n",
    "sigmas = [0.2, 0.3]\n",
    "p0 = [slope] + intercepts + sigmas\n",
    "\n",
    "print('\\n\\nBFGS minimization:')\n",
    "res = minimize(nlogl, p0, args=([data1, data2], [cov1, cov2]), method='BFGS')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1e1e3-8689-4f09-8ddb-81aea7fa5648",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encapsulate Multi-Dataset Fits in a Single Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39bc9de-3e36-4102-a4b2-a16afec0a4fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "Define a class `MultiLinFit` that takes in a list of datasets and covariances, each in the same format used by `LinFit` in the hyperfit package. i.e.,\n",
    "* `data` are 2xN arrays, and `datasets` is a list of `data`.\n",
    "* `cov` are 2x2xN arrays, and `covs` is a list of `cov`.\n",
    "\n",
    "Note that the data sets can be different sizes.\n",
    "\n",
    "While the `LinFit` class allows for higher-dimensional fits -- planes and hyperplanes in addition to lines -- this class only fits lines, as needed for the Tully-Fisher relation. It is assumed that all data sets share a common slope but have different intercepts and scatter parameters. The fit parameters are of the form\n",
    "\n",
    "$$\n",
    "\\vec{\\theta} = (a, b_1, b_2, \\ldots, b_m, \\sigma_1, \\sigma_2, \\ldots, \\sigma_m),\n",
    "$$\n",
    "\n",
    "where $a$ is the common slope, $b_1,\\ldots,b_m$ are the intercepts for the $m$ datasets, and $\\sigma_1,\\ldots,\\sigma_m$ are the scatter parameters for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ca628-60c7-4f8d-aa2f-534db2588010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiLinFit:\n",
    "    \"\"\"Class to implement linear fits to multiple datasets, assuming\n",
    "    a common slope but different intercepts across each set.\n",
    "    \n",
    "    Based on the hyperfit algorithm of Robotham and Obreschkow (PASP 2015)\n",
    "    and the Python LinFit implementation of Howlett and Gordon\n",
    "    (https://hyperfit.readthedocs.io/en/latest/).\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    nsets : int\n",
    "        Number of data sets and covariances entered by user.\n",
    "    ndims : int\n",
    "        Dimensionality of the data (expect 2).\n",
    "    ndata : ndarray\n",
    "        Array giving the length of every input data vector.\n",
    "    params : ndarray\n",
    "        Best-fit linear parameters for the data sets.\n",
    "    params_scatter : ndarray\n",
    "        Best-fit scatters along the y-axis for each data set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list or ndarray\n",
    "        An Mx2xN array of 2xN data vectors.\n",
    "    covs : list or ndarray\n",
    "        An Mx2x2xN array of 2x2xN covariance matrices.\n",
    "    weights : ndarray\n",
    "        Array of weights for each data set. Unit weights if not specified.\n",
    "    vertaxis : float\n",
    "        Specify which coordinate axis in data is the 'vertical' one. Defaults to last axis (-1).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, datasets, covs, weights=None, vertaxis=-1):\n",
    "        \n",
    "        self.nsets = len(datasets)\n",
    "        self.ndims = np.shape(datasets[0])[0]\n",
    "        self.ndata = np.array([np.shape(data)[1] for data in datasets])\n",
    "        self.datasets = datasets\n",
    "        self.covs = covs\n",
    "        self.data = None\n",
    "        self.cov = None\n",
    "        \n",
    "        self.npars = 1 + self.nsets # slope + intercepts + sigmas\n",
    "        self.params = np.zeros(self.npars)\n",
    "        self.params_scatter = np.zeros(self.nsets)\n",
    "        \n",
    "        self.weights = [np.ones(n) for n in self.ndata] if weights is None else weights\n",
    "        self.vertaxis = vertaxis\n",
    "        \n",
    "        self.param_bounds = None      # parameter fit bounds for all data sets\n",
    "        \n",
    "    # Log posterior function.\n",
    "    def _lnpost(self, params):\n",
    "        lnpost = 0.\n",
    "\n",
    "        for i in range(self.nsets):\n",
    "            # Loop over individual data sets. \n",
    "            self.data = self.datasets[i]\n",
    "            self.cov  = self.covs[i]\n",
    "            \n",
    "            # Set up parameter and bounds arrays for each data set.\n",
    "            pars_i = np.array([params[0]] + [params[1+i]] + [params[self.nsets+1+i]])\n",
    "            bounds_i = [self.param_bounds[0]] + \\\n",
    "                       [self.param_bounds[1+i]] + \\\n",
    "                       [self.param_bounds[self.nsets+1+i]]\n",
    "\n",
    "            # Set up weights for each data set.\n",
    "            weights = self.weights[i]\n",
    "            \n",
    "            # Sum over all data sets.\n",
    "            lnprior = self._lnprior(pars_i, bounds_i)\n",
    "            lnlike = self._lnlike(pars_i)                \n",
    "            lnpost += np.sum(weights * lnlike) + lnprior\n",
    "        \n",
    "        return lnpost\n",
    "            \n",
    "    # Log prior function.\n",
    "    def _lnprior(self, params, bounds):\n",
    "        lnprior = 0.\n",
    "        for i, (param, bound) in enumerate(zip(params.T, bounds)):\n",
    "            lnprior += np.where(np.logical_or(param < bound[0], param > bound[1]), -np.inf, 0.0)\n",
    "\n",
    "        return lnprior\n",
    "    \n",
    "    # Log likelihood function.\n",
    "    def _lnlike(self, params):\n",
    "        a, b, sigma = params\n",
    "\n",
    "        x, dx2 = self.data[0], self.cov[0,0]\n",
    "        y, dy2 = self.data[1], self.cov[1,1]\n",
    "        dxy = self.cov[0,1]\n",
    "        sy2 = sigma**2 + a**2*dx2 + dy2 - 2*dxy*a\n",
    "        lnlike = 0.5*np.sum(np.log((a**2 + 1)/sy2) - (a*x - y + b)**2/sy2)\n",
    "\n",
    "        return lnlike\n",
    "    \n",
    "    def bessel_cochran(self, sigma):\n",
    "        \"\"\"Bessel-Cochran correction of sample scatter to population scatter.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : ndarray\n",
    "            1xM array of scatters for the M input datasets.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        sigma_corr : ndarray\n",
    "            1xM array of corrected scatter parameters.\n",
    "        \"\"\"\n",
    "        sigma_corr = (\n",
    "            np.sqrt(0.5 * self.ndata)\n",
    "            * np.exp(loggamma(0.5 * (self.ndata - self.ndims)) - loggamma(0.5 * (self.ndata - self.ndims + 1.0)))\n",
    "        ) * sigma\n",
    "\n",
    "        return sigma_corr\n",
    "    \n",
    "    def optimize(self, bounds, tol=1e-6, verbose=False):\n",
    "        \"\"\"Find the best-fit line for multiple datasets, assuming a\n",
    "        common slope across all sets but independent intercepts and scatters.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        bounds : sequence\n",
    "            Bounds for variables [a, b1, ..., bm, sig1, ..., sigm].\n",
    "        tol : float\n",
    "            Optimization tolerance.\n",
    "        verbose : bool\n",
    "            Print fit result.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        params : ndarray\n",
    "            Array of best-fit slope and intercepts [a, b1, b2, ..., bm]\n",
    "        params_scatter : ndarray\n",
    "            Array of vertical axis scatter parameters [sig1, sig2, ... sigm]\n",
    "        log_posterior : float\n",
    "            Value of ln(posterior) at the best fit point.\n",
    "        \"\"\"\n",
    "        self.param_bounds = bounds\n",
    "        res = differential_evolution(lambda *args: -self._lnpost(*args), self.param_bounds, tol=tol)\n",
    "\n",
    "        if verbose:\n",
    "            print(res)\n",
    "            \n",
    "        self.params = res.x[:-self.nsets]\n",
    "        self.params_scatter = np.fabs(res.x[-self.nsets:])\n",
    "        self.params_scatter = self.bessel_cochran(self.params_scatter)\n",
    "        return self.params, self.params_scatter, -res.fun\n",
    "    \n",
    "    def emcee(self, bounds, max_iter=100000, batchsize=1000, ntau=50.0, tautol=0.05, verbose=False):\n",
    "        \"\"\"Run MCMC using the emcee EnsembleSampler.\n",
    "        \n",
    "        The MCMC is seeded using a randomization of the best-fit values of the\n",
    "        common slope, intercepts, and vertical scatters [a, b1, ..., bm, sig1, ..., sigm].\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        bounds : sequence\n",
    "            Bounds for variables [a, b1, ..., bm, sig1, ..., sigm].\n",
    "        max_iter : int\n",
    "            Maximum number of MCMC iterations.\n",
    "        batchsize : int\n",
    "            Size of each batch. Convergence checked after each batch.\n",
    "        ntau : float\n",
    "            Minimum autocorrelation length to consider for convergence.\n",
    "        tautol : float\n",
    "            Maximum fractional deviation between successive autocorrelation lengths for convergence.\n",
    "        verbose : bool\n",
    "            Print out convergence statistics and progress bars if True.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        mcmc_samples : ndarray\n",
    "            Array of flattened and burned-in MCMC samples.\n",
    "        mcmc_lnlike : ndarray\n",
    "            Log-likelihood values of every MCMC sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up emcee. Start the walkers in a small 1 percent ball around the best fit.\n",
    "        # The best fit will set self.params and self.params_scatter.\n",
    "        self.optimize(bounds, verbose=verbose)\n",
    "        ndim = len(self.params) + len(self.params_scatter)\n",
    "        nwalker = 4 * ndim\n",
    "        seeds = np.asarray([\n",
    "            [(0.01 * np.random.rand() + 0.995) * j for j in np.concatenate([self.params, self.params_scatter])]\n",
    "            for _ in range(nwalker)\n",
    "        ])\n",
    "\n",
    "        sampler = emcee.EnsembleSampler(nwalker, ndim, self._lnpost)\n",
    "\n",
    "        old_tau = np.inf\n",
    "        niter = 0\n",
    "        converged = 0\n",
    "        while ~converged:\n",
    "            sampler.run_mcmc(seeds, nsteps=batchsize, progress=verbose)\n",
    "            tau = sampler.get_autocorr_time(discard=int(0.5 * niter), tol=0)\n",
    "            converged = np.all(ntau * tau < niter)\n",
    "            converged &= np.all(np.abs(old_tau - tau) / tau < tautol)\n",
    "            old_tau = tau\n",
    "            begin = None\n",
    "            niter += 1000\n",
    "            if verbose:\n",
    "                print(\"Niterations/Max Iterations: \", niter, \"/\", max_iter)\n",
    "                print(\"Integrated ACT/Min Convergence Iterations: \", tau, \"/\", np.amax(ntau * tau))\n",
    "            if niter >= max_iter:\n",
    "                break\n",
    "\n",
    "        # Remove burn-in and and save the samples\n",
    "        tau = sampler.get_autocorr_time(discard=int(0.5 * niter), tol=0)\n",
    "        burnin = int(2 * np.max(tau))\n",
    "        samples = sampler.get_chain(discard=burnin, flat=True).T\n",
    "        mcmc_samples = samples\n",
    "        mcmc_lnlike = sampler.get_log_prob(discard=burnin, flat=True)\n",
    "\n",
    "        return mcmc_samples, mcmc_lnlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd850a-34d1-4642-aeb2-308b72121713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlf = MultiLinFit([data1, data2], [cov1, cov2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7152e8-5dc5-4c97-b211-07cba933fce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlf.params_scatter, mlf.ndata, mlf.ndims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647c368-5bf2-4fd7-953e-f1f0fcf1c381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bounds = [[-10., 10.], [-10., 10.], [-10., 10.], [0., 2.], [0., 2.]]\n",
    "mlf.optimize(bounds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4686f-b96c-48a5-84e6-5a7384240923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run an MCMC\n",
    "bounds = [[-10., 10.], [-10., 10.], [-10., 10.], [0., 2.], [0., 2.]]\n",
    "mcmc_samples, mcmc_lnlike = mlf.emcee(bounds, max_iter=10000, verbose=True)\n",
    "print(np.mean(mcmc_samples, axis=1), np.std(mcmc_samples, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee1e38-3bdd-4596-b10e-d9d0aa1b8c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = corner(mcmc_samples.T, bins=25, smooth=1,\n",
    "#              range=[[1.9, 2.4], [0.75, 1.1], [0.1, 0.3]],   # Range for a, b, sigma. Adjust as needed.\n",
    "             labels=['$a$', '$b_1$', '$b_2$', r'$\\sigma_1$', r'$\\sigma_2$'],\n",
    "             levels=(1-np.exp(-0.5), 1-np.exp(-2)),\n",
    "             quantiles=[0.16, 0.5, 0.84],\n",
    "             color='blue',\n",
    "             hist_kwargs={'histtype':'stepfilled', 'alpha':0.3},\n",
    "             plot_datapoints=False,\n",
    "             fill_contours=True,\n",
    "             show_titles=True,\n",
    "             title_kwargs={\"fontsize\": 12})\n",
    "\n",
    "fig.savefig('multiline_fit_corner.png', dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESI main",
   "language": "python",
   "name": "desi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
